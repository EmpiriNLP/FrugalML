model	experiment	trained_samples	epochs	batch_size	evaluated_samples	accuracy	avg_similarity	total_time	avg_time_per_sample	training_time
meta-llama/Llama-3.1-8B-Instruct	baseline	0	0	0	22	54.55	75.91	18.9913	0.8632	0.0
meta-llama/Llama-3.1-8B-Instruct	adapter	1	1	1	22	0.0	7.14	23.984	1.0902	25.173
meta-llama/Llama-3.1-8B-Instruct	adapter	1	5	1	22	0.0	7.14	24.0365	1.0926	29.936
meta-llama/Llama-3.1-8B-Instruct	adapter	1	15	1	22	0.0	7.14	23.6036	1.0729	31.6139
meta-llama/Llama-3.1-8B-Instruct	adapter	1	1	2	22	0.0	0.0	23.8505	1.0841	30.6361
meta-llama/Llama-3.1-8B-Instruct	adapter	1	5	2	22	0.0	0.91	23.6434	1.0747	27.6252
meta-llama/Llama-3.1-8B-Instruct	adapter	1	15	2	22	0.0	0.09	23.7797	1.0809	32.9998
meta-llama/Llama-3.1-8B-Instruct	adapter	1	1	4	22	0.0	0.82	23.8801	1.0855	26.8761
meta-llama/Llama-3.1-8B-Instruct	adapter	1	5	4	22	0.0	0.05	23.8729	1.0851	28.0962
meta-llama/Llama-3.1-8B-Instruct	adapter	1	15	4	22	0.0	0.0	23.8711	1.0851	33.35907
meta-llama/Llama-3.1-8B-Instruct	adapter	200	1	1	22	0.0	6.64	96.8077	4.4003	174.6678
meta-llama/Llama-3.1-8B-Instruct	adapter	200	5	1	22	18.18	60.68	95.8796	4.3582	783.5384
meta-llama/Llama-3.1-8B-Instruct	adapter	200	15	1	22	22.73	61.68	102.0024	4.6365	2351.3529
meta-llama/Llama-3.1-8B-Instruct	adapter	200	1	2	22	9.09	59.82	38.5248	1.7511	204.3478
meta-llama/Llama-3.1-8B-Instruct	adapter	200	1	4	22	0.0	17.82	29.8879	1.3585	223.0566
meta-llama/Llama-3.1-8B-Instruct	adapter	200	5	2	22	0.0	12.23	95.163	4.3256	912.5571
meta-llama/Llama-3.1-8B-Instruct	adapter	200	5	4	22	4.55	57.82	95.1233	4.3238	1056.7121
meta-llama/Llama-3.1-8B-Instruct	adapter	200	15	2	22	40.91	68.27	93.9031	4.2683	2724.6833
meta-llama/Llama-3.1-8B-Instruct	adapter	200	15	4	22	18.18	60.23	95.0987	4.3227	3132.8125
meta-llama/Llama-3.1-8B-Instruct	adapter	1000	1	1	22	18.18	60.55	95.1064	4.323	798.8035
meta-llama/Llama-3.1-8B-Instruct	adapter	1000	1	2	22	9.09	58.55	95.1258	4.3239	931.8902
meta-llama/Llama-3.1-8B-Instruct	adapter	1000	1	4	22	0.0	12.23	95.2487	4.3295	1056.5642
meta-llama/Llama-3.1-8B-Instruct	adapter	1000	5	1	22	0.0	12.23	94.9918	4.3178	3940.4032
meta-llama/Llama-3.1-8B-Instruct	adapter	1000	5	2	22	18.18	61.82	95.0703	4.3214	4629.721
meta-llama/Llama-3.1-8B-Instruct	adapter	1000	5	4	22	9.09	9.09	4.7909	0.2178	5270.9413
meta-llama/Llama-3.1-8B-Instruct	adapter	1000	5	4	22	13.64	60.82	97.2963	4.4226	5011.325
meta-llama/Llama-3.1-8B-Instruct	adapter	1000	15	1	22	18.18	60.55	95.1283	4.324	11027.3941
meta-llama/Llama-3.1-8B-Instruct	adapter	1000	15	2	22	9.09	9.09	4.8478	0.2204	13125.7046
meta-llama/Llama-3.1-8B-Instruct	adapter	1000	15	4	22	0.0	6.64	95.2776	4.3308	15036.1789
meta-llama/Llama-3.1-8B-Instruct	adapter	1	1	1	22	0.0	7.14	95.6552	4.348	1.0977
