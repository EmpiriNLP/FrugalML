{
  "best_metric": 4.778515815734863,
  "best_model_checkpoint": "./models/adapter/checkpoint-3000",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 136.0,
      "learning_rate": 1e-05,
      "loss": 11.8938,
      "step": 10
    },
    {
      "epoch": 0.02,
      "grad_norm": 167.0,
      "learning_rate": 2e-05,
      "loss": 11.0938,
      "step": 20
    },
    {
      "epoch": 0.03,
      "grad_norm": 107.5,
      "learning_rate": 3e-05,
      "loss": 9.4719,
      "step": 30
    },
    {
      "epoch": 0.04,
      "grad_norm": 92.0,
      "learning_rate": 4e-05,
      "loss": 8.1027,
      "step": 40
    },
    {
      "epoch": 0.05,
      "grad_norm": 107.0,
      "learning_rate": 5e-05,
      "loss": 8.4875,
      "step": 50
    },
    {
      "epoch": 0.06,
      "grad_norm": 54.0,
      "learning_rate": 6e-05,
      "loss": 8.8562,
      "step": 60
    },
    {
      "epoch": 0.07,
      "grad_norm": 52.25,
      "learning_rate": 7e-05,
      "loss": 7.0508,
      "step": 70
    },
    {
      "epoch": 0.08,
      "grad_norm": 67.5,
      "learning_rate": 8e-05,
      "loss": 7.2083,
      "step": 80
    },
    {
      "epoch": 0.09,
      "grad_norm": 38.0,
      "learning_rate": 9e-05,
      "loss": 8.1016,
      "step": 90
    },
    {
      "epoch": 0.1,
      "grad_norm": 34.0,
      "learning_rate": 0.0001,
      "loss": 7.6437,
      "step": 100
    },
    {
      "epoch": 0.11,
      "grad_norm": 19.25,
      "learning_rate": 9.993288590604028e-05,
      "loss": 5.3516,
      "step": 110
    },
    {
      "epoch": 0.12,
      "grad_norm": 24.75,
      "learning_rate": 9.986577181208055e-05,
      "loss": 6.6281,
      "step": 120
    },
    {
      "epoch": 0.13,
      "grad_norm": 14.875,
      "learning_rate": 9.979865771812082e-05,
      "loss": 6.6125,
      "step": 130
    },
    {
      "epoch": 0.14,
      "grad_norm": 22.125,
      "learning_rate": 9.973154362416108e-05,
      "loss": 6.7318,
      "step": 140
    },
    {
      "epoch": 0.15,
      "grad_norm": 16.5,
      "learning_rate": 9.966442953020134e-05,
      "loss": 7.4969,
      "step": 150
    },
    {
      "epoch": 0.16,
      "grad_norm": 17.25,
      "learning_rate": 9.959731543624161e-05,
      "loss": 5.4938,
      "step": 160
    },
    {
      "epoch": 0.17,
      "grad_norm": 28.625,
      "learning_rate": 9.953020134228188e-05,
      "loss": 5.3375,
      "step": 170
    },
    {
      "epoch": 0.18,
      "grad_norm": 10.375,
      "learning_rate": 9.946308724832215e-05,
      "loss": 5.1984,
      "step": 180
    },
    {
      "epoch": 0.19,
      "grad_norm": 10.3125,
      "learning_rate": 9.939597315436242e-05,
      "loss": 6.4266,
      "step": 190
    },
    {
      "epoch": 0.2,
      "grad_norm": 25.25,
      "learning_rate": 9.93288590604027e-05,
      "loss": 5.9016,
      "step": 200
    },
    {
      "epoch": 0.21,
      "grad_norm": 12.0625,
      "learning_rate": 9.926174496644296e-05,
      "loss": 5.0172,
      "step": 210
    },
    {
      "epoch": 0.22,
      "grad_norm": 24.75,
      "learning_rate": 9.919463087248323e-05,
      "loss": 6.6922,
      "step": 220
    },
    {
      "epoch": 0.23,
      "grad_norm": 20.75,
      "learning_rate": 9.91275167785235e-05,
      "loss": 4.9875,
      "step": 230
    },
    {
      "epoch": 0.24,
      "grad_norm": 9.875,
      "learning_rate": 9.906040268456376e-05,
      "loss": 3.7751,
      "step": 240
    },
    {
      "epoch": 0.25,
      "grad_norm": 12.0,
      "learning_rate": 9.899328859060403e-05,
      "loss": 6.8117,
      "step": 250
    },
    {
      "epoch": 0.26,
      "grad_norm": 8.5625,
      "learning_rate": 9.89261744966443e-05,
      "loss": 5.5312,
      "step": 260
    },
    {
      "epoch": 0.27,
      "grad_norm": 8.3125,
      "learning_rate": 9.885906040268457e-05,
      "loss": 5.043,
      "step": 270
    },
    {
      "epoch": 0.28,
      "grad_norm": 22.125,
      "learning_rate": 9.879194630872483e-05,
      "loss": 6.5469,
      "step": 280
    },
    {
      "epoch": 0.29,
      "grad_norm": 21.75,
      "learning_rate": 9.87248322147651e-05,
      "loss": 6.3406,
      "step": 290
    },
    {
      "epoch": 0.3,
      "grad_norm": 13.3125,
      "learning_rate": 9.865771812080538e-05,
      "loss": 6.1328,
      "step": 300
    },
    {
      "epoch": 0.31,
      "grad_norm": 21.0,
      "learning_rate": 9.859060402684565e-05,
      "loss": 7.2359,
      "step": 310
    },
    {
      "epoch": 0.32,
      "grad_norm": 17.375,
      "learning_rate": 9.852348993288592e-05,
      "loss": 6.9391,
      "step": 320
    },
    {
      "epoch": 0.33,
      "grad_norm": 15.375,
      "learning_rate": 9.845637583892618e-05,
      "loss": 6.5969,
      "step": 330
    },
    {
      "epoch": 0.34,
      "grad_norm": 10.5,
      "learning_rate": 9.838926174496645e-05,
      "loss": 4.4813,
      "step": 340
    },
    {
      "epoch": 0.35,
      "grad_norm": 27.5,
      "learning_rate": 9.832214765100671e-05,
      "loss": 6.0375,
      "step": 350
    },
    {
      "epoch": 0.36,
      "grad_norm": 7.625,
      "learning_rate": 9.825503355704698e-05,
      "loss": 5.1367,
      "step": 360
    },
    {
      "epoch": 0.37,
      "grad_norm": 15.6875,
      "learning_rate": 9.818791946308725e-05,
      "loss": 5.7527,
      "step": 370
    },
    {
      "epoch": 0.38,
      "grad_norm": 6.625,
      "learning_rate": 9.812080536912752e-05,
      "loss": 4.6789,
      "step": 380
    },
    {
      "epoch": 0.39,
      "grad_norm": 10.8125,
      "learning_rate": 9.80536912751678e-05,
      "loss": 5.3922,
      "step": 390
    },
    {
      "epoch": 0.4,
      "grad_norm": 8.5,
      "learning_rate": 9.798657718120807e-05,
      "loss": 5.7944,
      "step": 400
    },
    {
      "epoch": 0.41,
      "grad_norm": 9.75,
      "learning_rate": 9.791946308724833e-05,
      "loss": 4.9086,
      "step": 410
    },
    {
      "epoch": 0.42,
      "grad_norm": 17.75,
      "learning_rate": 9.78523489932886e-05,
      "loss": 6.9219,
      "step": 420
    },
    {
      "epoch": 0.43,
      "grad_norm": 14.25,
      "learning_rate": 9.778523489932886e-05,
      "loss": 7.2094,
      "step": 430
    },
    {
      "epoch": 0.44,
      "grad_norm": 6.9375,
      "learning_rate": 9.771812080536913e-05,
      "loss": 4.8354,
      "step": 440
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.0,
      "learning_rate": 9.76510067114094e-05,
      "loss": 6.6395,
      "step": 450
    },
    {
      "epoch": 0.46,
      "grad_norm": 7.46875,
      "learning_rate": 9.758389261744967e-05,
      "loss": 4.15,
      "step": 460
    },
    {
      "epoch": 0.47,
      "grad_norm": 13.9375,
      "learning_rate": 9.751677852348994e-05,
      "loss": 6.75,
      "step": 470
    },
    {
      "epoch": 0.48,
      "grad_norm": 6.53125,
      "learning_rate": 9.74496644295302e-05,
      "loss": 5.5672,
      "step": 480
    },
    {
      "epoch": 0.49,
      "grad_norm": 13.5,
      "learning_rate": 9.738255033557047e-05,
      "loss": 6.9266,
      "step": 490
    },
    {
      "epoch": 0.5,
      "grad_norm": 11.4375,
      "learning_rate": 9.731543624161075e-05,
      "loss": 5.2953,
      "step": 500
    },
    {
      "epoch": 0.51,
      "grad_norm": 18.375,
      "learning_rate": 9.724832214765102e-05,
      "loss": 6.5062,
      "step": 510
    },
    {
      "epoch": 0.52,
      "grad_norm": 8.5625,
      "learning_rate": 9.718120805369128e-05,
      "loss": 5.4156,
      "step": 520
    },
    {
      "epoch": 0.53,
      "grad_norm": 11.1875,
      "learning_rate": 9.711409395973155e-05,
      "loss": 5.8797,
      "step": 530
    },
    {
      "epoch": 0.54,
      "grad_norm": 9.0,
      "learning_rate": 9.704697986577182e-05,
      "loss": 5.9031,
      "step": 540
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.0,
      "learning_rate": 9.697986577181208e-05,
      "loss": 4.9431,
      "step": 550
    },
    {
      "epoch": 0.56,
      "grad_norm": 11.25,
      "learning_rate": 9.691275167785235e-05,
      "loss": 6.3797,
      "step": 560
    },
    {
      "epoch": 0.57,
      "grad_norm": 6.625,
      "learning_rate": 9.684563758389262e-05,
      "loss": 5.8563,
      "step": 570
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.0,
      "learning_rate": 9.67785234899329e-05,
      "loss": 7.6914,
      "step": 580
    },
    {
      "epoch": 0.59,
      "grad_norm": 7.125,
      "learning_rate": 9.671140939597317e-05,
      "loss": 6.3063,
      "step": 590
    },
    {
      "epoch": 0.6,
      "grad_norm": 11.25,
      "learning_rate": 9.664429530201344e-05,
      "loss": 5.6797,
      "step": 600
    },
    {
      "epoch": 0.61,
      "grad_norm": 16.0,
      "learning_rate": 9.65771812080537e-05,
      "loss": 5.2898,
      "step": 610
    },
    {
      "epoch": 0.62,
      "grad_norm": 4.8125,
      "learning_rate": 9.651006711409395e-05,
      "loss": 4.3438,
      "step": 620
    },
    {
      "epoch": 0.63,
      "grad_norm": 15.75,
      "learning_rate": 9.644295302013423e-05,
      "loss": 5.3375,
      "step": 630
    },
    {
      "epoch": 0.64,
      "grad_norm": 16.375,
      "learning_rate": 9.63758389261745e-05,
      "loss": 6.2146,
      "step": 640
    },
    {
      "epoch": 0.65,
      "grad_norm": 6.25,
      "learning_rate": 9.630872483221477e-05,
      "loss": 4.2016,
      "step": 650
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.0,
      "learning_rate": 9.624161073825504e-05,
      "loss": 4.6716,
      "step": 660
    },
    {
      "epoch": 0.67,
      "grad_norm": 7.25,
      "learning_rate": 9.617449664429531e-05,
      "loss": 4.4125,
      "step": 670
    },
    {
      "epoch": 0.68,
      "grad_norm": 13.4375,
      "learning_rate": 9.610738255033557e-05,
      "loss": 5.5359,
      "step": 680
    },
    {
      "epoch": 0.69,
      "grad_norm": 11.6875,
      "learning_rate": 9.604026845637584e-05,
      "loss": 6.1008,
      "step": 690
    },
    {
      "epoch": 0.7,
      "grad_norm": 10.6875,
      "learning_rate": 9.59731543624161e-05,
      "loss": 6.4125,
      "step": 700
    },
    {
      "epoch": 0.71,
      "grad_norm": 15.75,
      "learning_rate": 9.590604026845637e-05,
      "loss": 3.7672,
      "step": 710
    },
    {
      "epoch": 0.72,
      "grad_norm": 11.125,
      "learning_rate": 9.583892617449665e-05,
      "loss": 5.7594,
      "step": 720
    },
    {
      "epoch": 0.73,
      "grad_norm": 13.0,
      "learning_rate": 9.577181208053692e-05,
      "loss": 4.8906,
      "step": 730
    },
    {
      "epoch": 0.74,
      "grad_norm": 5.9375,
      "learning_rate": 9.570469798657719e-05,
      "loss": 3.9781,
      "step": 740
    },
    {
      "epoch": 0.75,
      "grad_norm": 13.375,
      "learning_rate": 9.563758389261745e-05,
      "loss": 5.4102,
      "step": 750
    },
    {
      "epoch": 0.76,
      "grad_norm": 5.65625,
      "learning_rate": 9.557046979865772e-05,
      "loss": 4.9719,
      "step": 760
    },
    {
      "epoch": 0.77,
      "grad_norm": 6.3125,
      "learning_rate": 9.550335570469799e-05,
      "loss": 4.7547,
      "step": 770
    },
    {
      "epoch": 0.78,
      "grad_norm": 5.625,
      "learning_rate": 9.543624161073826e-05,
      "loss": 5.1297,
      "step": 780
    },
    {
      "epoch": 0.79,
      "grad_norm": 15.1875,
      "learning_rate": 9.536912751677852e-05,
      "loss": 4.8219,
      "step": 790
    },
    {
      "epoch": 0.8,
      "grad_norm": 5.71875,
      "learning_rate": 9.53020134228188e-05,
      "loss": 4.0359,
      "step": 800
    },
    {
      "epoch": 0.81,
      "grad_norm": 5.90625,
      "learning_rate": 9.523489932885907e-05,
      "loss": 4.9016,
      "step": 810
    },
    {
      "epoch": 0.82,
      "grad_norm": 8.75,
      "learning_rate": 9.516778523489933e-05,
      "loss": 5.3906,
      "step": 820
    },
    {
      "epoch": 0.83,
      "grad_norm": 11.75,
      "learning_rate": 9.51006711409396e-05,
      "loss": 5.6906,
      "step": 830
    },
    {
      "epoch": 0.84,
      "grad_norm": 8.625,
      "learning_rate": 9.503355704697987e-05,
      "loss": 6.1484,
      "step": 840
    },
    {
      "epoch": 0.85,
      "grad_norm": 6.46875,
      "learning_rate": 9.496644295302014e-05,
      "loss": 3.6266,
      "step": 850
    },
    {
      "epoch": 0.86,
      "grad_norm": 16.0,
      "learning_rate": 9.489932885906041e-05,
      "loss": 5.8445,
      "step": 860
    },
    {
      "epoch": 0.87,
      "grad_norm": 13.8125,
      "learning_rate": 9.483221476510069e-05,
      "loss": 6.1359,
      "step": 870
    },
    {
      "epoch": 0.88,
      "grad_norm": 8.25,
      "learning_rate": 9.476510067114094e-05,
      "loss": 5.7938,
      "step": 880
    },
    {
      "epoch": 0.89,
      "grad_norm": 7.53125,
      "learning_rate": 9.46979865771812e-05,
      "loss": 5.9469,
      "step": 890
    },
    {
      "epoch": 0.9,
      "grad_norm": 10.75,
      "learning_rate": 9.463087248322147e-05,
      "loss": 5.7031,
      "step": 900
    },
    {
      "epoch": 0.91,
      "grad_norm": 9.5625,
      "learning_rate": 9.456375838926175e-05,
      "loss": 5.4453,
      "step": 910
    },
    {
      "epoch": 0.92,
      "grad_norm": 9.4375,
      "learning_rate": 9.449664429530202e-05,
      "loss": 6.5976,
      "step": 920
    },
    {
      "epoch": 0.93,
      "grad_norm": 5.15625,
      "learning_rate": 9.442953020134229e-05,
      "loss": 5.7047,
      "step": 930
    },
    {
      "epoch": 0.94,
      "grad_norm": 8.5625,
      "learning_rate": 9.436241610738256e-05,
      "loss": 5.3273,
      "step": 940
    },
    {
      "epoch": 0.95,
      "grad_norm": 14.3125,
      "learning_rate": 9.429530201342282e-05,
      "loss": 6.1094,
      "step": 950
    },
    {
      "epoch": 0.96,
      "grad_norm": 6.90625,
      "learning_rate": 9.422818791946309e-05,
      "loss": 3.7018,
      "step": 960
    },
    {
      "epoch": 0.97,
      "grad_norm": 6.8125,
      "learning_rate": 9.416107382550336e-05,
      "loss": 3.7406,
      "step": 970
    },
    {
      "epoch": 0.98,
      "grad_norm": 11.25,
      "learning_rate": 9.409395973154362e-05,
      "loss": 4.3719,
      "step": 980
    },
    {
      "epoch": 0.99,
      "grad_norm": 7.46875,
      "learning_rate": 9.40268456375839e-05,
      "loss": 4.682,
      "step": 990
    },
    {
      "epoch": 1.0,
      "grad_norm": 12.3125,
      "learning_rate": 9.395973154362417e-05,
      "loss": 3.9414,
      "step": 1000
    },
    {
      "epoch": 1.0,
      "eval_loss": 5.111015796661377,
      "eval_runtime": 23.9865,
      "eval_samples_per_second": 4.169,
      "eval_steps_per_second": 4.169,
      "step": 1000
    },
    {
      "epoch": 1.01,
      "grad_norm": 12.3125,
      "learning_rate": 9.389261744966444e-05,
      "loss": 4.7367,
      "step": 1010
    },
    {
      "epoch": 1.02,
      "grad_norm": 14.375,
      "learning_rate": 9.38255033557047e-05,
      "loss": 5.9609,
      "step": 1020
    },
    {
      "epoch": 1.03,
      "grad_norm": 4.9375,
      "learning_rate": 9.375838926174497e-05,
      "loss": 4.6082,
      "step": 1030
    },
    {
      "epoch": 1.04,
      "grad_norm": 5.5625,
      "learning_rate": 9.369127516778524e-05,
      "loss": 4.3641,
      "step": 1040
    },
    {
      "epoch": 1.05,
      "grad_norm": 14.25,
      "learning_rate": 9.362416107382551e-05,
      "loss": 4.8964,
      "step": 1050
    },
    {
      "epoch": 1.06,
      "grad_norm": 5.0625,
      "learning_rate": 9.355704697986578e-05,
      "loss": 4.382,
      "step": 1060
    },
    {
      "epoch": 1.07,
      "grad_norm": 10.5625,
      "learning_rate": 9.348993288590604e-05,
      "loss": 6.4375,
      "step": 1070
    },
    {
      "epoch": 1.08,
      "grad_norm": 5.5625,
      "learning_rate": 9.342281879194631e-05,
      "loss": 4.6305,
      "step": 1080
    },
    {
      "epoch": 1.09,
      "grad_norm": 6.75,
      "learning_rate": 9.335570469798657e-05,
      "loss": 4.1469,
      "step": 1090
    },
    {
      "epoch": 1.1,
      "grad_norm": 6.25,
      "learning_rate": 9.328859060402684e-05,
      "loss": 4.5117,
      "step": 1100
    },
    {
      "epoch": 1.11,
      "grad_norm": 9.0,
      "learning_rate": 9.322147651006712e-05,
      "loss": 4.3109,
      "step": 1110
    },
    {
      "epoch": 1.12,
      "grad_norm": 7.65625,
      "learning_rate": 9.315436241610739e-05,
      "loss": 4.5984,
      "step": 1120
    },
    {
      "epoch": 1.13,
      "grad_norm": 7.09375,
      "learning_rate": 9.308724832214766e-05,
      "loss": 5.3773,
      "step": 1130
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 7.84375,
      "learning_rate": 9.302013422818793e-05,
      "loss": 5.3906,
      "step": 1140
    },
    {
      "epoch": 1.15,
      "grad_norm": 5.03125,
      "learning_rate": 9.295302013422819e-05,
      "loss": 5.2781,
      "step": 1150
    },
    {
      "epoch": 1.16,
      "grad_norm": 5.34375,
      "learning_rate": 9.288590604026846e-05,
      "loss": 4.107,
      "step": 1160
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.0,
      "learning_rate": 9.281879194630872e-05,
      "loss": 5.0291,
      "step": 1170
    },
    {
      "epoch": 1.18,
      "grad_norm": 5.34375,
      "learning_rate": 9.275167785234899e-05,
      "loss": 6.1117,
      "step": 1180
    },
    {
      "epoch": 1.19,
      "grad_norm": 5.0625,
      "learning_rate": 9.268456375838926e-05,
      "loss": 3.5578,
      "step": 1190
    },
    {
      "epoch": 1.2,
      "grad_norm": 7.0625,
      "learning_rate": 9.261744966442954e-05,
      "loss": 4.2417,
      "step": 1200
    },
    {
      "epoch": 1.21,
      "grad_norm": 9.0625,
      "learning_rate": 9.255033557046981e-05,
      "loss": 5.2,
      "step": 1210
    },
    {
      "epoch": 1.22,
      "grad_norm": 5.71875,
      "learning_rate": 9.248322147651008e-05,
      "loss": 5.4297,
      "step": 1220
    },
    {
      "epoch": 1.23,
      "grad_norm": 13.0,
      "learning_rate": 9.241610738255034e-05,
      "loss": 4.0977,
      "step": 1230
    },
    {
      "epoch": 1.24,
      "grad_norm": 7.125,
      "learning_rate": 9.234899328859061e-05,
      "loss": 5.8219,
      "step": 1240
    },
    {
      "epoch": 1.25,
      "grad_norm": 5.34375,
      "learning_rate": 9.228187919463087e-05,
      "loss": 3.8297,
      "step": 1250
    },
    {
      "epoch": 1.26,
      "grad_norm": 7.65625,
      "learning_rate": 9.221476510067114e-05,
      "loss": 6.5266,
      "step": 1260
    },
    {
      "epoch": 1.27,
      "grad_norm": 6.34375,
      "learning_rate": 9.214765100671141e-05,
      "loss": 4.9719,
      "step": 1270
    },
    {
      "epoch": 1.28,
      "grad_norm": 7.3125,
      "learning_rate": 9.208053691275168e-05,
      "loss": 3.8586,
      "step": 1280
    },
    {
      "epoch": 1.29,
      "grad_norm": 14.4375,
      "learning_rate": 9.201342281879196e-05,
      "loss": 5.3328,
      "step": 1290
    },
    {
      "epoch": 1.3,
      "grad_norm": 5.40625,
      "learning_rate": 9.194630872483221e-05,
      "loss": 4.1109,
      "step": 1300
    },
    {
      "epoch": 1.31,
      "grad_norm": 5.78125,
      "learning_rate": 9.187919463087249e-05,
      "loss": 5.3234,
      "step": 1310
    },
    {
      "epoch": 1.32,
      "grad_norm": 16.375,
      "learning_rate": 9.181208053691276e-05,
      "loss": 5.3047,
      "step": 1320
    },
    {
      "epoch": 1.33,
      "grad_norm": 15.5625,
      "learning_rate": 9.174496644295303e-05,
      "loss": 4.1445,
      "step": 1330
    },
    {
      "epoch": 1.34,
      "grad_norm": 11.0625,
      "learning_rate": 9.16778523489933e-05,
      "loss": 7.09,
      "step": 1340
    },
    {
      "epoch": 1.35,
      "grad_norm": 5.40625,
      "learning_rate": 9.161073825503356e-05,
      "loss": 4.4031,
      "step": 1350
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 11.6875,
      "learning_rate": 9.154362416107383e-05,
      "loss": 6.4031,
      "step": 1360
    },
    {
      "epoch": 1.37,
      "grad_norm": 16.125,
      "learning_rate": 9.147651006711409e-05,
      "loss": 5.2422,
      "step": 1370
    },
    {
      "epoch": 1.38,
      "grad_norm": 6.125,
      "learning_rate": 9.140939597315436e-05,
      "loss": 4.6391,
      "step": 1380
    },
    {
      "epoch": 1.3900000000000001,
      "grad_norm": 10.9375,
      "learning_rate": 9.134228187919464e-05,
      "loss": 5.2758,
      "step": 1390
    },
    {
      "epoch": 1.4,
      "grad_norm": 7.4375,
      "learning_rate": 9.127516778523491e-05,
      "loss": 5.4406,
      "step": 1400
    },
    {
      "epoch": 1.41,
      "grad_norm": 9.75,
      "learning_rate": 9.120805369127518e-05,
      "loss": 3.1094,
      "step": 1410
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.0,
      "learning_rate": 9.114093959731545e-05,
      "loss": 3.7675,
      "step": 1420
    },
    {
      "epoch": 1.43,
      "grad_norm": 4.8125,
      "learning_rate": 9.107382550335571e-05,
      "loss": 4.5594,
      "step": 1430
    },
    {
      "epoch": 1.44,
      "grad_norm": 4.6875,
      "learning_rate": 9.100671140939597e-05,
      "loss": 5.3977,
      "step": 1440
    },
    {
      "epoch": 1.45,
      "grad_norm": 13.4375,
      "learning_rate": 9.093959731543624e-05,
      "loss": 4.3492,
      "step": 1450
    },
    {
      "epoch": 1.46,
      "grad_norm": 6.375,
      "learning_rate": 9.087248322147651e-05,
      "loss": 4.2484,
      "step": 1460
    },
    {
      "epoch": 1.47,
      "grad_norm": 6.71875,
      "learning_rate": 9.080536912751678e-05,
      "loss": 5.1797,
      "step": 1470
    },
    {
      "epoch": 1.48,
      "grad_norm": 13.3125,
      "learning_rate": 9.073825503355706e-05,
      "loss": 4.8063,
      "step": 1480
    },
    {
      "epoch": 1.49,
      "grad_norm": 34.0,
      "learning_rate": 9.067114093959733e-05,
      "loss": 4.1948,
      "step": 1490
    },
    {
      "epoch": 1.5,
      "grad_norm": 22.875,
      "learning_rate": 9.060402684563759e-05,
      "loss": 5.5109,
      "step": 1500
    },
    {
      "epoch": 1.51,
      "grad_norm": 9.625,
      "learning_rate": 9.053691275167786e-05,
      "loss": 5.6,
      "step": 1510
    },
    {
      "epoch": 1.52,
      "grad_norm": 5.125,
      "learning_rate": 9.046979865771813e-05,
      "loss": 4.1312,
      "step": 1520
    },
    {
      "epoch": 1.53,
      "grad_norm": 7.75,
      "learning_rate": 9.040268456375839e-05,
      "loss": 5.075,
      "step": 1530
    },
    {
      "epoch": 1.54,
      "grad_norm": 13.25,
      "learning_rate": 9.033557046979866e-05,
      "loss": 6.0484,
      "step": 1540
    },
    {
      "epoch": 1.55,
      "grad_norm": 14.0625,
      "learning_rate": 9.026845637583893e-05,
      "loss": 7.1094,
      "step": 1550
    },
    {
      "epoch": 1.56,
      "grad_norm": 8.375,
      "learning_rate": 9.02013422818792e-05,
      "loss": 4.7539,
      "step": 1560
    },
    {
      "epoch": 1.5699999999999998,
      "grad_norm": 10.375,
      "learning_rate": 9.013422818791946e-05,
      "loss": 6.3063,
      "step": 1570
    },
    {
      "epoch": 1.58,
      "grad_norm": 13.4375,
      "learning_rate": 9.006711409395973e-05,
      "loss": 5.0469,
      "step": 1580
    },
    {
      "epoch": 1.5899999999999999,
      "grad_norm": 4.84375,
      "learning_rate": 9e-05,
      "loss": 3.4406,
      "step": 1590
    },
    {
      "epoch": 1.6,
      "grad_norm": 15.3125,
      "learning_rate": 8.993288590604028e-05,
      "loss": 4.6539,
      "step": 1600
    },
    {
      "epoch": 1.6099999999999999,
      "grad_norm": 7.96875,
      "learning_rate": 8.986577181208055e-05,
      "loss": 6.0406,
      "step": 1610
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.0,
      "learning_rate": 8.979865771812081e-05,
      "loss": 4.4791,
      "step": 1620
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.0,
      "learning_rate": 8.973154362416108e-05,
      "loss": 6.6619,
      "step": 1630
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 10.625,
      "learning_rate": 8.966442953020134e-05,
      "loss": 4.8247,
      "step": 1640
    },
    {
      "epoch": 1.65,
      "grad_norm": 5.78125,
      "learning_rate": 8.959731543624161e-05,
      "loss": 4.2945,
      "step": 1650
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 9.125,
      "learning_rate": 8.953020134228188e-05,
      "loss": 3.7211,
      "step": 1660
    },
    {
      "epoch": 1.67,
      "grad_norm": 5.28125,
      "learning_rate": 8.946308724832215e-05,
      "loss": 3.7766,
      "step": 1670
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 4.90625,
      "learning_rate": 8.939597315436243e-05,
      "loss": 3.9516,
      "step": 1680
    },
    {
      "epoch": 1.69,
      "grad_norm": 4.625,
      "learning_rate": 8.93288590604027e-05,
      "loss": 6.1835,
      "step": 1690
    },
    {
      "epoch": 1.7,
      "grad_norm": 4.90625,
      "learning_rate": 8.926174496644296e-05,
      "loss": 3.6558,
      "step": 1700
    },
    {
      "epoch": 1.71,
      "grad_norm": 4.125,
      "learning_rate": 8.919463087248321e-05,
      "loss": 5.4945,
      "step": 1710
    },
    {
      "epoch": 1.72,
      "grad_norm": 5.1875,
      "learning_rate": 8.912751677852349e-05,
      "loss": 3.6297,
      "step": 1720
    },
    {
      "epoch": 1.73,
      "grad_norm": 7.34375,
      "learning_rate": 8.906040268456376e-05,
      "loss": 5.0367,
      "step": 1730
    },
    {
      "epoch": 1.74,
      "grad_norm": 7.3125,
      "learning_rate": 8.899328859060403e-05,
      "loss": 4.9562,
      "step": 1740
    },
    {
      "epoch": 1.75,
      "grad_norm": 7.5625,
      "learning_rate": 8.89261744966443e-05,
      "loss": 3.2016,
      "step": 1750
    },
    {
      "epoch": 1.76,
      "grad_norm": 4.78125,
      "learning_rate": 8.885906040268457e-05,
      "loss": 5.8058,
      "step": 1760
    },
    {
      "epoch": 1.77,
      "grad_norm": 6.28125,
      "learning_rate": 8.879194630872483e-05,
      "loss": 3.8008,
      "step": 1770
    },
    {
      "epoch": 1.78,
      "grad_norm": 11.0625,
      "learning_rate": 8.87248322147651e-05,
      "loss": 6.2203,
      "step": 1780
    },
    {
      "epoch": 1.79,
      "grad_norm": 14.375,
      "learning_rate": 8.865771812080538e-05,
      "loss": 6.0977,
      "step": 1790
    },
    {
      "epoch": 1.8,
      "grad_norm": 11.6875,
      "learning_rate": 8.859060402684565e-05,
      "loss": 7.9484,
      "step": 1800
    },
    {
      "epoch": 1.81,
      "grad_norm": 17.625,
      "learning_rate": 8.85234899328859e-05,
      "loss": 3.6266,
      "step": 1810
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 10.875,
      "learning_rate": 8.845637583892618e-05,
      "loss": 4.4272,
      "step": 1820
    },
    {
      "epoch": 1.83,
      "grad_norm": 11.1875,
      "learning_rate": 8.838926174496645e-05,
      "loss": 4.725,
      "step": 1830
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 4.625,
      "learning_rate": 8.832214765100671e-05,
      "loss": 3.4875,
      "step": 1840
    },
    {
      "epoch": 1.85,
      "grad_norm": 4.65625,
      "learning_rate": 8.825503355704698e-05,
      "loss": 5.0211,
      "step": 1850
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 5.8125,
      "learning_rate": 8.818791946308725e-05,
      "loss": 4.6922,
      "step": 1860
    },
    {
      "epoch": 1.87,
      "grad_norm": 6.9375,
      "learning_rate": 8.812080536912752e-05,
      "loss": 5.8141,
      "step": 1870
    },
    {
      "epoch": 1.88,
      "grad_norm": 5.78125,
      "learning_rate": 8.80536912751678e-05,
      "loss": 5.3406,
      "step": 1880
    },
    {
      "epoch": 1.8900000000000001,
      "grad_norm": 4.53125,
      "learning_rate": 8.798657718120807e-05,
      "loss": 3.7617,
      "step": 1890
    },
    {
      "epoch": 1.9,
      "grad_norm": 7.25,
      "learning_rate": 8.791946308724833e-05,
      "loss": 6.9773,
      "step": 1900
    },
    {
      "epoch": 1.9100000000000001,
      "grad_norm": 12.75,
      "learning_rate": 8.785234899328859e-05,
      "loss": 5.834,
      "step": 1910
    },
    {
      "epoch": 1.92,
      "grad_norm": 4.53125,
      "learning_rate": 8.778523489932886e-05,
      "loss": 5.7156,
      "step": 1920
    },
    {
      "epoch": 1.9300000000000002,
      "grad_norm": 5.53125,
      "learning_rate": 8.771812080536913e-05,
      "loss": 5.2328,
      "step": 1930
    },
    {
      "epoch": 1.94,
      "grad_norm": 4.59375,
      "learning_rate": 8.76510067114094e-05,
      "loss": 5.0422,
      "step": 1940
    },
    {
      "epoch": 1.95,
      "grad_norm": 16.5,
      "learning_rate": 8.758389261744967e-05,
      "loss": 5.1266,
      "step": 1950
    },
    {
      "epoch": 1.96,
      "grad_norm": 4.46875,
      "learning_rate": 8.751677852348994e-05,
      "loss": 4.4055,
      "step": 1960
    },
    {
      "epoch": 1.97,
      "grad_norm": 5.875,
      "learning_rate": 8.74496644295302e-05,
      "loss": 3.6906,
      "step": 1970
    },
    {
      "epoch": 1.98,
      "grad_norm": 10.25,
      "learning_rate": 8.738255033557047e-05,
      "loss": 5.0656,
      "step": 1980
    },
    {
      "epoch": 1.99,
      "grad_norm": 12.625,
      "learning_rate": 8.731543624161073e-05,
      "loss": 5.6732,
      "step": 1990
    },
    {
      "epoch": 2.0,
      "grad_norm": 12.5,
      "learning_rate": 8.7248322147651e-05,
      "loss": 5.4094,
      "step": 2000
    },
    {
      "epoch": 2.0,
      "eval_loss": 4.868906021118164,
      "eval_runtime": 23.9895,
      "eval_samples_per_second": 4.168,
      "eval_steps_per_second": 4.168,
      "step": 2000
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.0,
      "learning_rate": 8.718120805369128e-05,
      "loss": 3.0516,
      "step": 2010
    },
    {
      "epoch": 2.02,
      "grad_norm": 9.3125,
      "learning_rate": 8.711409395973155e-05,
      "loss": 3.7314,
      "step": 2020
    },
    {
      "epoch": 2.03,
      "grad_norm": 7.25,
      "learning_rate": 8.704697986577182e-05,
      "loss": 4.2969,
      "step": 2030
    },
    {
      "epoch": 2.04,
      "grad_norm": 6.59375,
      "learning_rate": 8.697986577181208e-05,
      "loss": 2.6078,
      "step": 2040
    },
    {
      "epoch": 2.05,
      "grad_norm": 6.78125,
      "learning_rate": 8.691275167785235e-05,
      "loss": 4.4315,
      "step": 2050
    },
    {
      "epoch": 2.06,
      "grad_norm": 12.6875,
      "learning_rate": 8.684563758389262e-05,
      "loss": 5.3187,
      "step": 2060
    },
    {
      "epoch": 2.07,
      "grad_norm": 4.84375,
      "learning_rate": 8.67785234899329e-05,
      "loss": 3.243,
      "step": 2070
    },
    {
      "epoch": 2.08,
      "grad_norm": 7.0625,
      "learning_rate": 8.671140939597315e-05,
      "loss": 5.0836,
      "step": 2080
    },
    {
      "epoch": 2.09,
      "grad_norm": 11.4375,
      "learning_rate": 8.664429530201343e-05,
      "loss": 4.1672,
      "step": 2090
    },
    {
      "epoch": 2.1,
      "grad_norm": 6.9375,
      "learning_rate": 8.65771812080537e-05,
      "loss": 3.9406,
      "step": 2100
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.0,
      "learning_rate": 8.651006711409396e-05,
      "loss": 4.1877,
      "step": 2110
    },
    {
      "epoch": 2.12,
      "grad_norm": 12.4375,
      "learning_rate": 8.644295302013423e-05,
      "loss": 5.0016,
      "step": 2120
    },
    {
      "epoch": 2.13,
      "grad_norm": 11.5,
      "learning_rate": 8.63758389261745e-05,
      "loss": 5.4594,
      "step": 2130
    },
    {
      "epoch": 2.14,
      "grad_norm": 4.96875,
      "learning_rate": 8.630872483221477e-05,
      "loss": 5.4406,
      "step": 2140
    },
    {
      "epoch": 2.15,
      "grad_norm": 14.5,
      "learning_rate": 8.624161073825504e-05,
      "loss": 5.7359,
      "step": 2150
    },
    {
      "epoch": 2.16,
      "grad_norm": 17.25,
      "learning_rate": 8.617449664429532e-05,
      "loss": 4.193,
      "step": 2160
    },
    {
      "epoch": 2.17,
      "grad_norm": 14.375,
      "learning_rate": 8.610738255033557e-05,
      "loss": 4.7617,
      "step": 2170
    },
    {
      "epoch": 2.18,
      "grad_norm": 7.9375,
      "learning_rate": 8.604026845637583e-05,
      "loss": 5.5781,
      "step": 2180
    },
    {
      "epoch": 2.19,
      "grad_norm": 15.0625,
      "learning_rate": 8.59731543624161e-05,
      "loss": 5.5734,
      "step": 2190
    },
    {
      "epoch": 2.2,
      "grad_norm": 5.65625,
      "learning_rate": 8.590604026845638e-05,
      "loss": 4.9219,
      "step": 2200
    },
    {
      "epoch": 2.21,
      "grad_norm": 13.125,
      "learning_rate": 8.583892617449665e-05,
      "loss": 4.0805,
      "step": 2210
    },
    {
      "epoch": 2.22,
      "grad_norm": 18.125,
      "learning_rate": 8.577181208053692e-05,
      "loss": 5.6609,
      "step": 2220
    },
    {
      "epoch": 2.23,
      "grad_norm": 6.03125,
      "learning_rate": 8.570469798657719e-05,
      "loss": 4.2109,
      "step": 2230
    },
    {
      "epoch": 2.24,
      "grad_norm": 5.84375,
      "learning_rate": 8.563758389261745e-05,
      "loss": 4.9062,
      "step": 2240
    },
    {
      "epoch": 2.25,
      "grad_norm": 22.25,
      "learning_rate": 8.557046979865772e-05,
      "loss": 3.5891,
      "step": 2250
    },
    {
      "epoch": 2.26,
      "grad_norm": 22.75,
      "learning_rate": 8.5503355704698e-05,
      "loss": 5.3906,
      "step": 2260
    },
    {
      "epoch": 2.27,
      "grad_norm": 13.0625,
      "learning_rate": 8.543624161073825e-05,
      "loss": 4.9703,
      "step": 2270
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 4.78125,
      "learning_rate": 8.536912751677852e-05,
      "loss": 3.8367,
      "step": 2280
    },
    {
      "epoch": 2.29,
      "grad_norm": 14.6875,
      "learning_rate": 8.53020134228188e-05,
      "loss": 4.3945,
      "step": 2290
    },
    {
      "epoch": 2.3,
      "grad_norm": 13.6875,
      "learning_rate": 8.523489932885907e-05,
      "loss": 5.618,
      "step": 2300
    },
    {
      "epoch": 2.31,
      "grad_norm": 5.0,
      "learning_rate": 8.516778523489934e-05,
      "loss": 3.2773,
      "step": 2310
    },
    {
      "epoch": 2.32,
      "grad_norm": 14.1875,
      "learning_rate": 8.51006711409396e-05,
      "loss": 3.5688,
      "step": 2320
    },
    {
      "epoch": 2.33,
      "grad_norm": 13.0,
      "learning_rate": 8.503355704697987e-05,
      "loss": 5.2469,
      "step": 2330
    },
    {
      "epoch": 2.34,
      "grad_norm": 7.0,
      "learning_rate": 8.496644295302014e-05,
      "loss": 4.7352,
      "step": 2340
    },
    {
      "epoch": 2.35,
      "grad_norm": 4.78125,
      "learning_rate": 8.489932885906041e-05,
      "loss": 4.4719,
      "step": 2350
    },
    {
      "epoch": 2.36,
      "grad_norm": 4.96875,
      "learning_rate": 8.483221476510067e-05,
      "loss": 2.5682,
      "step": 2360
    },
    {
      "epoch": 2.37,
      "grad_norm": 16.375,
      "learning_rate": 8.476510067114094e-05,
      "loss": 6.1982,
      "step": 2370
    },
    {
      "epoch": 2.38,
      "grad_norm": 6.28125,
      "learning_rate": 8.469798657718122e-05,
      "loss": 5.5391,
      "step": 2380
    },
    {
      "epoch": 2.39,
      "grad_norm": 13.8125,
      "learning_rate": 8.463087248322147e-05,
      "loss": 4.6711,
      "step": 2390
    },
    {
      "epoch": 2.4,
      "grad_norm": 4.6875,
      "learning_rate": 8.456375838926175e-05,
      "loss": 4.6703,
      "step": 2400
    },
    {
      "epoch": 2.41,
      "grad_norm": 7.09375,
      "learning_rate": 8.449664429530202e-05,
      "loss": 3.7062,
      "step": 2410
    },
    {
      "epoch": 2.42,
      "grad_norm": 5.03125,
      "learning_rate": 8.442953020134229e-05,
      "loss": 3.7906,
      "step": 2420
    },
    {
      "epoch": 2.43,
      "grad_norm": 7.84375,
      "learning_rate": 8.436241610738256e-05,
      "loss": 3.4469,
      "step": 2430
    },
    {
      "epoch": 2.44,
      "grad_norm": 7.84375,
      "learning_rate": 8.429530201342283e-05,
      "loss": 5.1519,
      "step": 2440
    },
    {
      "epoch": 2.45,
      "grad_norm": 5.1875,
      "learning_rate": 8.422818791946309e-05,
      "loss": 4.693,
      "step": 2450
    },
    {
      "epoch": 2.46,
      "grad_norm": 5.0625,
      "learning_rate": 8.416107382550335e-05,
      "loss": 5.1445,
      "step": 2460
    },
    {
      "epoch": 2.4699999999999998,
      "grad_norm": 14.1875,
      "learning_rate": 8.409395973154362e-05,
      "loss": 4.3672,
      "step": 2470
    },
    {
      "epoch": 2.48,
      "grad_norm": 9.3125,
      "learning_rate": 8.40268456375839e-05,
      "loss": 5.3906,
      "step": 2480
    },
    {
      "epoch": 2.49,
      "grad_norm": 22.5,
      "learning_rate": 8.395973154362417e-05,
      "loss": 5.9594,
      "step": 2490
    },
    {
      "epoch": 2.5,
      "grad_norm": 18.0,
      "learning_rate": 8.389261744966444e-05,
      "loss": 5.325,
      "step": 2500
    },
    {
      "epoch": 2.51,
      "grad_norm": 16.25,
      "learning_rate": 8.382550335570471e-05,
      "loss": 3.1945,
      "step": 2510
    },
    {
      "epoch": 2.52,
      "grad_norm": 7.3125,
      "learning_rate": 8.375838926174497e-05,
      "loss": 4.2633,
      "step": 2520
    },
    {
      "epoch": 2.5300000000000002,
      "grad_norm": 9.125,
      "learning_rate": 8.369127516778524e-05,
      "loss": 5.5758,
      "step": 2530
    },
    {
      "epoch": 2.54,
      "grad_norm": 5.71875,
      "learning_rate": 8.36241610738255e-05,
      "loss": 4.2687,
      "step": 2540
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.0,
      "learning_rate": 8.355704697986577e-05,
      "loss": 3.1677,
      "step": 2550
    },
    {
      "epoch": 2.56,
      "grad_norm": 5.25,
      "learning_rate": 8.348993288590604e-05,
      "loss": 4.4227,
      "step": 2560
    },
    {
      "epoch": 2.57,
      "grad_norm": 9.25,
      "learning_rate": 8.342281879194631e-05,
      "loss": 4.7398,
      "step": 2570
    },
    {
      "epoch": 2.58,
      "grad_norm": 5.6875,
      "learning_rate": 8.335570469798659e-05,
      "loss": 3.95,
      "step": 2580
    },
    {
      "epoch": 2.59,
      "grad_norm": 13.5,
      "learning_rate": 8.328859060402685e-05,
      "loss": 5.2969,
      "step": 2590
    },
    {
      "epoch": 2.6,
      "grad_norm": 5.375,
      "learning_rate": 8.322147651006712e-05,
      "loss": 2.8808,
      "step": 2600
    },
    {
      "epoch": 2.61,
      "grad_norm": 5.75,
      "learning_rate": 8.315436241610739e-05,
      "loss": 5.175,
      "step": 2610
    },
    {
      "epoch": 2.62,
      "grad_norm": 14.6875,
      "learning_rate": 8.308724832214766e-05,
      "loss": 4.868,
      "step": 2620
    },
    {
      "epoch": 2.63,
      "grad_norm": 7.5625,
      "learning_rate": 8.302013422818792e-05,
      "loss": 5.6094,
      "step": 2630
    },
    {
      "epoch": 2.64,
      "grad_norm": 19.0,
      "learning_rate": 8.295302013422819e-05,
      "loss": 5.9906,
      "step": 2640
    },
    {
      "epoch": 2.65,
      "grad_norm": 14.25,
      "learning_rate": 8.288590604026846e-05,
      "loss": 5.4289,
      "step": 2650
    },
    {
      "epoch": 2.66,
      "grad_norm": 7.0,
      "learning_rate": 8.281879194630872e-05,
      "loss": 5.132,
      "step": 2660
    },
    {
      "epoch": 2.67,
      "grad_norm": 5.21875,
      "learning_rate": 8.2751677852349e-05,
      "loss": 4.1078,
      "step": 2670
    },
    {
      "epoch": 2.68,
      "grad_norm": 5.59375,
      "learning_rate": 8.268456375838927e-05,
      "loss": 2.8539,
      "step": 2680
    },
    {
      "epoch": 2.69,
      "grad_norm": 15.125,
      "learning_rate": 8.261744966442954e-05,
      "loss": 6.1141,
      "step": 2690
    },
    {
      "epoch": 2.7,
      "grad_norm": 7.375,
      "learning_rate": 8.255033557046981e-05,
      "loss": 3.9586,
      "step": 2700
    },
    {
      "epoch": 2.71,
      "grad_norm": 7.375,
      "learning_rate": 8.248322147651008e-05,
      "loss": 3.4061,
      "step": 2710
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 6.8125,
      "learning_rate": 8.241610738255034e-05,
      "loss": 4.5406,
      "step": 2720
    },
    {
      "epoch": 2.73,
      "grad_norm": 12.75,
      "learning_rate": 8.23489932885906e-05,
      "loss": 5.3453,
      "step": 2730
    },
    {
      "epoch": 2.74,
      "grad_norm": 5.28125,
      "learning_rate": 8.228187919463087e-05,
      "loss": 4.975,
      "step": 2740
    },
    {
      "epoch": 2.75,
      "grad_norm": 19.75,
      "learning_rate": 8.221476510067114e-05,
      "loss": 5.6914,
      "step": 2750
    },
    {
      "epoch": 2.76,
      "grad_norm": 16.75,
      "learning_rate": 8.214765100671141e-05,
      "loss": 6.1547,
      "step": 2760
    },
    {
      "epoch": 2.77,
      "grad_norm": 13.25,
      "learning_rate": 8.208053691275169e-05,
      "loss": 6.2961,
      "step": 2770
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 7.5625,
      "learning_rate": 8.201342281879196e-05,
      "loss": 3.8414,
      "step": 2780
    },
    {
      "epoch": 2.79,
      "grad_norm": 8.125,
      "learning_rate": 8.194630872483222e-05,
      "loss": 4.0883,
      "step": 2790
    },
    {
      "epoch": 2.8,
      "grad_norm": 6.09375,
      "learning_rate": 8.187919463087249e-05,
      "loss": 5.2562,
      "step": 2800
    },
    {
      "epoch": 2.81,
      "grad_norm": 6.75,
      "learning_rate": 8.181208053691276e-05,
      "loss": 6.0328,
      "step": 2810
    },
    {
      "epoch": 2.82,
      "grad_norm": 20.625,
      "learning_rate": 8.174496644295302e-05,
      "loss": 5.9234,
      "step": 2820
    },
    {
      "epoch": 2.83,
      "grad_norm": 7.21875,
      "learning_rate": 8.167785234899329e-05,
      "loss": 4.7031,
      "step": 2830
    },
    {
      "epoch": 2.84,
      "grad_norm": 6.65625,
      "learning_rate": 8.161073825503356e-05,
      "loss": 3.4242,
      "step": 2840
    },
    {
      "epoch": 2.85,
      "grad_norm": 5.78125,
      "learning_rate": 8.154362416107383e-05,
      "loss": 4.1891,
      "step": 2850
    },
    {
      "epoch": 2.86,
      "grad_norm": 6.9375,
      "learning_rate": 8.147651006711409e-05,
      "loss": 6.0359,
      "step": 2860
    },
    {
      "epoch": 2.87,
      "grad_norm": 4.90625,
      "learning_rate": 8.140939597315436e-05,
      "loss": 5.5594,
      "step": 2870
    },
    {
      "epoch": 2.88,
      "grad_norm": 4.75,
      "learning_rate": 8.134228187919464e-05,
      "loss": 3.9583,
      "step": 2880
    },
    {
      "epoch": 2.89,
      "grad_norm": 5.5,
      "learning_rate": 8.127516778523491e-05,
      "loss": 5.6414,
      "step": 2890
    },
    {
      "epoch": 2.9,
      "grad_norm": 5.5625,
      "learning_rate": 8.120805369127518e-05,
      "loss": 4.8406,
      "step": 2900
    },
    {
      "epoch": 2.91,
      "grad_norm": 16.375,
      "learning_rate": 8.114093959731544e-05,
      "loss": 4.9541,
      "step": 2910
    },
    {
      "epoch": 2.92,
      "grad_norm": 5.90625,
      "learning_rate": 8.107382550335571e-05,
      "loss": 3.8219,
      "step": 2920
    },
    {
      "epoch": 2.93,
      "grad_norm": 5.4375,
      "learning_rate": 8.100671140939597e-05,
      "loss": 3.8891,
      "step": 2930
    },
    {
      "epoch": 2.94,
      "grad_norm": 24.625,
      "learning_rate": 8.093959731543624e-05,
      "loss": 3.5406,
      "step": 2940
    },
    {
      "epoch": 2.95,
      "grad_norm": 12.0,
      "learning_rate": 8.087248322147651e-05,
      "loss": 4.5719,
      "step": 2950
    },
    {
      "epoch": 2.96,
      "grad_norm": 7.96875,
      "learning_rate": 8.080536912751678e-05,
      "loss": 4.3633,
      "step": 2960
    },
    {
      "epoch": 2.9699999999999998,
      "grad_norm": 12.0,
      "learning_rate": 8.073825503355706e-05,
      "loss": 3.7648,
      "step": 2970
    },
    {
      "epoch": 2.98,
      "grad_norm": 5.90625,
      "learning_rate": 8.067114093959733e-05,
      "loss": 4.8906,
      "step": 2980
    },
    {
      "epoch": 2.99,
      "grad_norm": 9.5,
      "learning_rate": 8.060402684563759e-05,
      "loss": 3.3695,
      "step": 2990
    },
    {
      "epoch": 3.0,
      "grad_norm": 6.625,
      "learning_rate": 8.053691275167784e-05,
      "loss": 4.5422,
      "step": 3000
    },
    {
      "epoch": 3.0,
      "eval_loss": 4.778515815734863,
      "eval_runtime": 23.9854,
      "eval_samples_per_second": 4.169,
      "eval_steps_per_second": 4.169,
      "step": 3000
    }
  ],
  "logging_steps": 10,
  "max_steps": 15000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2725297499739392e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
