{
  "best_metric": 2.633439540863037,
  "best_model_checkpoint": "./models/adapter/checkpoint-5000",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 227.0,
      "learning_rate": 3e-06,
      "loss": 12.55,
      "step": 10
    },
    {
      "epoch": 0.02,
      "grad_norm": 228.0,
      "learning_rate": 6e-06,
      "loss": 11.7937,
      "step": 20
    },
    {
      "epoch": 0.03,
      "grad_norm": 210.0,
      "learning_rate": 9e-06,
      "loss": 11.5813,
      "step": 30
    },
    {
      "epoch": 0.04,
      "grad_norm": 158.0,
      "learning_rate": 1.2e-05,
      "loss": 8.9062,
      "step": 40
    },
    {
      "epoch": 0.05,
      "grad_norm": 34.0,
      "learning_rate": 1.5e-05,
      "loss": 5.7369,
      "step": 50
    },
    {
      "epoch": 0.06,
      "grad_norm": 270.0,
      "learning_rate": 1.8e-05,
      "loss": 3.2921,
      "step": 60
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0057373046875,
      "learning_rate": 2.1e-05,
      "loss": 1.3376,
      "step": 70
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.74609375,
      "learning_rate": 2.4e-05,
      "loss": 4.7129,
      "step": 80
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.050048828125,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 3.1835,
      "step": 90
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.28125,
      "learning_rate": 3e-05,
      "loss": 4.8034,
      "step": 100
    },
    {
      "epoch": 0.11,
      "grad_norm": 82.5,
      "learning_rate": 2.9979865771812083e-05,
      "loss": 3.7285,
      "step": 110
    },
    {
      "epoch": 0.12,
      "grad_norm": 100.0,
      "learning_rate": 2.9959731543624162e-05,
      "loss": 1.8581,
      "step": 120
    },
    {
      "epoch": 0.13,
      "grad_norm": 91.0,
      "learning_rate": 2.9939597315436244e-05,
      "loss": 3.447,
      "step": 130
    },
    {
      "epoch": 0.14,
      "grad_norm": 130.0,
      "learning_rate": 2.9919463087248323e-05,
      "loss": 4.1063,
      "step": 140
    },
    {
      "epoch": 0.15,
      "grad_norm": 86.5,
      "learning_rate": 2.9899328859060402e-05,
      "loss": 4.0792,
      "step": 150
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.01336669921875,
      "learning_rate": 2.9879194630872484e-05,
      "loss": 2.5891,
      "step": 160
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.0,
      "learning_rate": 2.9859060402684563e-05,
      "loss": 0.9077,
      "step": 170
    },
    {
      "epoch": 0.18,
      "grad_norm": 76.0,
      "learning_rate": 2.9838926174496645e-05,
      "loss": 4.3725,
      "step": 180
    },
    {
      "epoch": 0.19,
      "grad_norm": 82.0,
      "learning_rate": 2.9818791946308724e-05,
      "loss": 2.4268,
      "step": 190
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.021728515625,
      "learning_rate": 2.9798657718120806e-05,
      "loss": 2.3482,
      "step": 200
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.07568359375,
      "learning_rate": 2.977852348993289e-05,
      "loss": 4.111,
      "step": 210
    },
    {
      "epoch": 0.22,
      "grad_norm": 116.0,
      "learning_rate": 2.9758389261744967e-05,
      "loss": 4.5346,
      "step": 220
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.001617431640625,
      "learning_rate": 2.973825503355705e-05,
      "loss": 2.1031,
      "step": 230
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.00145721435546875,
      "learning_rate": 2.9718120805369125e-05,
      "loss": 1.4107,
      "step": 240
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.0067138671875,
      "learning_rate": 2.9697986577181207e-05,
      "loss": 2.5602,
      "step": 250
    },
    {
      "epoch": 0.26,
      "grad_norm": 54.0,
      "learning_rate": 2.967785234899329e-05,
      "loss": 4.0078,
      "step": 260
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.07373046875,
      "learning_rate": 2.965771812080537e-05,
      "loss": 3.6595,
      "step": 270
    },
    {
      "epoch": 0.28,
      "grad_norm": 137.0,
      "learning_rate": 2.963758389261745e-05,
      "loss": 3.6299,
      "step": 280
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.2431640625,
      "learning_rate": 2.961744966442953e-05,
      "loss": 2.8736,
      "step": 290
    },
    {
      "epoch": 0.3,
      "grad_norm": 77.0,
      "learning_rate": 2.9597315436241612e-05,
      "loss": 3.6047,
      "step": 300
    },
    {
      "epoch": 0.31,
      "grad_norm": 130.0,
      "learning_rate": 2.9577181208053694e-05,
      "loss": 2.4188,
      "step": 310
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.0017547607421875,
      "learning_rate": 2.9557046979865773e-05,
      "loss": 3.9828,
      "step": 320
    },
    {
      "epoch": 0.33,
      "grad_norm": 115.5,
      "learning_rate": 2.9536912751677852e-05,
      "loss": 0.9438,
      "step": 330
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.0033721923828125,
      "learning_rate": 2.951677852348993e-05,
      "loss": 1.8531,
      "step": 340
    },
    {
      "epoch": 0.35,
      "grad_norm": 66.0,
      "learning_rate": 2.9496644295302013e-05,
      "loss": 4.6891,
      "step": 350
    },
    {
      "epoch": 0.36,
      "grad_norm": 46.25,
      "learning_rate": 2.9476510067114095e-05,
      "loss": 2.4821,
      "step": 360
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.01123046875,
      "learning_rate": 2.9456375838926174e-05,
      "loss": 5.1567,
      "step": 370
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.04345703125,
      "learning_rate": 2.9436241610738256e-05,
      "loss": 2.1345,
      "step": 380
    },
    {
      "epoch": 0.39,
      "grad_norm": 30.75,
      "learning_rate": 2.9416107382550335e-05,
      "loss": 3.0662,
      "step": 390
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.0030059814453125,
      "learning_rate": 2.9395973154362418e-05,
      "loss": 2.9043,
      "step": 400
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.01275634765625,
      "learning_rate": 2.93758389261745e-05,
      "loss": 3.8781,
      "step": 410
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.033203125,
      "learning_rate": 2.935570469798658e-05,
      "loss": 6.2313,
      "step": 420
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.0458984375,
      "learning_rate": 2.9335570469798658e-05,
      "loss": 4.9844,
      "step": 430
    },
    {
      "epoch": 0.44,
      "grad_norm": 42.25,
      "learning_rate": 2.9315436241610736e-05,
      "loss": 1.1814,
      "step": 440
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.01123046875,
      "learning_rate": 2.929530201342282e-05,
      "loss": 1.3735,
      "step": 450
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.0079345703125,
      "learning_rate": 2.92751677852349e-05,
      "loss": 1.6125,
      "step": 460
    },
    {
      "epoch": 0.47,
      "grad_norm": 93.0,
      "learning_rate": 2.925503355704698e-05,
      "loss": 2.5072,
      "step": 470
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.0162353515625,
      "learning_rate": 2.9234899328859062e-05,
      "loss": 3.9563,
      "step": 480
    },
    {
      "epoch": 0.49,
      "grad_norm": 86.0,
      "learning_rate": 2.921476510067114e-05,
      "loss": 4.4067,
      "step": 490
    },
    {
      "epoch": 0.5,
      "grad_norm": 89.5,
      "learning_rate": 2.9194630872483223e-05,
      "loss": 5.2407,
      "step": 500
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.0294189453125,
      "learning_rate": 2.9174496644295305e-05,
      "loss": 1.4251,
      "step": 510
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.0247802734375,
      "learning_rate": 2.915436241610738e-05,
      "loss": 2.511,
      "step": 520
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.00604248046875,
      "learning_rate": 2.9134228187919463e-05,
      "loss": 1.1719,
      "step": 530
    },
    {
      "epoch": 0.54,
      "grad_norm": 55.75,
      "learning_rate": 2.9114093959731542e-05,
      "loss": 3.5313,
      "step": 540
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.00885009765625,
      "learning_rate": 2.9093959731543624e-05,
      "loss": 2.3,
      "step": 550
    },
    {
      "epoch": 0.56,
      "grad_norm": 72.0,
      "learning_rate": 2.9073825503355706e-05,
      "loss": 6.1938,
      "step": 560
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.0213623046875,
      "learning_rate": 2.9053691275167785e-05,
      "loss": 3.2469,
      "step": 570
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.0,
      "learning_rate": 2.9033557046979868e-05,
      "loss": 5.39,
      "step": 580
    },
    {
      "epoch": 0.59,
      "grad_norm": 46.75,
      "learning_rate": 2.9013422818791946e-05,
      "loss": 5.45,
      "step": 590
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.0089111328125,
      "learning_rate": 2.899328859060403e-05,
      "loss": 1.4625,
      "step": 600
    },
    {
      "epoch": 0.61,
      "grad_norm": 109.0,
      "learning_rate": 2.8973154362416108e-05,
      "loss": 4.5703,
      "step": 610
    },
    {
      "epoch": 0.62,
      "grad_norm": 34.0,
      "learning_rate": 2.8953020134228186e-05,
      "loss": 2.7598,
      "step": 620
    },
    {
      "epoch": 0.63,
      "grad_norm": 104.0,
      "learning_rate": 2.893288590604027e-05,
      "loss": 4.2985,
      "step": 630
    },
    {
      "epoch": 0.64,
      "grad_norm": 104.5,
      "learning_rate": 2.891275167785235e-05,
      "loss": 5.5977,
      "step": 640
    },
    {
      "epoch": 0.65,
      "grad_norm": 37.5,
      "learning_rate": 2.889261744966443e-05,
      "loss": 1.2845,
      "step": 650
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.0,
      "learning_rate": 2.8872483221476512e-05,
      "loss": 3.5734,
      "step": 660
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.0233154296875,
      "learning_rate": 2.885234899328859e-05,
      "loss": 1.1313,
      "step": 670
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.0155029296875,
      "learning_rate": 2.8832214765100673e-05,
      "loss": 3.6961,
      "step": 680
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.01446533203125,
      "learning_rate": 2.8812080536912755e-05,
      "loss": 6.1094,
      "step": 690
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.0260009765625,
      "learning_rate": 2.879194630872483e-05,
      "loss": 2.3501,
      "step": 700
    },
    {
      "epoch": 0.71,
      "grad_norm": 107.5,
      "learning_rate": 2.8771812080536913e-05,
      "loss": 2.3688,
      "step": 710
    },
    {
      "epoch": 0.72,
      "grad_norm": 65.5,
      "learning_rate": 2.8751677852348992e-05,
      "loss": 4.1875,
      "step": 720
    },
    {
      "epoch": 0.73,
      "grad_norm": 88.0,
      "learning_rate": 2.8731543624161074e-05,
      "loss": 2.7078,
      "step": 730
    },
    {
      "epoch": 0.74,
      "grad_norm": 34.0,
      "learning_rate": 2.8711409395973157e-05,
      "loss": 4.1469,
      "step": 740
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.007415771484375,
      "learning_rate": 2.8691275167785235e-05,
      "loss": 3.1789,
      "step": 750
    },
    {
      "epoch": 0.76,
      "grad_norm": 33.5,
      "learning_rate": 2.8671140939597318e-05,
      "loss": 2.5532,
      "step": 760
    },
    {
      "epoch": 0.77,
      "grad_norm": 48.75,
      "learning_rate": 2.8651006711409397e-05,
      "loss": 2.7906,
      "step": 770
    },
    {
      "epoch": 0.78,
      "grad_norm": 35.5,
      "learning_rate": 2.863087248322148e-05,
      "loss": 2.1052,
      "step": 780
    },
    {
      "epoch": 0.79,
      "grad_norm": 97.0,
      "learning_rate": 2.8610738255033558e-05,
      "loss": 2.3108,
      "step": 790
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.006500244140625,
      "learning_rate": 2.8590604026845637e-05,
      "loss": 1.6531,
      "step": 800
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.00872802734375,
      "learning_rate": 2.857046979865772e-05,
      "loss": 3.0211,
      "step": 810
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.007171630859375,
      "learning_rate": 2.8550335570469798e-05,
      "loss": 3.6422,
      "step": 820
    },
    {
      "epoch": 0.83,
      "grad_norm": 62.5,
      "learning_rate": 2.853020134228188e-05,
      "loss": 3.9008,
      "step": 830
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.00109100341796875,
      "learning_rate": 2.8510067114093962e-05,
      "loss": 2.4938,
      "step": 840
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.001373291015625,
      "learning_rate": 2.848993288590604e-05,
      "loss": 1.6188,
      "step": 850
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.0020294189453125,
      "learning_rate": 2.8469798657718123e-05,
      "loss": 3.7813,
      "step": 860
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.00115203857421875,
      "learning_rate": 2.8449664429530202e-05,
      "loss": 2.8719,
      "step": 870
    },
    {
      "epoch": 0.88,
      "grad_norm": 42.25,
      "learning_rate": 2.8429530201342284e-05,
      "loss": 3.2031,
      "step": 880
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.007354736328125,
      "learning_rate": 2.8409395973154363e-05,
      "loss": 2.6844,
      "step": 890
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.0089111328125,
      "learning_rate": 2.8389261744966442e-05,
      "loss": 2.4485,
      "step": 900
    },
    {
      "epoch": 0.91,
      "grad_norm": 36.75,
      "learning_rate": 2.8369127516778524e-05,
      "loss": 3.0844,
      "step": 910
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.004241943359375,
      "learning_rate": 2.8348993288590603e-05,
      "loss": 2.4719,
      "step": 920
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.0033111572265625,
      "learning_rate": 2.8328859060402685e-05,
      "loss": 2.8906,
      "step": 930
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.0032958984375,
      "learning_rate": 2.8308724832214768e-05,
      "loss": 1.5906,
      "step": 940
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.0038299560546875,
      "learning_rate": 2.8288590604026847e-05,
      "loss": 1.7422,
      "step": 950
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.0037384033203125,
      "learning_rate": 2.826845637583893e-05,
      "loss": 0.6438,
      "step": 960
    },
    {
      "epoch": 0.97,
      "grad_norm": 42.75,
      "learning_rate": 2.8248322147651008e-05,
      "loss": 2.025,
      "step": 970
    },
    {
      "epoch": 0.98,
      "grad_norm": 41.5,
      "learning_rate": 2.8228187919463087e-05,
      "loss": 4.0016,
      "step": 980
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.003448486328125,
      "learning_rate": 2.820805369127517e-05,
      "loss": 2.55,
      "step": 990
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.002960205078125,
      "learning_rate": 2.8187919463087248e-05,
      "loss": 2.0829,
      "step": 1000
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.8107428550720215,
      "eval_runtime": 28.786,
      "eval_samples_per_second": 3.474,
      "eval_steps_per_second": 3.474,
      "step": 1000
    },
    {
      "epoch": 1.01,
      "grad_norm": 71.0,
      "learning_rate": 2.816778523489933e-05,
      "loss": 3.5516,
      "step": 1010
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.0103759765625,
      "learning_rate": 2.814765100671141e-05,
      "loss": 4.2141,
      "step": 1020
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.00157928466796875,
      "learning_rate": 2.812751677852349e-05,
      "loss": 2.1359,
      "step": 1030
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.0019989013671875,
      "learning_rate": 2.8107382550335573e-05,
      "loss": 1.6703,
      "step": 1040
    },
    {
      "epoch": 1.05,
      "grad_norm": 86.5,
      "learning_rate": 2.8087248322147652e-05,
      "loss": 3.6484,
      "step": 1050
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.001983642578125,
      "learning_rate": 2.8067114093959734e-05,
      "loss": 2.9609,
      "step": 1060
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.0030059814453125,
      "learning_rate": 2.804697986577181e-05,
      "loss": 2.0781,
      "step": 1070
    },
    {
      "epoch": 1.08,
      "grad_norm": 30.5,
      "learning_rate": 2.8026845637583892e-05,
      "loss": 2.4465,
      "step": 1080
    },
    {
      "epoch": 1.09,
      "grad_norm": 41.5,
      "learning_rate": 2.8006711409395974e-05,
      "loss": 1.5906,
      "step": 1090
    },
    {
      "epoch": 1.1,
      "grad_norm": 39.25,
      "learning_rate": 2.7986577181208053e-05,
      "loss": 3.1992,
      "step": 1100
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.003143310546875,
      "learning_rate": 2.7966442953020136e-05,
      "loss": 1.4916,
      "step": 1110
    },
    {
      "epoch": 1.12,
      "grad_norm": 75.0,
      "learning_rate": 2.7946308724832214e-05,
      "loss": 2.7188,
      "step": 1120
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.020263671875,
      "learning_rate": 2.7926174496644297e-05,
      "loss": 1.3906,
      "step": 1130
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 55.0,
      "learning_rate": 2.790604026845638e-05,
      "loss": 3.1029,
      "step": 1140
    },
    {
      "epoch": 1.15,
      "grad_norm": 31.625,
      "learning_rate": 2.7885906040268458e-05,
      "loss": 1.8042,
      "step": 1150
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.00081634521484375,
      "learning_rate": 2.7865771812080537e-05,
      "loss": 0.4508,
      "step": 1160
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.001373291015625,
      "learning_rate": 2.7845637583892616e-05,
      "loss": 0.5125,
      "step": 1170
    },
    {
      "epoch": 1.18,
      "grad_norm": 29.125,
      "learning_rate": 2.7825503355704698e-05,
      "loss": 2.9617,
      "step": 1180
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.007293701171875,
      "learning_rate": 2.780536912751678e-05,
      "loss": 2.0625,
      "step": 1190
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.0029296875,
      "learning_rate": 2.778523489932886e-05,
      "loss": 2.4167,
      "step": 1200
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.0047607421875,
      "learning_rate": 2.776510067114094e-05,
      "loss": 1.7219,
      "step": 1210
    },
    {
      "epoch": 1.22,
      "grad_norm": 34.75,
      "learning_rate": 2.774496644295302e-05,
      "loss": 0.5766,
      "step": 1220
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.00164794921875,
      "learning_rate": 2.7724832214765102e-05,
      "loss": 2.8922,
      "step": 1230
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.0018310546875,
      "learning_rate": 2.7704697986577185e-05,
      "loss": 3.525,
      "step": 1240
    },
    {
      "epoch": 1.25,
      "grad_norm": 29.25,
      "learning_rate": 2.768456375838926e-05,
      "loss": 2.2672,
      "step": 1250
    },
    {
      "epoch": 1.26,
      "grad_norm": 76.5,
      "learning_rate": 2.7664429530201342e-05,
      "loss": 4.0383,
      "step": 1260
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.0029144287109375,
      "learning_rate": 2.764429530201342e-05,
      "loss": 1.761,
      "step": 1270
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.0034942626953125,
      "learning_rate": 2.7624161073825503e-05,
      "loss": 1.8002,
      "step": 1280
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.003692626953125,
      "learning_rate": 2.7604026845637586e-05,
      "loss": 2.1297,
      "step": 1290
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.00518798828125,
      "learning_rate": 2.7583892617449664e-05,
      "loss": 2.2656,
      "step": 1300
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.0069580078125,
      "learning_rate": 2.7563758389261747e-05,
      "loss": 2.9703,
      "step": 1310
    },
    {
      "epoch": 1.32,
      "grad_norm": 69.0,
      "learning_rate": 2.7543624161073826e-05,
      "loss": 2.1875,
      "step": 1320
    },
    {
      "epoch": 1.33,
      "grad_norm": 70.0,
      "learning_rate": 2.7523489932885908e-05,
      "loss": 3.0656,
      "step": 1330
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.00921630859375,
      "learning_rate": 2.750335570469799e-05,
      "loss": 3.2571,
      "step": 1340
    },
    {
      "epoch": 1.35,
      "grad_norm": 23.375,
      "learning_rate": 2.7483221476510066e-05,
      "loss": 1.7594,
      "step": 1350
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.004669189453125,
      "learning_rate": 2.7463087248322148e-05,
      "loss": 2.3625,
      "step": 1360
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.00830078125,
      "learning_rate": 2.7442953020134227e-05,
      "loss": 2.7656,
      "step": 1370
    },
    {
      "epoch": 1.38,
      "grad_norm": 29.125,
      "learning_rate": 2.742281879194631e-05,
      "loss": 1.1735,
      "step": 1380
    },
    {
      "epoch": 1.3900000000000001,
      "grad_norm": 0.00982666015625,
      "learning_rate": 2.740268456375839e-05,
      "loss": 3.9094,
      "step": 1390
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.004608154296875,
      "learning_rate": 2.738255033557047e-05,
      "loss": 4.3391,
      "step": 1400
    },
    {
      "epoch": 1.41,
      "grad_norm": 59.25,
      "learning_rate": 2.7362416107382552e-05,
      "loss": 0.9453,
      "step": 1410
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.00148773193359375,
      "learning_rate": 2.734228187919463e-05,
      "loss": 2.718,
      "step": 1420
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.000904083251953125,
      "learning_rate": 2.7322147651006713e-05,
      "loss": 1.6438,
      "step": 1430
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.0016021728515625,
      "learning_rate": 2.7302013422818792e-05,
      "loss": 3.575,
      "step": 1440
    },
    {
      "epoch": 1.45,
      "grad_norm": 86.5,
      "learning_rate": 2.728187919463087e-05,
      "loss": 2.7875,
      "step": 1450
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.0024566650390625,
      "learning_rate": 2.7261744966442953e-05,
      "loss": 1.7422,
      "step": 1460
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.00119781494140625,
      "learning_rate": 2.7241610738255032e-05,
      "loss": 1.2813,
      "step": 1470
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.0,
      "learning_rate": 2.7221476510067115e-05,
      "loss": 1.968,
      "step": 1480
    },
    {
      "epoch": 1.49,
      "grad_norm": 40.5,
      "learning_rate": 2.7201342281879197e-05,
      "loss": 2.0141,
      "step": 1490
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.00396728515625,
      "learning_rate": 2.7181208053691276e-05,
      "loss": 2.0289,
      "step": 1500
    },
    {
      "epoch": 1.51,
      "grad_norm": 41.0,
      "learning_rate": 2.7161073825503358e-05,
      "loss": 2.1,
      "step": 1510
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.030029296875,
      "learning_rate": 2.7140939597315437e-05,
      "loss": 1.8157,
      "step": 1520
    },
    {
      "epoch": 1.53,
      "grad_norm": 66.0,
      "learning_rate": 2.7120805369127516e-05,
      "loss": 4.2156,
      "step": 1530
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.002105712890625,
      "learning_rate": 2.7100671140939598e-05,
      "loss": 2.1045,
      "step": 1540
    },
    {
      "epoch": 1.55,
      "grad_norm": 51.5,
      "learning_rate": 2.7080536912751677e-05,
      "loss": 2.9859,
      "step": 1550
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.0021820068359375,
      "learning_rate": 2.706040268456376e-05,
      "loss": 2.5766,
      "step": 1560
    },
    {
      "epoch": 1.5699999999999998,
      "grad_norm": 0.001373291015625,
      "learning_rate": 2.7040268456375838e-05,
      "loss": 4.4625,
      "step": 1570
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.0021820068359375,
      "learning_rate": 2.702013422818792e-05,
      "loss": 2.3469,
      "step": 1580
    },
    {
      "epoch": 1.5899999999999999,
      "grad_norm": 0.0040283203125,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 1.9727,
      "step": 1590
    },
    {
      "epoch": 1.6,
      "grad_norm": 67.5,
      "learning_rate": 2.697986577181208e-05,
      "loss": 3.2734,
      "step": 1600
    },
    {
      "epoch": 1.6099999999999999,
      "grad_norm": 0.0031280517578125,
      "learning_rate": 2.6959731543624163e-05,
      "loss": 3.3238,
      "step": 1610
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.0,
      "learning_rate": 2.6939597315436242e-05,
      "loss": 2.8591,
      "step": 1620
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.002410888671875,
      "learning_rate": 2.691946308724832e-05,
      "loss": 0.2188,
      "step": 1630
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 54.0,
      "learning_rate": 2.6899328859060403e-05,
      "loss": 1.9086,
      "step": 1640
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.0034027099609375,
      "learning_rate": 2.6879194630872482e-05,
      "loss": 2.1813,
      "step": 1650
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 64.0,
      "learning_rate": 2.6859060402684565e-05,
      "loss": 1.6781,
      "step": 1660
    },
    {
      "epoch": 1.67,
      "grad_norm": 33.75,
      "learning_rate": 2.6838926174496647e-05,
      "loss": 1.6359,
      "step": 1670
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 27.25,
      "learning_rate": 2.6818791946308726e-05,
      "loss": 2.6914,
      "step": 1680
    },
    {
      "epoch": 1.69,
      "grad_norm": 29.5,
      "learning_rate": 2.6798657718120808e-05,
      "loss": 1.8893,
      "step": 1690
    },
    {
      "epoch": 1.7,
      "grad_norm": 29.375,
      "learning_rate": 2.6778523489932887e-05,
      "loss": 2.2685,
      "step": 1700
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.009033203125,
      "learning_rate": 2.6758389261744966e-05,
      "loss": 4.2047,
      "step": 1710
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.004486083984375,
      "learning_rate": 2.6738255033557048e-05,
      "loss": 0.9031,
      "step": 1720
    },
    {
      "epoch": 1.73,
      "grad_norm": 27.5,
      "learning_rate": 2.6718120805369127e-05,
      "loss": 3.8875,
      "step": 1730
    },
    {
      "epoch": 1.74,
      "grad_norm": 40.75,
      "learning_rate": 2.669798657718121e-05,
      "loss": 4.2172,
      "step": 1740
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.002655029296875,
      "learning_rate": 2.6677852348993288e-05,
      "loss": 2.1281,
      "step": 1750
    },
    {
      "epoch": 1.76,
      "grad_norm": 30.75,
      "learning_rate": 2.665771812080537e-05,
      "loss": 2.1727,
      "step": 1760
    },
    {
      "epoch": 1.77,
      "grad_norm": 36.5,
      "learning_rate": 2.6637583892617452e-05,
      "loss": 2.2266,
      "step": 1770
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.0035858154296875,
      "learning_rate": 2.661744966442953e-05,
      "loss": 2.936,
      "step": 1780
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.004730224609375,
      "learning_rate": 2.6597315436241614e-05,
      "loss": 3.1164,
      "step": 1790
    },
    {
      "epoch": 1.8,
      "grad_norm": 62.5,
      "learning_rate": 2.6577181208053692e-05,
      "loss": 6.3906,
      "step": 1800
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.009521484375,
      "learning_rate": 2.655704697986577e-05,
      "loss": 2.4641,
      "step": 1810
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 60.0,
      "learning_rate": 2.6536912751677854e-05,
      "loss": 2.875,
      "step": 1820
    },
    {
      "epoch": 1.83,
      "grad_norm": 64.5,
      "learning_rate": 2.6516778523489932e-05,
      "loss": 3.3188,
      "step": 1830
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 25.875,
      "learning_rate": 2.6496644295302015e-05,
      "loss": 1.343,
      "step": 1840
    },
    {
      "epoch": 1.85,
      "grad_norm": 29.25,
      "learning_rate": 2.6476510067114094e-05,
      "loss": 2.5625,
      "step": 1850
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 0.002227783203125,
      "learning_rate": 2.6456375838926176e-05,
      "loss": 1.5625,
      "step": 1860
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.0027008056640625,
      "learning_rate": 2.6436241610738258e-05,
      "loss": 2.7674,
      "step": 1870
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.003997802734375,
      "learning_rate": 2.6416107382550337e-05,
      "loss": 2.2438,
      "step": 1880
    },
    {
      "epoch": 1.8900000000000001,
      "grad_norm": 31.375,
      "learning_rate": 2.639597315436242e-05,
      "loss": 2.3641,
      "step": 1890
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.005126953125,
      "learning_rate": 2.6375838926174495e-05,
      "loss": 3.1719,
      "step": 1900
    },
    {
      "epoch": 1.9100000000000001,
      "grad_norm": 81.5,
      "learning_rate": 2.6355704697986577e-05,
      "loss": 1.7625,
      "step": 1910
    },
    {
      "epoch": 1.92,
      "grad_norm": 30.125,
      "learning_rate": 2.633557046979866e-05,
      "loss": 2.5899,
      "step": 1920
    },
    {
      "epoch": 1.9300000000000002,
      "grad_norm": 36.5,
      "learning_rate": 2.6315436241610738e-05,
      "loss": 2.4234,
      "step": 1930
    },
    {
      "epoch": 1.94,
      "grad_norm": 28.875,
      "learning_rate": 2.629530201342282e-05,
      "loss": 2.4578,
      "step": 1940
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.00244140625,
      "learning_rate": 2.62751677852349e-05,
      "loss": 3.0203,
      "step": 1950
    },
    {
      "epoch": 1.96,
      "grad_norm": 30.625,
      "learning_rate": 2.625503355704698e-05,
      "loss": 2.2266,
      "step": 1960
    },
    {
      "epoch": 1.97,
      "grad_norm": 35.0,
      "learning_rate": 2.6234899328859064e-05,
      "loss": 1.1281,
      "step": 1970
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.00689697265625,
      "learning_rate": 2.6214765100671142e-05,
      "loss": 3.0625,
      "step": 1980
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.002471923828125,
      "learning_rate": 2.619463087248322e-05,
      "loss": 3.4729,
      "step": 1990
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.00836181640625,
      "learning_rate": 2.61744966442953e-05,
      "loss": 3.9102,
      "step": 2000
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.6948020458221436,
      "eval_runtime": 28.7115,
      "eval_samples_per_second": 3.483,
      "eval_steps_per_second": 3.483,
      "step": 2000
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.0,
      "learning_rate": 2.6154362416107382e-05,
      "loss": 1.253,
      "step": 2010
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.00579833984375,
      "learning_rate": 2.6134228187919465e-05,
      "loss": 2.1875,
      "step": 2020
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.26953125,
      "learning_rate": 2.6114093959731544e-05,
      "loss": 2.158,
      "step": 2030
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.002960205078125,
      "learning_rate": 2.6093959731543626e-05,
      "loss": 1.5422,
      "step": 2040
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.00135040283203125,
      "learning_rate": 2.6073825503355705e-05,
      "loss": 1.7336,
      "step": 2050
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.00101470947265625,
      "learning_rate": 2.6053691275167787e-05,
      "loss": 2.1531,
      "step": 2060
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.001922607421875,
      "learning_rate": 2.603355704697987e-05,
      "loss": 1.2859,
      "step": 2070
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.0010223388671875,
      "learning_rate": 2.6013422818791945e-05,
      "loss": 3.3164,
      "step": 2080
    },
    {
      "epoch": 2.09,
      "grad_norm": 50.75,
      "learning_rate": 2.5993288590604027e-05,
      "loss": 2.9961,
      "step": 2090
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.0019073486328125,
      "learning_rate": 2.5973154362416106e-05,
      "loss": 1.0353,
      "step": 2100
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.0013427734375,
      "learning_rate": 2.5953020134228188e-05,
      "loss": 1.6641,
      "step": 2110
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.0015716552734375,
      "learning_rate": 2.593288590604027e-05,
      "loss": 3.2422,
      "step": 2120
    },
    {
      "epoch": 2.13,
      "grad_norm": 35.75,
      "learning_rate": 2.591275167785235e-05,
      "loss": 0.7422,
      "step": 2130
    },
    {
      "epoch": 2.14,
      "grad_norm": 29.875,
      "learning_rate": 2.589261744966443e-05,
      "loss": 3.3641,
      "step": 2140
    },
    {
      "epoch": 2.15,
      "grad_norm": 62.5,
      "learning_rate": 2.587248322147651e-05,
      "loss": 3.5375,
      "step": 2150
    },
    {
      "epoch": 2.16,
      "grad_norm": 64.5,
      "learning_rate": 2.5852348993288593e-05,
      "loss": 3.2219,
      "step": 2160
    },
    {
      "epoch": 2.17,
      "grad_norm": 60.25,
      "learning_rate": 2.583221476510067e-05,
      "loss": 3.7688,
      "step": 2170
    },
    {
      "epoch": 2.18,
      "grad_norm": 42.0,
      "learning_rate": 2.581208053691275e-05,
      "loss": 2.1844,
      "step": 2180
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.00180816650390625,
      "learning_rate": 2.5791946308724833e-05,
      "loss": 2.2633,
      "step": 2190
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.00089263916015625,
      "learning_rate": 2.577181208053691e-05,
      "loss": 3.5875,
      "step": 2200
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.000823974609375,
      "learning_rate": 2.5751677852348994e-05,
      "loss": 2.832,
      "step": 2210
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.00107574462890625,
      "learning_rate": 2.5731543624161076e-05,
      "loss": 0.5188,
      "step": 2220
    },
    {
      "epoch": 2.23,
      "grad_norm": 30.625,
      "learning_rate": 2.5711409395973155e-05,
      "loss": 1.7953,
      "step": 2230
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.00138092041015625,
      "learning_rate": 2.5691275167785237e-05,
      "loss": 2.9757,
      "step": 2240
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.00115203857421875,
      "learning_rate": 2.5671140939597316e-05,
      "loss": 1.3641,
      "step": 2250
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.000946044921875,
      "learning_rate": 2.5651006711409398e-05,
      "loss": 2.118,
      "step": 2260
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.000911712646484375,
      "learning_rate": 2.5630872483221477e-05,
      "loss": 1.4102,
      "step": 2270
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 31.5,
      "learning_rate": 2.5610738255033556e-05,
      "loss": 2.2094,
      "step": 2280
    },
    {
      "epoch": 2.29,
      "grad_norm": 64.5,
      "learning_rate": 2.5590604026845638e-05,
      "loss": 1.7977,
      "step": 2290
    },
    {
      "epoch": 2.3,
      "grad_norm": 84.0,
      "learning_rate": 2.5570469798657717e-05,
      "loss": 2.6938,
      "step": 2300
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.000885009765625,
      "learning_rate": 2.55503355704698e-05,
      "loss": 1.5841,
      "step": 2310
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.000823974609375,
      "learning_rate": 2.553020134228188e-05,
      "loss": 2.2328,
      "step": 2320
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.001220703125,
      "learning_rate": 2.551006711409396e-05,
      "loss": 3.5688,
      "step": 2330
    },
    {
      "epoch": 2.34,
      "grad_norm": 40.25,
      "learning_rate": 2.5489932885906043e-05,
      "loss": 2.5414,
      "step": 2340
    },
    {
      "epoch": 2.35,
      "grad_norm": 28.5,
      "learning_rate": 2.546979865771812e-05,
      "loss": 0.9922,
      "step": 2350
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.00118255615234375,
      "learning_rate": 2.54496644295302e-05,
      "loss": 1.1586,
      "step": 2360
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.0008697509765625,
      "learning_rate": 2.5429530201342283e-05,
      "loss": 2.8156,
      "step": 2370
    },
    {
      "epoch": 2.38,
      "grad_norm": 36.25,
      "learning_rate": 2.540939597315436e-05,
      "loss": 2.5484,
      "step": 2380
    },
    {
      "epoch": 2.39,
      "grad_norm": 83.5,
      "learning_rate": 2.5389261744966444e-05,
      "loss": 2.7508,
      "step": 2390
    },
    {
      "epoch": 2.4,
      "grad_norm": 29.125,
      "learning_rate": 2.5369127516778523e-05,
      "loss": 2.5438,
      "step": 2400
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.0021820068359375,
      "learning_rate": 2.5348993288590605e-05,
      "loss": 1.3125,
      "step": 2410
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.00136566162109375,
      "learning_rate": 2.5328859060402687e-05,
      "loss": 1.2938,
      "step": 2420
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.00138092041015625,
      "learning_rate": 2.5308724832214766e-05,
      "loss": 2.575,
      "step": 2430
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.0029449462890625,
      "learning_rate": 2.5288590604026848e-05,
      "loss": 3.665,
      "step": 2440
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.006103515625,
      "learning_rate": 2.5268456375838924e-05,
      "loss": 3.5578,
      "step": 2450
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.00421142578125,
      "learning_rate": 2.5248322147651006e-05,
      "loss": 3.111,
      "step": 2460
    },
    {
      "epoch": 2.4699999999999998,
      "grad_norm": 0.001678466796875,
      "learning_rate": 2.5228187919463088e-05,
      "loss": 0.7511,
      "step": 2470
    },
    {
      "epoch": 2.48,
      "grad_norm": 28.5,
      "learning_rate": 2.5208053691275167e-05,
      "loss": 3.7023,
      "step": 2480
    },
    {
      "epoch": 2.49,
      "grad_norm": 62.5,
      "learning_rate": 2.518791946308725e-05,
      "loss": 3.1359,
      "step": 2490
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.00139617919921875,
      "learning_rate": 2.5167785234899328e-05,
      "loss": 3.3672,
      "step": 2500
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.0,
      "learning_rate": 2.514765100671141e-05,
      "loss": 1.6474,
      "step": 2510
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.00095367431640625,
      "learning_rate": 2.5127516778523493e-05,
      "loss": 3.2547,
      "step": 2520
    },
    {
      "epoch": 2.5300000000000002,
      "grad_norm": 0.00113677978515625,
      "learning_rate": 2.510738255033557e-05,
      "loss": 2.7813,
      "step": 2530
    },
    {
      "epoch": 2.54,
      "grad_norm": 35.0,
      "learning_rate": 2.508724832214765e-05,
      "loss": 1.5844,
      "step": 2540
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.00087738037109375,
      "learning_rate": 2.506711409395973e-05,
      "loss": 1.4193,
      "step": 2550
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.000751495361328125,
      "learning_rate": 2.504697986577181e-05,
      "loss": 3.5641,
      "step": 2560
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.000820159912109375,
      "learning_rate": 2.5026845637583894e-05,
      "loss": 2.2039,
      "step": 2570
    },
    {
      "epoch": 2.58,
      "grad_norm": 30.125,
      "learning_rate": 2.5006711409395973e-05,
      "loss": 1.5266,
      "step": 2580
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.00107574462890625,
      "learning_rate": 2.4986577181208055e-05,
      "loss": 1.962,
      "step": 2590
    },
    {
      "epoch": 2.6,
      "grad_norm": 29.375,
      "learning_rate": 2.4966442953020137e-05,
      "loss": 1.7508,
      "step": 2600
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.00119781494140625,
      "learning_rate": 2.4946308724832216e-05,
      "loss": 4.0406,
      "step": 2610
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.00122833251953125,
      "learning_rate": 2.4926174496644298e-05,
      "loss": 1.1016,
      "step": 2620
    },
    {
      "epoch": 2.63,
      "grad_norm": 39.5,
      "learning_rate": 2.4906040268456374e-05,
      "loss": 3.0156,
      "step": 2630
    },
    {
      "epoch": 2.64,
      "grad_norm": 66.5,
      "learning_rate": 2.4885906040268456e-05,
      "loss": 3.2078,
      "step": 2640
    },
    {
      "epoch": 2.65,
      "grad_norm": 82.0,
      "learning_rate": 2.4865771812080538e-05,
      "loss": 2.882,
      "step": 2650
    },
    {
      "epoch": 2.66,
      "grad_norm": 38.75,
      "learning_rate": 2.4845637583892617e-05,
      "loss": 3.0578,
      "step": 2660
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.0013275146484375,
      "learning_rate": 2.48255033557047e-05,
      "loss": 2.5195,
      "step": 2670
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.00118255615234375,
      "learning_rate": 2.4805369127516778e-05,
      "loss": 1.5656,
      "step": 2680
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.002410888671875,
      "learning_rate": 2.478523489932886e-05,
      "loss": 3.1313,
      "step": 2690
    },
    {
      "epoch": 2.7,
      "grad_norm": 39.25,
      "learning_rate": 2.4765100671140943e-05,
      "loss": 2.3484,
      "step": 2700
    },
    {
      "epoch": 2.71,
      "grad_norm": 42.5,
      "learning_rate": 2.474496644295302e-05,
      "loss": 2.0434,
      "step": 2710
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 39.75,
      "learning_rate": 2.4724832214765104e-05,
      "loss": 3.4375,
      "step": 2720
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.00147247314453125,
      "learning_rate": 2.470469798657718e-05,
      "loss": 2.8977,
      "step": 2730
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.005126953125,
      "learning_rate": 2.468456375838926e-05,
      "loss": 1.325,
      "step": 2740
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.00193023681640625,
      "learning_rate": 2.4664429530201344e-05,
      "loss": 2.6672,
      "step": 2750
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.0016632080078125,
      "learning_rate": 2.4644295302013423e-05,
      "loss": 3.9547,
      "step": 2760
    },
    {
      "epoch": 2.77,
      "grad_norm": 76.0,
      "learning_rate": 2.4624161073825505e-05,
      "loss": 3.9859,
      "step": 2770
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 49.0,
      "learning_rate": 2.4604026845637584e-05,
      "loss": 1.5602,
      "step": 2780
    },
    {
      "epoch": 2.79,
      "grad_norm": 39.25,
      "learning_rate": 2.4583892617449666e-05,
      "loss": 1.3984,
      "step": 2790
    },
    {
      "epoch": 2.8,
      "grad_norm": 32.5,
      "learning_rate": 2.456375838926175e-05,
      "loss": 0.9063,
      "step": 2800
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.0030517578125,
      "learning_rate": 2.4543624161073827e-05,
      "loss": 1.545,
      "step": 2810
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.00170135498046875,
      "learning_rate": 2.4523489932885906e-05,
      "loss": 1.1109,
      "step": 2820
    },
    {
      "epoch": 2.83,
      "grad_norm": 37.0,
      "learning_rate": 2.4503355704697985e-05,
      "loss": 4.2063,
      "step": 2830
    },
    {
      "epoch": 2.84,
      "grad_norm": 34.5,
      "learning_rate": 2.4483221476510067e-05,
      "loss": 2.4672,
      "step": 2840
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.00110626220703125,
      "learning_rate": 2.446308724832215e-05,
      "loss": 1.1922,
      "step": 2850
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.00096893310546875,
      "learning_rate": 2.444295302013423e-05,
      "loss": 0.2266,
      "step": 2860
    },
    {
      "epoch": 2.87,
      "grad_norm": 27.5,
      "learning_rate": 2.442281879194631e-05,
      "loss": 1.3922,
      "step": 2870
    },
    {
      "epoch": 2.88,
      "grad_norm": 26.0,
      "learning_rate": 2.440268456375839e-05,
      "loss": 2.7013,
      "step": 2880
    },
    {
      "epoch": 2.89,
      "grad_norm": 29.375,
      "learning_rate": 2.438255033557047e-05,
      "loss": 2.3641,
      "step": 2890
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.00170135498046875,
      "learning_rate": 2.4362416107382554e-05,
      "loss": 2.9203,
      "step": 2900
    },
    {
      "epoch": 2.91,
      "grad_norm": 65.0,
      "learning_rate": 2.434228187919463e-05,
      "loss": 1.9857,
      "step": 2910
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.001220703125,
      "learning_rate": 2.432214765100671e-05,
      "loss": 2.525,
      "step": 2920
    },
    {
      "epoch": 2.93,
      "grad_norm": 31.0,
      "learning_rate": 2.430201342281879e-05,
      "loss": 2.0609,
      "step": 2930
    },
    {
      "epoch": 2.94,
      "grad_norm": 46.0,
      "learning_rate": 2.4281879194630873e-05,
      "loss": 2.4131,
      "step": 2940
    },
    {
      "epoch": 2.95,
      "grad_norm": 40.5,
      "learning_rate": 2.4261744966442955e-05,
      "loss": 2.5297,
      "step": 2950
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.0008087158203125,
      "learning_rate": 2.4241610738255034e-05,
      "loss": 2.0313,
      "step": 2960
    },
    {
      "epoch": 2.9699999999999998,
      "grad_norm": 74.0,
      "learning_rate": 2.4221476510067116e-05,
      "loss": 2.4453,
      "step": 2970
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.000469207763671875,
      "learning_rate": 2.4201342281879195e-05,
      "loss": 1.6609,
      "step": 2980
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.000415802001953125,
      "learning_rate": 2.4181208053691277e-05,
      "loss": 2.1563,
      "step": 2990
    },
    {
      "epoch": 3.0,
      "grad_norm": 29.25,
      "learning_rate": 2.4161073825503356e-05,
      "loss": 4.1328,
      "step": 3000
    },
    {
      "epoch": 3.0,
      "eval_loss": 2.634068250656128,
      "eval_runtime": 28.7805,
      "eval_samples_per_second": 3.475,
      "eval_steps_per_second": 3.475,
      "step": 3000
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.00083160400390625,
      "learning_rate": 2.4140939597315435e-05,
      "loss": 2.6891,
      "step": 3010
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.0008544921875,
      "learning_rate": 2.4120805369127517e-05,
      "loss": 1.5378,
      "step": 3020
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.0045166015625,
      "learning_rate": 2.4100671140939596e-05,
      "loss": 1.6406,
      "step": 3030
    },
    {
      "epoch": 3.04,
      "grad_norm": 32.0,
      "learning_rate": 2.408053691275168e-05,
      "loss": 1.6663,
      "step": 3040
    },
    {
      "epoch": 3.05,
      "grad_norm": 36.75,
      "learning_rate": 2.406040268456376e-05,
      "loss": 1.382,
      "step": 3050
    },
    {
      "epoch": 3.06,
      "grad_norm": 70.5,
      "learning_rate": 2.404026845637584e-05,
      "loss": 2.4508,
      "step": 3060
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.000732421875,
      "learning_rate": 2.4020134228187922e-05,
      "loss": 1.8375,
      "step": 3070
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.00136566162109375,
      "learning_rate": 2.4e-05,
      "loss": 2.7229,
      "step": 3080
    },
    {
      "epoch": 3.09,
      "grad_norm": 0.00074005126953125,
      "learning_rate": 2.397986577181208e-05,
      "loss": 1.4297,
      "step": 3090
    },
    {
      "epoch": 3.1,
      "grad_norm": 76.5,
      "learning_rate": 2.3959731543624162e-05,
      "loss": 1.5953,
      "step": 3100
    },
    {
      "epoch": 3.11,
      "grad_norm": 45.5,
      "learning_rate": 2.393959731543624e-05,
      "loss": 1.4141,
      "step": 3110
    },
    {
      "epoch": 3.12,
      "grad_norm": 29.875,
      "learning_rate": 2.3919463087248323e-05,
      "loss": 2.6641,
      "step": 3120
    },
    {
      "epoch": 3.13,
      "grad_norm": 33.75,
      "learning_rate": 2.3899328859060402e-05,
      "loss": 3.3703,
      "step": 3130
    },
    {
      "epoch": 3.14,
      "grad_norm": 43.25,
      "learning_rate": 2.3879194630872484e-05,
      "loss": 3.0875,
      "step": 3140
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.000789642333984375,
      "learning_rate": 2.3859060402684566e-05,
      "loss": 2.45,
      "step": 3150
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.000514984130859375,
      "learning_rate": 2.3838926174496645e-05,
      "loss": 2.8977,
      "step": 3160
    },
    {
      "epoch": 3.17,
      "grad_norm": 43.0,
      "learning_rate": 2.3818791946308727e-05,
      "loss": 2.0383,
      "step": 3170
    },
    {
      "epoch": 3.18,
      "grad_norm": 30.875,
      "learning_rate": 2.3798657718120806e-05,
      "loss": 3.5674,
      "step": 3180
    },
    {
      "epoch": 3.19,
      "grad_norm": 39.0,
      "learning_rate": 2.3778523489932885e-05,
      "loss": 2.3297,
      "step": 3190
    },
    {
      "epoch": 3.2,
      "grad_norm": 46.75,
      "learning_rate": 2.3758389261744967e-05,
      "loss": 2.5656,
      "step": 3200
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.000789642333984375,
      "learning_rate": 2.3738255033557046e-05,
      "loss": 2.4844,
      "step": 3210
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.00042724609375,
      "learning_rate": 2.371812080536913e-05,
      "loss": 2.2781,
      "step": 3220
    },
    {
      "epoch": 3.23,
      "grad_norm": 33.5,
      "learning_rate": 2.3697986577181207e-05,
      "loss": 2.0242,
      "step": 3230
    },
    {
      "epoch": 3.24,
      "grad_norm": 41.25,
      "learning_rate": 2.367785234899329e-05,
      "loss": 1.6195,
      "step": 3240
    },
    {
      "epoch": 3.25,
      "grad_norm": 56.25,
      "learning_rate": 2.3657718120805372e-05,
      "loss": 4.2844,
      "step": 3250
    },
    {
      "epoch": 3.26,
      "grad_norm": 35.25,
      "learning_rate": 2.363758389261745e-05,
      "loss": 0.9188,
      "step": 3260
    },
    {
      "epoch": 3.27,
      "grad_norm": 32.0,
      "learning_rate": 2.3617449664429533e-05,
      "loss": 1.8391,
      "step": 3270
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 43.5,
      "learning_rate": 2.359731543624161e-05,
      "loss": 2.382,
      "step": 3280
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.0006256103515625,
      "learning_rate": 2.357718120805369e-05,
      "loss": 1.4758,
      "step": 3290
    },
    {
      "epoch": 3.3,
      "grad_norm": 27.75,
      "learning_rate": 2.3557046979865773e-05,
      "loss": 2.1375,
      "step": 3300
    },
    {
      "epoch": 3.31,
      "grad_norm": 0.000720977783203125,
      "learning_rate": 2.3536912751677852e-05,
      "loss": 2.9539,
      "step": 3310
    },
    {
      "epoch": 3.32,
      "grad_norm": 41.25,
      "learning_rate": 2.3516778523489934e-05,
      "loss": 2.4974,
      "step": 3320
    },
    {
      "epoch": 3.33,
      "grad_norm": 91.5,
      "learning_rate": 2.3496644295302013e-05,
      "loss": 2.1469,
      "step": 3330
    },
    {
      "epoch": 3.34,
      "grad_norm": 41.75,
      "learning_rate": 2.3476510067114095e-05,
      "loss": 2.5891,
      "step": 3340
    },
    {
      "epoch": 3.35,
      "grad_norm": 68.0,
      "learning_rate": 2.3456375838926177e-05,
      "loss": 2.6422,
      "step": 3350
    },
    {
      "epoch": 3.36,
      "grad_norm": 65.0,
      "learning_rate": 2.3436241610738256e-05,
      "loss": 3.1484,
      "step": 3360
    },
    {
      "epoch": 3.37,
      "grad_norm": 62.5,
      "learning_rate": 2.3416107382550335e-05,
      "loss": 1.2038,
      "step": 3370
    },
    {
      "epoch": 3.38,
      "grad_norm": 33.25,
      "learning_rate": 2.3395973154362414e-05,
      "loss": 1.6531,
      "step": 3380
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.00125885009765625,
      "learning_rate": 2.3375838926174496e-05,
      "loss": 1.3305,
      "step": 3390
    },
    {
      "epoch": 3.4,
      "grad_norm": 69.0,
      "learning_rate": 2.335570469798658e-05,
      "loss": 2.5906,
      "step": 3400
    },
    {
      "epoch": 3.41,
      "grad_norm": 51.25,
      "learning_rate": 2.3335570469798657e-05,
      "loss": 2.1656,
      "step": 3410
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.0,
      "learning_rate": 2.331543624161074e-05,
      "loss": 3.6059,
      "step": 3420
    },
    {
      "epoch": 3.43,
      "grad_norm": 0.0004673004150390625,
      "learning_rate": 2.329530201342282e-05,
      "loss": 2.8016,
      "step": 3430
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.000579833984375,
      "learning_rate": 2.32751677852349e-05,
      "loss": 1.0453,
      "step": 3440
    },
    {
      "epoch": 3.45,
      "grad_norm": 35.25,
      "learning_rate": 2.3255033557046983e-05,
      "loss": 3.0852,
      "step": 3450
    },
    {
      "epoch": 3.46,
      "grad_norm": 69.0,
      "learning_rate": 2.323489932885906e-05,
      "loss": 3.1844,
      "step": 3460
    },
    {
      "epoch": 3.4699999999999998,
      "grad_norm": 74.5,
      "learning_rate": 2.321476510067114e-05,
      "loss": 4.6594,
      "step": 3470
    },
    {
      "epoch": 3.48,
      "grad_norm": 64.5,
      "learning_rate": 2.319463087248322e-05,
      "loss": 1.7547,
      "step": 3480
    },
    {
      "epoch": 3.49,
      "grad_norm": 49.25,
      "learning_rate": 2.3174496644295302e-05,
      "loss": 1.9305,
      "step": 3490
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.0019073486328125,
      "learning_rate": 2.3154362416107384e-05,
      "loss": 1.9109,
      "step": 3500
    },
    {
      "epoch": 3.51,
      "grad_norm": 0.00058746337890625,
      "learning_rate": 2.3134228187919463e-05,
      "loss": 1.8313,
      "step": 3510
    },
    {
      "epoch": 3.52,
      "grad_norm": 79.5,
      "learning_rate": 2.3114093959731545e-05,
      "loss": 1.6992,
      "step": 3520
    },
    {
      "epoch": 3.5300000000000002,
      "grad_norm": 0.000507354736328125,
      "learning_rate": 2.3093959731543624e-05,
      "loss": 2.5777,
      "step": 3530
    },
    {
      "epoch": 3.54,
      "grad_norm": 0.00037384033203125,
      "learning_rate": 2.3073825503355706e-05,
      "loss": 1.2246,
      "step": 3540
    },
    {
      "epoch": 3.55,
      "grad_norm": 74.0,
      "learning_rate": 2.3053691275167785e-05,
      "loss": 2.8789,
      "step": 3550
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.0002765655517578125,
      "learning_rate": 2.3033557046979864e-05,
      "loss": 1.85,
      "step": 3560
    },
    {
      "epoch": 3.57,
      "grad_norm": 0.0003337860107421875,
      "learning_rate": 2.3013422818791946e-05,
      "loss": 2.7203,
      "step": 3570
    },
    {
      "epoch": 3.58,
      "grad_norm": 37.0,
      "learning_rate": 2.299328859060403e-05,
      "loss": 2.4297,
      "step": 3580
    },
    {
      "epoch": 3.59,
      "grad_norm": 87.0,
      "learning_rate": 2.2973154362416107e-05,
      "loss": 2.2922,
      "step": 3590
    },
    {
      "epoch": 3.6,
      "grad_norm": 34.75,
      "learning_rate": 2.295302013422819e-05,
      "loss": 1.3656,
      "step": 3600
    },
    {
      "epoch": 3.61,
      "grad_norm": 0.000255584716796875,
      "learning_rate": 2.293288590604027e-05,
      "loss": 1.5617,
      "step": 3610
    },
    {
      "epoch": 3.62,
      "grad_norm": 32.25,
      "learning_rate": 2.291275167785235e-05,
      "loss": 1.9969,
      "step": 3620
    },
    {
      "epoch": 3.63,
      "grad_norm": 31.5,
      "learning_rate": 2.2892617449664433e-05,
      "loss": 1.1906,
      "step": 3630
    },
    {
      "epoch": 3.64,
      "grad_norm": 39.75,
      "learning_rate": 2.2872483221476512e-05,
      "loss": 3.1133,
      "step": 3640
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.0003643035888671875,
      "learning_rate": 2.285234899328859e-05,
      "loss": 0.1852,
      "step": 3650
    },
    {
      "epoch": 3.66,
      "grad_norm": 0.0,
      "learning_rate": 2.283221476510067e-05,
      "loss": 1.7463,
      "step": 3660
    },
    {
      "epoch": 3.67,
      "grad_norm": 0.000469207763671875,
      "learning_rate": 2.2812080536912752e-05,
      "loss": 2.3344,
      "step": 3670
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.00035858154296875,
      "learning_rate": 2.2791946308724834e-05,
      "loss": 1.7836,
      "step": 3680
    },
    {
      "epoch": 3.69,
      "grad_norm": 0.0004367828369140625,
      "learning_rate": 2.2771812080536913e-05,
      "loss": 1.8056,
      "step": 3690
    },
    {
      "epoch": 3.7,
      "grad_norm": 79.0,
      "learning_rate": 2.2751677852348995e-05,
      "loss": 1.7563,
      "step": 3700
    },
    {
      "epoch": 3.71,
      "grad_norm": 0.0,
      "learning_rate": 2.2731543624161074e-05,
      "loss": 1.6689,
      "step": 3710
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 0.000301361083984375,
      "learning_rate": 2.2711409395973156e-05,
      "loss": 0.5875,
      "step": 3720
    },
    {
      "epoch": 3.73,
      "grad_norm": 39.5,
      "learning_rate": 2.269127516778524e-05,
      "loss": 3.8586,
      "step": 3730
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.000255584716796875,
      "learning_rate": 2.2671140939597314e-05,
      "loss": 1.8266,
      "step": 3740
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.0004825592041015625,
      "learning_rate": 2.2651006711409396e-05,
      "loss": 1.4891,
      "step": 3750
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.000972747802734375,
      "learning_rate": 2.2630872483221475e-05,
      "loss": 2.2281,
      "step": 3760
    },
    {
      "epoch": 3.77,
      "grad_norm": 32.25,
      "learning_rate": 2.2610738255033557e-05,
      "loss": 3.6031,
      "step": 3770
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 0.0001983642578125,
      "learning_rate": 2.259060402684564e-05,
      "loss": 2.7094,
      "step": 3780
    },
    {
      "epoch": 3.79,
      "grad_norm": 0.0002269744873046875,
      "learning_rate": 2.257046979865772e-05,
      "loss": 3.1,
      "step": 3790
    },
    {
      "epoch": 3.8,
      "grad_norm": 94.5,
      "learning_rate": 2.25503355704698e-05,
      "loss": 3.2672,
      "step": 3800
    },
    {
      "epoch": 3.81,
      "grad_norm": 0.000438690185546875,
      "learning_rate": 2.253020134228188e-05,
      "loss": 0.3555,
      "step": 3810
    },
    {
      "epoch": 3.82,
      "grad_norm": 0.000324249267578125,
      "learning_rate": 2.2510067114093962e-05,
      "loss": 2.5633,
      "step": 3820
    },
    {
      "epoch": 3.83,
      "grad_norm": 0.00115966796875,
      "learning_rate": 2.248993288590604e-05,
      "loss": 2.3758,
      "step": 3830
    },
    {
      "epoch": 3.84,
      "grad_norm": 33.0,
      "learning_rate": 2.246979865771812e-05,
      "loss": 2.1586,
      "step": 3840
    },
    {
      "epoch": 3.85,
      "grad_norm": 50.25,
      "learning_rate": 2.2449664429530202e-05,
      "loss": 1.7258,
      "step": 3850
    },
    {
      "epoch": 3.86,
      "grad_norm": 38.5,
      "learning_rate": 2.242953020134228e-05,
      "loss": 2.456,
      "step": 3860
    },
    {
      "epoch": 3.87,
      "grad_norm": 91.0,
      "learning_rate": 2.2409395973154363e-05,
      "loss": 3.5647,
      "step": 3870
    },
    {
      "epoch": 3.88,
      "grad_norm": 90.5,
      "learning_rate": 2.2389261744966445e-05,
      "loss": 2.6199,
      "step": 3880
    },
    {
      "epoch": 3.89,
      "grad_norm": 77.0,
      "learning_rate": 2.2369127516778524e-05,
      "loss": 2.9461,
      "step": 3890
    },
    {
      "epoch": 3.9,
      "grad_norm": 31.375,
      "learning_rate": 2.2348993288590606e-05,
      "loss": 2.3734,
      "step": 3900
    },
    {
      "epoch": 3.91,
      "grad_norm": 0.0003566741943359375,
      "learning_rate": 2.2328859060402685e-05,
      "loss": 3.5031,
      "step": 3910
    },
    {
      "epoch": 3.92,
      "grad_norm": 32.25,
      "learning_rate": 2.2308724832214764e-05,
      "loss": 1.0703,
      "step": 3920
    },
    {
      "epoch": 3.93,
      "grad_norm": 0.0002994537353515625,
      "learning_rate": 2.2288590604026846e-05,
      "loss": 2.3922,
      "step": 3930
    },
    {
      "epoch": 3.94,
      "grad_norm": 63.25,
      "learning_rate": 2.2268456375838925e-05,
      "loss": 3.1656,
      "step": 3940
    },
    {
      "epoch": 3.95,
      "grad_norm": 36.75,
      "learning_rate": 2.2248322147651008e-05,
      "loss": 2.043,
      "step": 3950
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.0,
      "learning_rate": 2.2228187919463086e-05,
      "loss": 1.7222,
      "step": 3960
    },
    {
      "epoch": 3.9699999999999998,
      "grad_norm": 43.5,
      "learning_rate": 2.220805369127517e-05,
      "loss": 1.7828,
      "step": 3970
    },
    {
      "epoch": 3.98,
      "grad_norm": 74.5,
      "learning_rate": 2.218791946308725e-05,
      "loss": 2.7633,
      "step": 3980
    },
    {
      "epoch": 3.99,
      "grad_norm": 0.0002498626708984375,
      "learning_rate": 2.216778523489933e-05,
      "loss": 0.5813,
      "step": 3990
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.00023555755615234375,
      "learning_rate": 2.2147651006711412e-05,
      "loss": 0.7014,
      "step": 4000
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.6435961723327637,
      "eval_runtime": 28.7099,
      "eval_samples_per_second": 3.483,
      "eval_steps_per_second": 3.483,
      "step": 4000
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.0003719329833984375,
      "learning_rate": 2.2127516778523488e-05,
      "loss": 0.3328,
      "step": 4010
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.0002269744873046875,
      "learning_rate": 2.210738255033557e-05,
      "loss": 1.7781,
      "step": 4020
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.000492095947265625,
      "learning_rate": 2.2087248322147652e-05,
      "loss": 2.0375,
      "step": 4030
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.0018768310546875,
      "learning_rate": 2.206711409395973e-05,
      "loss": 0.9,
      "step": 4040
    },
    {
      "epoch": 4.05,
      "grad_norm": 0.000255584716796875,
      "learning_rate": 2.2046979865771813e-05,
      "loss": 1.8023,
      "step": 4050
    },
    {
      "epoch": 4.06,
      "grad_norm": 0.00035858154296875,
      "learning_rate": 2.2026845637583892e-05,
      "loss": 1.4688,
      "step": 4060
    },
    {
      "epoch": 4.07,
      "grad_norm": 0.0003643035888671875,
      "learning_rate": 2.2006711409395974e-05,
      "loss": 1.2719,
      "step": 4070
    },
    {
      "epoch": 4.08,
      "grad_norm": 34.5,
      "learning_rate": 2.1986577181208057e-05,
      "loss": 2.5672,
      "step": 4080
    },
    {
      "epoch": 4.09,
      "grad_norm": 94.5,
      "learning_rate": 2.1966442953020135e-05,
      "loss": 2.1289,
      "step": 4090
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.00030517578125,
      "learning_rate": 2.1946308724832218e-05,
      "loss": 0.6781,
      "step": 4100
    },
    {
      "epoch": 4.11,
      "grad_norm": 0.000362396240234375,
      "learning_rate": 2.1926174496644293e-05,
      "loss": 1.1641,
      "step": 4110
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.000244140625,
      "learning_rate": 2.1906040268456375e-05,
      "loss": 2.2422,
      "step": 4120
    },
    {
      "epoch": 4.13,
      "grad_norm": 0.0004138946533203125,
      "learning_rate": 2.1885906040268458e-05,
      "loss": 3.3047,
      "step": 4130
    },
    {
      "epoch": 4.14,
      "grad_norm": 44.5,
      "learning_rate": 2.1865771812080536e-05,
      "loss": 2.3156,
      "step": 4140
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.0003261566162109375,
      "learning_rate": 2.184563758389262e-05,
      "loss": 2.5719,
      "step": 4150
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.0003910064697265625,
      "learning_rate": 2.1825503355704698e-05,
      "loss": 0.4133,
      "step": 4160
    },
    {
      "epoch": 4.17,
      "grad_norm": 49.25,
      "learning_rate": 2.180536912751678e-05,
      "loss": 2.2078,
      "step": 4170
    },
    {
      "epoch": 4.18,
      "grad_norm": 33.25,
      "learning_rate": 2.1785234899328862e-05,
      "loss": 1.5063,
      "step": 4180
    },
    {
      "epoch": 4.19,
      "grad_norm": 83.5,
      "learning_rate": 2.176510067114094e-05,
      "loss": 3.3141,
      "step": 4190
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.0005340576171875,
      "learning_rate": 2.174496644295302e-05,
      "loss": 1.7836,
      "step": 4200
    },
    {
      "epoch": 4.21,
      "grad_norm": 37.25,
      "learning_rate": 2.17248322147651e-05,
      "loss": 1.5227,
      "step": 4210
    },
    {
      "epoch": 4.22,
      "grad_norm": 0.000545501708984375,
      "learning_rate": 2.170469798657718e-05,
      "loss": 1.7988,
      "step": 4220
    },
    {
      "epoch": 4.23,
      "grad_norm": 47.0,
      "learning_rate": 2.1684563758389263e-05,
      "loss": 2.3539,
      "step": 4230
    },
    {
      "epoch": 4.24,
      "grad_norm": 104.5,
      "learning_rate": 2.1664429530201342e-05,
      "loss": 4.7516,
      "step": 4240
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.000370025634765625,
      "learning_rate": 2.1644295302013424e-05,
      "loss": 0.6367,
      "step": 4250
    },
    {
      "epoch": 4.26,
      "grad_norm": 0.000385284423828125,
      "learning_rate": 2.1624161073825503e-05,
      "loss": 1.4625,
      "step": 4260
    },
    {
      "epoch": 4.27,
      "grad_norm": 0.00035858154296875,
      "learning_rate": 2.1604026845637585e-05,
      "loss": 1.0273,
      "step": 4270
    },
    {
      "epoch": 4.28,
      "grad_norm": 41.5,
      "learning_rate": 2.1583892617449668e-05,
      "loss": 2.2677,
      "step": 4280
    },
    {
      "epoch": 4.29,
      "grad_norm": 47.75,
      "learning_rate": 2.1563758389261743e-05,
      "loss": 2.0422,
      "step": 4290
    },
    {
      "epoch": 4.3,
      "grad_norm": 35.25,
      "learning_rate": 2.1543624161073825e-05,
      "loss": 2.4852,
      "step": 4300
    },
    {
      "epoch": 4.31,
      "grad_norm": 31.5,
      "learning_rate": 2.1523489932885904e-05,
      "loss": 2.8141,
      "step": 4310
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.00106048583984375,
      "learning_rate": 2.1503355704697987e-05,
      "loss": 1.4852,
      "step": 4320
    },
    {
      "epoch": 4.33,
      "grad_norm": 55.75,
      "learning_rate": 2.148322147651007e-05,
      "loss": 2.0875,
      "step": 4330
    },
    {
      "epoch": 4.34,
      "grad_norm": 0.000293731689453125,
      "learning_rate": 2.1463087248322148e-05,
      "loss": 1.5781,
      "step": 4340
    },
    {
      "epoch": 4.35,
      "grad_norm": 34.5,
      "learning_rate": 2.144295302013423e-05,
      "loss": 1.2293,
      "step": 4350
    },
    {
      "epoch": 4.36,
      "grad_norm": 47.25,
      "learning_rate": 2.142281879194631e-05,
      "loss": 3.4414,
      "step": 4360
    },
    {
      "epoch": 4.37,
      "grad_norm": 0.00023651123046875,
      "learning_rate": 2.140268456375839e-05,
      "loss": 2.8766,
      "step": 4370
    },
    {
      "epoch": 4.38,
      "grad_norm": 0.0002288818359375,
      "learning_rate": 2.138255033557047e-05,
      "loss": 1.4992,
      "step": 4380
    },
    {
      "epoch": 4.39,
      "grad_norm": 31.375,
      "learning_rate": 2.136241610738255e-05,
      "loss": 1.6065,
      "step": 4390
    },
    {
      "epoch": 4.4,
      "grad_norm": 91.0,
      "learning_rate": 2.134228187919463e-05,
      "loss": 3.273,
      "step": 4400
    },
    {
      "epoch": 4.41,
      "grad_norm": 0.0002346038818359375,
      "learning_rate": 2.132214765100671e-05,
      "loss": 1.8719,
      "step": 4410
    },
    {
      "epoch": 4.42,
      "grad_norm": 0.0003414154052734375,
      "learning_rate": 2.1302013422818792e-05,
      "loss": 1.318,
      "step": 4420
    },
    {
      "epoch": 4.43,
      "grad_norm": 0.0002651214599609375,
      "learning_rate": 2.1281879194630874e-05,
      "loss": 3.1047,
      "step": 4430
    },
    {
      "epoch": 4.44,
      "grad_norm": 58.25,
      "learning_rate": 2.1261744966442953e-05,
      "loss": 2.6875,
      "step": 4440
    },
    {
      "epoch": 4.45,
      "grad_norm": 0.00023651123046875,
      "learning_rate": 2.1241610738255036e-05,
      "loss": 3.418,
      "step": 4450
    },
    {
      "epoch": 4.46,
      "grad_norm": 36.75,
      "learning_rate": 2.1221476510067114e-05,
      "loss": 1.4281,
      "step": 4460
    },
    {
      "epoch": 4.47,
      "grad_norm": 47.25,
      "learning_rate": 2.1201342281879193e-05,
      "loss": 1.5766,
      "step": 4470
    },
    {
      "epoch": 4.48,
      "grad_norm": 44.25,
      "learning_rate": 2.1181208053691275e-05,
      "loss": 2.0795,
      "step": 4480
    },
    {
      "epoch": 4.49,
      "grad_norm": 49.0,
      "learning_rate": 2.1161073825503354e-05,
      "loss": 2.8492,
      "step": 4490
    },
    {
      "epoch": 4.5,
      "grad_norm": 32.25,
      "learning_rate": 2.1140939597315437e-05,
      "loss": 1.075,
      "step": 4500
    },
    {
      "epoch": 4.51,
      "grad_norm": 39.25,
      "learning_rate": 2.1120805369127515e-05,
      "loss": 3.0133,
      "step": 4510
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.0004119873046875,
      "learning_rate": 2.1100671140939598e-05,
      "loss": 2.8516,
      "step": 4520
    },
    {
      "epoch": 4.53,
      "grad_norm": 0.0003223419189453125,
      "learning_rate": 2.108053691275168e-05,
      "loss": 1.3234,
      "step": 4530
    },
    {
      "epoch": 4.54,
      "grad_norm": 79.5,
      "learning_rate": 2.106040268456376e-05,
      "loss": 4.9688,
      "step": 4540
    },
    {
      "epoch": 4.55,
      "grad_norm": 0.000270843505859375,
      "learning_rate": 2.104026845637584e-05,
      "loss": 1.509,
      "step": 4550
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 48.0,
      "learning_rate": 2.102013422818792e-05,
      "loss": 1.7195,
      "step": 4560
    },
    {
      "epoch": 4.57,
      "grad_norm": 0.0003814697265625,
      "learning_rate": 2.1e-05,
      "loss": 2.2547,
      "step": 4570
    },
    {
      "epoch": 4.58,
      "grad_norm": 77.0,
      "learning_rate": 2.097986577181208e-05,
      "loss": 2.4594,
      "step": 4580
    },
    {
      "epoch": 4.59,
      "grad_norm": 0.00020503997802734375,
      "learning_rate": 2.095973154362416e-05,
      "loss": 1.9453,
      "step": 4590
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.000682830810546875,
      "learning_rate": 2.0939597315436242e-05,
      "loss": 2.8898,
      "step": 4600
    },
    {
      "epoch": 4.61,
      "grad_norm": 35.25,
      "learning_rate": 2.0919463087248324e-05,
      "loss": 1.7773,
      "step": 4610
    },
    {
      "epoch": 4.62,
      "grad_norm": 0.00025177001953125,
      "learning_rate": 2.0899328859060403e-05,
      "loss": 0.8164,
      "step": 4620
    },
    {
      "epoch": 4.63,
      "grad_norm": 33.5,
      "learning_rate": 2.0879194630872486e-05,
      "loss": 2.9398,
      "step": 4630
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.000278472900390625,
      "learning_rate": 2.0859060402684564e-05,
      "loss": 3.0031,
      "step": 4640
    },
    {
      "epoch": 4.65,
      "grad_norm": 51.25,
      "learning_rate": 2.0838926174496647e-05,
      "loss": 2.2859,
      "step": 4650
    },
    {
      "epoch": 4.66,
      "grad_norm": 0.0004596710205078125,
      "learning_rate": 2.0818791946308726e-05,
      "loss": 1.2047,
      "step": 4660
    },
    {
      "epoch": 4.67,
      "grad_norm": 0.000263214111328125,
      "learning_rate": 2.0798657718120804e-05,
      "loss": 1.175,
      "step": 4670
    },
    {
      "epoch": 4.68,
      "grad_norm": 37.0,
      "learning_rate": 2.0778523489932887e-05,
      "loss": 1.6688,
      "step": 4680
    },
    {
      "epoch": 4.6899999999999995,
      "grad_norm": 0.000209808349609375,
      "learning_rate": 2.0758389261744966e-05,
      "loss": 1.7313,
      "step": 4690
    },
    {
      "epoch": 4.7,
      "grad_norm": 73.0,
      "learning_rate": 2.0738255033557048e-05,
      "loss": 2.4109,
      "step": 4700
    },
    {
      "epoch": 4.71,
      "grad_norm": 35.25,
      "learning_rate": 2.071812080536913e-05,
      "loss": 0.9176,
      "step": 4710
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.0,
      "learning_rate": 2.069798657718121e-05,
      "loss": 1.9095,
      "step": 4720
    },
    {
      "epoch": 4.73,
      "grad_norm": 57.75,
      "learning_rate": 2.067785234899329e-05,
      "loss": 1.9734,
      "step": 4730
    },
    {
      "epoch": 4.74,
      "grad_norm": 34.25,
      "learning_rate": 2.065771812080537e-05,
      "loss": 0.9125,
      "step": 4740
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.000301361083984375,
      "learning_rate": 2.063758389261745e-05,
      "loss": 1.2344,
      "step": 4750
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.000293731689453125,
      "learning_rate": 2.061744966442953e-05,
      "loss": 0.5668,
      "step": 4760
    },
    {
      "epoch": 4.77,
      "grad_norm": 52.0,
      "learning_rate": 2.059731543624161e-05,
      "loss": 2.1078,
      "step": 4770
    },
    {
      "epoch": 4.78,
      "grad_norm": 46.5,
      "learning_rate": 2.0577181208053692e-05,
      "loss": 1.5998,
      "step": 4780
    },
    {
      "epoch": 4.79,
      "grad_norm": 0.0002193450927734375,
      "learning_rate": 2.055704697986577e-05,
      "loss": 1.6672,
      "step": 4790
    },
    {
      "epoch": 4.8,
      "grad_norm": 95.0,
      "learning_rate": 2.0536912751677853e-05,
      "loss": 2.4219,
      "step": 4800
    },
    {
      "epoch": 4.8100000000000005,
      "grad_norm": 76.0,
      "learning_rate": 2.0516778523489936e-05,
      "loss": 3.2571,
      "step": 4810
    },
    {
      "epoch": 4.82,
      "grad_norm": 79.5,
      "learning_rate": 2.0496644295302015e-05,
      "loss": 3.9031,
      "step": 4820
    },
    {
      "epoch": 4.83,
      "grad_norm": 0.0002384185791015625,
      "learning_rate": 2.0476510067114097e-05,
      "loss": 1.8336,
      "step": 4830
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.0002689361572265625,
      "learning_rate": 2.0456375838926172e-05,
      "loss": 2.7742,
      "step": 4840
    },
    {
      "epoch": 4.85,
      "grad_norm": 0.00023365020751953125,
      "learning_rate": 2.0436241610738254e-05,
      "loss": 2.7609,
      "step": 4850
    },
    {
      "epoch": 4.86,
      "grad_norm": 40.75,
      "learning_rate": 2.0416107382550337e-05,
      "loss": 0.9289,
      "step": 4860
    },
    {
      "epoch": 4.87,
      "grad_norm": 0.0003814697265625,
      "learning_rate": 2.0395973154362416e-05,
      "loss": 3.1734,
      "step": 4870
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.00052642822265625,
      "learning_rate": 2.0375838926174498e-05,
      "loss": 1.9625,
      "step": 4880
    },
    {
      "epoch": 4.89,
      "grad_norm": 0.0004024505615234375,
      "learning_rate": 2.0355704697986577e-05,
      "loss": 1.1391,
      "step": 4890
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.0003070831298828125,
      "learning_rate": 2.033557046979866e-05,
      "loss": 4.1797,
      "step": 4900
    },
    {
      "epoch": 4.91,
      "grad_norm": 52.25,
      "learning_rate": 2.031543624161074e-05,
      "loss": 2.4422,
      "step": 4910
    },
    {
      "epoch": 4.92,
      "grad_norm": 77.5,
      "learning_rate": 2.029530201342282e-05,
      "loss": 3.2031,
      "step": 4920
    },
    {
      "epoch": 4.93,
      "grad_norm": 0.000396728515625,
      "learning_rate": 2.02751677852349e-05,
      "loss": 1.2914,
      "step": 4930
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 86.0,
      "learning_rate": 2.0255033557046978e-05,
      "loss": 1.8234,
      "step": 4940
    },
    {
      "epoch": 4.95,
      "grad_norm": 0.000614166259765625,
      "learning_rate": 2.023489932885906e-05,
      "loss": 1.5521,
      "step": 4950
    },
    {
      "epoch": 4.96,
      "grad_norm": 49.5,
      "learning_rate": 2.0214765100671142e-05,
      "loss": 3.2482,
      "step": 4960
    },
    {
      "epoch": 4.97,
      "grad_norm": 0.0003452301025390625,
      "learning_rate": 2.019463087248322e-05,
      "loss": 2.2281,
      "step": 4970
    },
    {
      "epoch": 4.98,
      "grad_norm": 103.5,
      "learning_rate": 2.0174496644295303e-05,
      "loss": 3.3266,
      "step": 4980
    },
    {
      "epoch": 4.99,
      "grad_norm": 43.25,
      "learning_rate": 2.0154362416107382e-05,
      "loss": 1.7484,
      "step": 4990
    },
    {
      "epoch": 5.0,
      "grad_norm": 48.75,
      "learning_rate": 2.0134228187919465e-05,
      "loss": 2.3771,
      "step": 5000
    },
    {
      "epoch": 5.0,
      "eval_loss": 2.633439540863037,
      "eval_runtime": 28.7085,
      "eval_samples_per_second": 3.483,
      "eval_steps_per_second": 3.483,
      "step": 5000
    }
  ],
  "logging_steps": 10,
  "max_steps": 15000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.480621746257408e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
