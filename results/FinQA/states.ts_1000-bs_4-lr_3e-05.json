{
  "best_metric": 1.4232043027877808,
  "best_model_checkpoint": "./models/adapter/checkpoint-5000",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 246.0,
      "learning_rate": 3e-06,
      "loss": 11.8438,
      "step": 10
    },
    {
      "epoch": 0.02,
      "grad_norm": 228.0,
      "learning_rate": 6e-06,
      "loss": 11.3438,
      "step": 20
    },
    {
      "epoch": 0.03,
      "grad_norm": 216.0,
      "learning_rate": 9e-06,
      "loss": 9.5813,
      "step": 30
    },
    {
      "epoch": 0.04,
      "grad_norm": 176.0,
      "learning_rate": 1.2e-05,
      "loss": 5.2844,
      "step": 40
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.068359375,
      "learning_rate": 1.5e-05,
      "loss": 3.4428,
      "step": 50
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.005157470703125,
      "learning_rate": 1.8e-05,
      "loss": 0.0001,
      "step": 60
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0081787109375,
      "learning_rate": 2.1e-05,
      "loss": 1.4625,
      "step": 70
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.00738525390625,
      "learning_rate": 2.4e-05,
      "loss": 1.8875,
      "step": 80
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.0966796875,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 2.5503,
      "step": 90
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.12158203125,
      "learning_rate": 3e-05,
      "loss": 1.3316,
      "step": 100
    },
    {
      "epoch": 0.11,
      "grad_norm": 116.5,
      "learning_rate": 2.9979865771812083e-05,
      "loss": 1.7064,
      "step": 110
    },
    {
      "epoch": 0.12,
      "grad_norm": 133.0,
      "learning_rate": 2.9959731543624162e-05,
      "loss": 1.991,
      "step": 120
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.03173828125,
      "learning_rate": 2.9939597315436244e-05,
      "loss": 2.8253,
      "step": 130
    },
    {
      "epoch": 0.14,
      "grad_norm": 118.0,
      "learning_rate": 2.9919463087248323e-05,
      "loss": 2.9084,
      "step": 140
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.08251953125,
      "learning_rate": 2.9899328859060402e-05,
      "loss": 1.9426,
      "step": 150
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.0108642578125,
      "learning_rate": 2.9879194630872484e-05,
      "loss": 2.6157,
      "step": 160
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.0,
      "learning_rate": 2.9859060402684563e-05,
      "loss": 0.746,
      "step": 170
    },
    {
      "epoch": 0.18,
      "grad_norm": 63.5,
      "learning_rate": 2.9838926174496645e-05,
      "loss": 4.0875,
      "step": 180
    },
    {
      "epoch": 0.19,
      "grad_norm": 73.5,
      "learning_rate": 2.9818791946308724e-05,
      "loss": 1.4563,
      "step": 190
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.002593994140625,
      "learning_rate": 2.9798657718120806e-05,
      "loss": 1.7778,
      "step": 200
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.0074462890625,
      "learning_rate": 2.977852348993289e-05,
      "loss": 3.5656,
      "step": 210
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.0264892578125,
      "learning_rate": 2.9758389261744967e-05,
      "loss": 3.5032,
      "step": 220
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.015625,
      "learning_rate": 2.973825503355705e-05,
      "loss": 0.0001,
      "step": 230
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.00396728515625,
      "learning_rate": 2.9718120805369125e-05,
      "loss": 0.8938,
      "step": 240
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.00152587890625,
      "learning_rate": 2.9697986577181207e-05,
      "loss": 1.9172,
      "step": 250
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.006927490234375,
      "learning_rate": 2.967785234899329e-05,
      "loss": 3.1156,
      "step": 260
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.02001953125,
      "learning_rate": 2.965771812080537e-05,
      "loss": 2.3565,
      "step": 270
    },
    {
      "epoch": 0.28,
      "grad_norm": 142.0,
      "learning_rate": 2.963758389261745e-05,
      "loss": 3.2844,
      "step": 280
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.00482177734375,
      "learning_rate": 2.961744966442953e-05,
      "loss": 0.7438,
      "step": 290
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.0113525390625,
      "learning_rate": 2.9597315436241612e-05,
      "loss": 2.5375,
      "step": 300
    },
    {
      "epoch": 0.31,
      "grad_norm": 144.0,
      "learning_rate": 2.9577181208053694e-05,
      "loss": 1.7438,
      "step": 310
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.09765625,
      "learning_rate": 2.9557046979865773e-05,
      "loss": 2.1751,
      "step": 320
    },
    {
      "epoch": 0.33,
      "grad_norm": 98.5,
      "learning_rate": 2.9536912751677852e-05,
      "loss": 0.9971,
      "step": 330
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.006317138671875,
      "learning_rate": 2.951677852348993e-05,
      "loss": 0.8251,
      "step": 340
    },
    {
      "epoch": 0.35,
      "grad_norm": 58.25,
      "learning_rate": 2.9496644295302013e-05,
      "loss": 1.9774,
      "step": 350
    },
    {
      "epoch": 0.36,
      "grad_norm": 48.5,
      "learning_rate": 2.9476510067114095e-05,
      "loss": 0.825,
      "step": 360
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.00244140625,
      "learning_rate": 2.9456375838926174e-05,
      "loss": 2.3,
      "step": 370
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.005340576171875,
      "learning_rate": 2.9436241610738256e-05,
      "loss": 2.0797,
      "step": 380
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.002838134765625,
      "learning_rate": 2.9416107382550335e-05,
      "loss": 0.7438,
      "step": 390
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.0054931640625,
      "learning_rate": 2.9395973154362418e-05,
      "loss": 2.0742,
      "step": 400
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.00848388671875,
      "learning_rate": 2.93758389261745e-05,
      "loss": 2.6813,
      "step": 410
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.004669189453125,
      "learning_rate": 2.935570469798658e-05,
      "loss": 1.8661,
      "step": 420
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.008056640625,
      "learning_rate": 2.9335570469798658e-05,
      "loss": 1.6219,
      "step": 430
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.007720947265625,
      "learning_rate": 2.9315436241610736e-05,
      "loss": 0.3672,
      "step": 440
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.00537109375,
      "learning_rate": 2.929530201342282e-05,
      "loss": 1.0766,
      "step": 450
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.0025482177734375,
      "learning_rate": 2.92751677852349e-05,
      "loss": 0.1945,
      "step": 460
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.005401611328125,
      "learning_rate": 2.925503355704698e-05,
      "loss": 0.7594,
      "step": 470
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.0030364990234375,
      "learning_rate": 2.9234899328859062e-05,
      "loss": 3.2375,
      "step": 480
    },
    {
      "epoch": 0.49,
      "grad_norm": 101.0,
      "learning_rate": 2.921476510067114e-05,
      "loss": 1.9688,
      "step": 490
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.00634765625,
      "learning_rate": 2.9194630872483223e-05,
      "loss": 1.1063,
      "step": 500
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.004364013671875,
      "learning_rate": 2.9174496644295305e-05,
      "loss": 0.925,
      "step": 510
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.006805419921875,
      "learning_rate": 2.915436241610738e-05,
      "loss": 1.4313,
      "step": 520
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.0032196044921875,
      "learning_rate": 2.9134228187919463e-05,
      "loss": 0.0,
      "step": 530
    },
    {
      "epoch": 0.54,
      "grad_norm": 63.5,
      "learning_rate": 2.9114093959731542e-05,
      "loss": 1.9875,
      "step": 540
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.003997802734375,
      "learning_rate": 2.9093959731543624e-05,
      "loss": 0.8938,
      "step": 550
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.0028533935546875,
      "learning_rate": 2.9073825503355706e-05,
      "loss": 0.6906,
      "step": 560
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.007415771484375,
      "learning_rate": 2.9053691275167785e-05,
      "loss": 3.8682,
      "step": 570
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.0052490234375,
      "learning_rate": 2.9033557046979868e-05,
      "loss": 2.8688,
      "step": 580
    },
    {
      "epoch": 0.59,
      "grad_norm": 58.25,
      "learning_rate": 2.9013422818791946e-05,
      "loss": 5.1985,
      "step": 590
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.01904296875,
      "learning_rate": 2.899328859060403e-05,
      "loss": 1.4751,
      "step": 600
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.0257568359375,
      "learning_rate": 2.8973154362416108e-05,
      "loss": 2.7267,
      "step": 610
    },
    {
      "epoch": 0.62,
      "grad_norm": 47.5,
      "learning_rate": 2.8953020134228186e-05,
      "loss": 0.4563,
      "step": 620
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.0101318359375,
      "learning_rate": 2.893288590604027e-05,
      "loss": 0.8344,
      "step": 630
    },
    {
      "epoch": 0.64,
      "grad_norm": 106.5,
      "learning_rate": 2.891275167785235e-05,
      "loss": 4.8016,
      "step": 640
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.003997802734375,
      "learning_rate": 2.889261744966443e-05,
      "loss": 1.05,
      "step": 650
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.0,
      "learning_rate": 2.8872483221476512e-05,
      "loss": 1.4592,
      "step": 660
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.006256103515625,
      "learning_rate": 2.885234899328859e-05,
      "loss": 0.2938,
      "step": 670
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.0034942626953125,
      "learning_rate": 2.8832214765100673e-05,
      "loss": 3.4375,
      "step": 680
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.00127410888671875,
      "learning_rate": 2.8812080536912755e-05,
      "loss": 1.4465,
      "step": 690
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.00052642822265625,
      "learning_rate": 2.879194630872483e-05,
      "loss": 1.4688,
      "step": 700
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.000537872314453125,
      "learning_rate": 2.8771812080536913e-05,
      "loss": 0.7813,
      "step": 710
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.000774383544921875,
      "learning_rate": 2.8751677852348992e-05,
      "loss": 1.4047,
      "step": 720
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.0037384033203125,
      "learning_rate": 2.8731543624161074e-05,
      "loss": 1.4125,
      "step": 730
    },
    {
      "epoch": 0.74,
      "grad_norm": 42.5,
      "learning_rate": 2.8711409395973157e-05,
      "loss": 1.6115,
      "step": 740
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.003692626953125,
      "learning_rate": 2.8691275167785235e-05,
      "loss": 1.8188,
      "step": 750
    },
    {
      "epoch": 0.76,
      "grad_norm": 35.75,
      "learning_rate": 2.8671140939597318e-05,
      "loss": 1.8719,
      "step": 760
    },
    {
      "epoch": 0.77,
      "grad_norm": 46.0,
      "learning_rate": 2.8651006711409397e-05,
      "loss": 1.5766,
      "step": 770
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.006591796875,
      "learning_rate": 2.863087248322148e-05,
      "loss": 0.7532,
      "step": 780
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.001983642578125,
      "learning_rate": 2.8610738255033558e-05,
      "loss": 1.3351,
      "step": 790
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.0067138671875,
      "learning_rate": 2.8590604026845637e-05,
      "loss": 0.9328,
      "step": 800
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.0021209716796875,
      "learning_rate": 2.857046979865772e-05,
      "loss": 1.4313,
      "step": 810
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.0013275146484375,
      "learning_rate": 2.8550335570469798e-05,
      "loss": 1.8063,
      "step": 820
    },
    {
      "epoch": 0.83,
      "grad_norm": 51.0,
      "learning_rate": 2.853020134228188e-05,
      "loss": 2.9156,
      "step": 830
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.0016021728515625,
      "learning_rate": 2.8510067114093962e-05,
      "loss": 2.3875,
      "step": 840
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.0035400390625,
      "learning_rate": 2.848993288590604e-05,
      "loss": 1.5258,
      "step": 850
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.0125732421875,
      "learning_rate": 2.8469798657718123e-05,
      "loss": 0.6563,
      "step": 860
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.00384521484375,
      "learning_rate": 2.8449664429530202e-05,
      "loss": 1.4531,
      "step": 870
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.0031280517578125,
      "learning_rate": 2.8429530201342284e-05,
      "loss": 0.8102,
      "step": 880
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.00145721435546875,
      "learning_rate": 2.8409395973154363e-05,
      "loss": 0.0,
      "step": 890
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.001983642578125,
      "learning_rate": 2.8389261744966442e-05,
      "loss": 1.5539,
      "step": 900
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.00171661376953125,
      "learning_rate": 2.8369127516778524e-05,
      "loss": 0.7484,
      "step": 910
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.00182342529296875,
      "learning_rate": 2.8348993288590603e-05,
      "loss": 1.45,
      "step": 920
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.001953125,
      "learning_rate": 2.8328859060402685e-05,
      "loss": 1.5594,
      "step": 930
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.0013427734375,
      "learning_rate": 2.8308724832214768e-05,
      "loss": 0.6875,
      "step": 940
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.00213623046875,
      "learning_rate": 2.8288590604026847e-05,
      "loss": 0.5563,
      "step": 950
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.00151824951171875,
      "learning_rate": 2.826845637583893e-05,
      "loss": 0.5719,
      "step": 960
    },
    {
      "epoch": 0.97,
      "grad_norm": 52.5,
      "learning_rate": 2.8248322147651008e-05,
      "loss": 1.4625,
      "step": 970
    },
    {
      "epoch": 0.98,
      "grad_norm": 53.25,
      "learning_rate": 2.8228187919463087e-05,
      "loss": 2.4422,
      "step": 980
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.00189208984375,
      "learning_rate": 2.820805369127517e-05,
      "loss": 1.8641,
      "step": 990
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.002899169921875,
      "learning_rate": 2.8187919463087248e-05,
      "loss": 1.15,
      "step": 1000
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.5363391637802124,
      "eval_runtime": 31.7234,
      "eval_samples_per_second": 3.152,
      "eval_steps_per_second": 3.152,
      "step": 1000
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.002349853515625,
      "learning_rate": 2.816778523489933e-05,
      "loss": 0.7234,
      "step": 1010
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.002471923828125,
      "learning_rate": 2.814765100671141e-05,
      "loss": 2.9414,
      "step": 1020
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.0038909912109375,
      "learning_rate": 2.812751677852349e-05,
      "loss": 1.5156,
      "step": 1030
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.0038604736328125,
      "learning_rate": 2.8107382550335573e-05,
      "loss": 0.0,
      "step": 1040
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.00390625,
      "learning_rate": 2.8087248322147652e-05,
      "loss": 1.7797,
      "step": 1050
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.0034332275390625,
      "learning_rate": 2.8067114093959734e-05,
      "loss": 2.4938,
      "step": 1060
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.0062255859375,
      "learning_rate": 2.804697986577181e-05,
      "loss": 0.8219,
      "step": 1070
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.004638671875,
      "learning_rate": 2.8026845637583892e-05,
      "loss": 1.3813,
      "step": 1080
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.0027923583984375,
      "learning_rate": 2.8006711409395974e-05,
      "loss": 0.2485,
      "step": 1090
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.005462646484375,
      "learning_rate": 2.7986577181208053e-05,
      "loss": 1.0125,
      "step": 1100
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.001953125,
      "learning_rate": 2.7966442953020136e-05,
      "loss": 0.5714,
      "step": 1110
    },
    {
      "epoch": 1.12,
      "grad_norm": 87.0,
      "learning_rate": 2.7946308724832214e-05,
      "loss": 1.7992,
      "step": 1120
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.0030517578125,
      "learning_rate": 2.7926174496644297e-05,
      "loss": 1.3281,
      "step": 1130
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 0.0027923583984375,
      "learning_rate": 2.790604026845638e-05,
      "loss": 1.3197,
      "step": 1140
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.0030670166015625,
      "learning_rate": 2.7885906040268458e-05,
      "loss": 0.7813,
      "step": 1150
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.0031890869140625,
      "learning_rate": 2.7865771812080537e-05,
      "loss": 0.0,
      "step": 1160
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.0021209716796875,
      "learning_rate": 2.7845637583892616e-05,
      "loss": 0.0,
      "step": 1170
    },
    {
      "epoch": 1.18,
      "grad_norm": 46.5,
      "learning_rate": 2.7825503355704698e-05,
      "loss": 1.3406,
      "step": 1180
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.0028228759765625,
      "learning_rate": 2.780536912751678e-05,
      "loss": 1.3984,
      "step": 1190
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.0016937255859375,
      "learning_rate": 2.778523489932886e-05,
      "loss": 0.9849,
      "step": 1200
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.0035858154296875,
      "learning_rate": 2.776510067114094e-05,
      "loss": 0.975,
      "step": 1210
    },
    {
      "epoch": 1.22,
      "grad_norm": 33.75,
      "learning_rate": 2.774496644295302e-05,
      "loss": 0.3125,
      "step": 1220
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.00176239013671875,
      "learning_rate": 2.7724832214765102e-05,
      "loss": 1.1563,
      "step": 1230
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.002197265625,
      "learning_rate": 2.7704697986577185e-05,
      "loss": 0.6,
      "step": 1240
    },
    {
      "epoch": 1.25,
      "grad_norm": 35.75,
      "learning_rate": 2.768456375838926e-05,
      "loss": 0.9992,
      "step": 1250
    },
    {
      "epoch": 1.26,
      "grad_norm": 78.5,
      "learning_rate": 2.7664429530201342e-05,
      "loss": 2.0172,
      "step": 1260
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.0012664794921875,
      "learning_rate": 2.764429530201342e-05,
      "loss": 0.2953,
      "step": 1270
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.0010223388671875,
      "learning_rate": 2.7624161073825503e-05,
      "loss": 0.9938,
      "step": 1280
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.0008087158203125,
      "learning_rate": 2.7604026845637586e-05,
      "loss": 0.4406,
      "step": 1290
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.00164031982421875,
      "learning_rate": 2.7583892617449664e-05,
      "loss": 0.8563,
      "step": 1300
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.00110626220703125,
      "learning_rate": 2.7563758389261747e-05,
      "loss": 1.5578,
      "step": 1310
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.000934600830078125,
      "learning_rate": 2.7543624161073826e-05,
      "loss": 1.7063,
      "step": 1320
    },
    {
      "epoch": 1.33,
      "grad_norm": 78.5,
      "learning_rate": 2.7523489932885908e-05,
      "loss": 2.2945,
      "step": 1330
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.00122833251953125,
      "learning_rate": 2.750335570469799e-05,
      "loss": 0.1461,
      "step": 1340
    },
    {
      "epoch": 1.35,
      "grad_norm": 23.625,
      "learning_rate": 2.7483221476510066e-05,
      "loss": 0.8727,
      "step": 1350
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.0019073486328125,
      "learning_rate": 2.7463087248322148e-05,
      "loss": 2.4625,
      "step": 1360
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.00186920166015625,
      "learning_rate": 2.7442953020134227e-05,
      "loss": 0.5953,
      "step": 1370
    },
    {
      "epoch": 1.38,
      "grad_norm": 34.5,
      "learning_rate": 2.742281879194631e-05,
      "loss": 0.6484,
      "step": 1380
    },
    {
      "epoch": 1.3900000000000001,
      "grad_norm": 0.003143310546875,
      "learning_rate": 2.740268456375839e-05,
      "loss": 2.5781,
      "step": 1390
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.0025177001953125,
      "learning_rate": 2.738255033557047e-05,
      "loss": 2.4688,
      "step": 1400
    },
    {
      "epoch": 1.41,
      "grad_norm": 70.0,
      "learning_rate": 2.7362416107382552e-05,
      "loss": 0.5359,
      "step": 1410
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.0018463134765625,
      "learning_rate": 2.734228187919463e-05,
      "loss": 1.1969,
      "step": 1420
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.002105712890625,
      "learning_rate": 2.7322147651006713e-05,
      "loss": 1.25,
      "step": 1430
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.0011444091796875,
      "learning_rate": 2.7302013422818792e-05,
      "loss": 1.8828,
      "step": 1440
    },
    {
      "epoch": 1.45,
      "grad_norm": 92.0,
      "learning_rate": 2.728187919463087e-05,
      "loss": 1.6063,
      "step": 1450
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.001251220703125,
      "learning_rate": 2.7261744966442953e-05,
      "loss": 1.2516,
      "step": 1460
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.00142669677734375,
      "learning_rate": 2.7241610738255032e-05,
      "loss": 1.2969,
      "step": 1470
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.0,
      "learning_rate": 2.7221476510067115e-05,
      "loss": 0.8009,
      "step": 1480
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.0013885498046875,
      "learning_rate": 2.7201342281879197e-05,
      "loss": 1.0318,
      "step": 1490
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.00091552734375,
      "learning_rate": 2.7181208053691276e-05,
      "loss": 0.8039,
      "step": 1500
    },
    {
      "epoch": 1.51,
      "grad_norm": 45.75,
      "learning_rate": 2.7161073825503358e-05,
      "loss": 0.7375,
      "step": 1510
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.0038299560546875,
      "learning_rate": 2.7140939597315437e-05,
      "loss": 0.6839,
      "step": 1520
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.00115203857421875,
      "learning_rate": 2.7120805369127516e-05,
      "loss": 3.2297,
      "step": 1530
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.000774383544921875,
      "learning_rate": 2.7100671140939598e-05,
      "loss": 1.5656,
      "step": 1540
    },
    {
      "epoch": 1.55,
      "grad_norm": 63.5,
      "learning_rate": 2.7080536912751677e-05,
      "loss": 1.1875,
      "step": 1550
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.002655029296875,
      "learning_rate": 2.706040268456376e-05,
      "loss": 0.7875,
      "step": 1560
    },
    {
      "epoch": 1.5699999999999998,
      "grad_norm": 0.00104522705078125,
      "learning_rate": 2.7040268456375838e-05,
      "loss": 2.6314,
      "step": 1570
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.00095367431640625,
      "learning_rate": 2.702013422818792e-05,
      "loss": 1.6875,
      "step": 1580
    },
    {
      "epoch": 1.5899999999999999,
      "grad_norm": 0.00116729736328125,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 1.325,
      "step": 1590
    },
    {
      "epoch": 1.6,
      "grad_norm": 72.5,
      "learning_rate": 2.697986577181208e-05,
      "loss": 1.6016,
      "step": 1600
    },
    {
      "epoch": 1.6099999999999999,
      "grad_norm": 0.0010986328125,
      "learning_rate": 2.6959731543624163e-05,
      "loss": 2.9706,
      "step": 1610
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.0,
      "learning_rate": 2.6939597315436242e-05,
      "loss": 1.271,
      "step": 1620
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.0015106201171875,
      "learning_rate": 2.691946308724832e-05,
      "loss": 0.0,
      "step": 1630
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 47.75,
      "learning_rate": 2.6899328859060403e-05,
      "loss": 1.7,
      "step": 1640
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.00078582763671875,
      "learning_rate": 2.6879194630872482e-05,
      "loss": 1.2188,
      "step": 1650
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 0.000682830810546875,
      "learning_rate": 2.6859060402684565e-05,
      "loss": 0.9727,
      "step": 1660
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.00067138671875,
      "learning_rate": 2.6838926174496647e-05,
      "loss": 0.5859,
      "step": 1670
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.000766754150390625,
      "learning_rate": 2.6818791946308726e-05,
      "loss": 1.1625,
      "step": 1680
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.0004425048828125,
      "learning_rate": 2.6798657718120808e-05,
      "loss": 1.8676,
      "step": 1690
    },
    {
      "epoch": 1.7,
      "grad_norm": 32.75,
      "learning_rate": 2.6778523489932887e-05,
      "loss": 1.6112,
      "step": 1700
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.00160980224609375,
      "learning_rate": 2.6758389261744966e-05,
      "loss": 1.6766,
      "step": 1710
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.000537872314453125,
      "learning_rate": 2.6738255033557048e-05,
      "loss": 0.3703,
      "step": 1720
    },
    {
      "epoch": 1.73,
      "grad_norm": 32.25,
      "learning_rate": 2.6718120805369127e-05,
      "loss": 1.9242,
      "step": 1730
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.000690460205078125,
      "learning_rate": 2.669798657718121e-05,
      "loss": 2.4203,
      "step": 1740
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.0008087158203125,
      "learning_rate": 2.6677852348993288e-05,
      "loss": 0.3516,
      "step": 1750
    },
    {
      "epoch": 1.76,
      "grad_norm": 35.0,
      "learning_rate": 2.665771812080537e-05,
      "loss": 1.7922,
      "step": 1760
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.00086212158203125,
      "learning_rate": 2.6637583892617452e-05,
      "loss": 0.9547,
      "step": 1770
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.00091552734375,
      "learning_rate": 2.661744966442953e-05,
      "loss": 1.6641,
      "step": 1780
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.000835418701171875,
      "learning_rate": 2.6597315436241614e-05,
      "loss": 1.225,
      "step": 1790
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.000843048095703125,
      "learning_rate": 2.6577181208053692e-05,
      "loss": 1.25,
      "step": 1800
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.00141143798828125,
      "learning_rate": 2.655704697986577e-05,
      "loss": 1.3484,
      "step": 1810
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 73.0,
      "learning_rate": 2.6536912751677854e-05,
      "loss": 2.3359,
      "step": 1820
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.0021209716796875,
      "learning_rate": 2.6516778523489932e-05,
      "loss": 0.5781,
      "step": 1830
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.0009918212890625,
      "learning_rate": 2.6496644295302015e-05,
      "loss": 0.3688,
      "step": 1840
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.0007781982421875,
      "learning_rate": 2.6476510067114094e-05,
      "loss": 1.2422,
      "step": 1850
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 0.000934600830078125,
      "learning_rate": 2.6456375838926176e-05,
      "loss": 0.2156,
      "step": 1860
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.000820159912109375,
      "learning_rate": 2.6436241610738258e-05,
      "loss": 2.4406,
      "step": 1870
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.0009307861328125,
      "learning_rate": 2.6416107382550337e-05,
      "loss": 1.45,
      "step": 1880
    },
    {
      "epoch": 1.8900000000000001,
      "grad_norm": 30.0,
      "learning_rate": 2.639597315436242e-05,
      "loss": 1.45,
      "step": 1890
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.0016326904296875,
      "learning_rate": 2.6375838926174495e-05,
      "loss": 1.4383,
      "step": 1900
    },
    {
      "epoch": 1.9100000000000001,
      "grad_norm": 0.00177001953125,
      "learning_rate": 2.6355704697986577e-05,
      "loss": 0.4844,
      "step": 1910
    },
    {
      "epoch": 1.92,
      "grad_norm": 30.375,
      "learning_rate": 2.633557046979866e-05,
      "loss": 0.6867,
      "step": 1920
    },
    {
      "epoch": 1.9300000000000002,
      "grad_norm": 34.5,
      "learning_rate": 2.6315436241610738e-05,
      "loss": 1.9594,
      "step": 1930
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.0009307861328125,
      "learning_rate": 2.629530201342282e-05,
      "loss": 0.4625,
      "step": 1940
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.000591278076171875,
      "learning_rate": 2.62751677852349e-05,
      "loss": 1.3297,
      "step": 1950
    },
    {
      "epoch": 1.96,
      "grad_norm": 30.75,
      "learning_rate": 2.625503355704698e-05,
      "loss": 1.3523,
      "step": 1960
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.000759124755859375,
      "learning_rate": 2.6234899328859064e-05,
      "loss": 0.5719,
      "step": 1970
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.0019073486328125,
      "learning_rate": 2.6214765100671142e-05,
      "loss": 1.9188,
      "step": 1980
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.00069427490234375,
      "learning_rate": 2.619463087248322e-05,
      "loss": 2.2688,
      "step": 1990
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.00115966796875,
      "learning_rate": 2.61744966442953e-05,
      "loss": 3.3883,
      "step": 2000
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.4243801832199097,
      "eval_runtime": 31.6708,
      "eval_samples_per_second": 3.157,
      "eval_steps_per_second": 3.157,
      "step": 2000
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.0,
      "learning_rate": 2.6154362416107382e-05,
      "loss": 0.4349,
      "step": 2010
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.00136566162109375,
      "learning_rate": 2.6134228187919465e-05,
      "loss": 0.575,
      "step": 2020
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.000946044921875,
      "learning_rate": 2.6114093959731544e-05,
      "loss": 1.2609,
      "step": 2030
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.001007080078125,
      "learning_rate": 2.6093959731543626e-05,
      "loss": 0.7688,
      "step": 2040
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.0010986328125,
      "learning_rate": 2.6073825503355705e-05,
      "loss": 1.5637,
      "step": 2050
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.00122833251953125,
      "learning_rate": 2.6053691275167787e-05,
      "loss": 1.3313,
      "step": 2060
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.0016021728515625,
      "learning_rate": 2.603355704697987e-05,
      "loss": 0.3891,
      "step": 2070
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.00167083740234375,
      "learning_rate": 2.6013422818791945e-05,
      "loss": 2.4656,
      "step": 2080
    },
    {
      "epoch": 2.09,
      "grad_norm": 60.5,
      "learning_rate": 2.5993288590604027e-05,
      "loss": 2.6109,
      "step": 2090
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.001373291015625,
      "learning_rate": 2.5973154362416106e-05,
      "loss": 0.675,
      "step": 2100
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.00153350830078125,
      "learning_rate": 2.5953020134228188e-05,
      "loss": 0.0,
      "step": 2110
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.00189971923828125,
      "learning_rate": 2.593288590604027e-05,
      "loss": 1.4016,
      "step": 2120
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.0022125244140625,
      "learning_rate": 2.591275167785235e-05,
      "loss": 0.0,
      "step": 2130
    },
    {
      "epoch": 2.14,
      "grad_norm": 33.0,
      "learning_rate": 2.589261744966443e-05,
      "loss": 1.5734,
      "step": 2140
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.0017547607421875,
      "learning_rate": 2.587248322147651e-05,
      "loss": 1.9453,
      "step": 2150
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.00156402587890625,
      "learning_rate": 2.5852348993288593e-05,
      "loss": 0.5125,
      "step": 2160
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.00156402587890625,
      "learning_rate": 2.583221476510067e-05,
      "loss": 1.2094,
      "step": 2170
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.00262451171875,
      "learning_rate": 2.581208053691275e-05,
      "loss": 0.3297,
      "step": 2180
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.002044677734375,
      "learning_rate": 2.5791946308724833e-05,
      "loss": 0.7198,
      "step": 2190
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.000804901123046875,
      "learning_rate": 2.577181208053691e-05,
      "loss": 1.9719,
      "step": 2200
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.000545501708984375,
      "learning_rate": 2.5751677852348994e-05,
      "loss": 2.1969,
      "step": 2210
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.00048828125,
      "learning_rate": 2.5731543624161076e-05,
      "loss": 0.1992,
      "step": 2220
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.000675201416015625,
      "learning_rate": 2.5711409395973155e-05,
      "loss": 0.8641,
      "step": 2230
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.00058746337890625,
      "learning_rate": 2.5691275167785237e-05,
      "loss": 2.5035,
      "step": 2240
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.000797271728515625,
      "learning_rate": 2.5671140939597316e-05,
      "loss": 0.6656,
      "step": 2250
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.0011138916015625,
      "learning_rate": 2.5651006711409398e-05,
      "loss": 1.4844,
      "step": 2260
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.000858306884765625,
      "learning_rate": 2.5630872483221477e-05,
      "loss": 0.0,
      "step": 2270
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.000843048095703125,
      "learning_rate": 2.5610738255033556e-05,
      "loss": 0.925,
      "step": 2280
    },
    {
      "epoch": 2.29,
      "grad_norm": 75.5,
      "learning_rate": 2.5590604026845638e-05,
      "loss": 1.0188,
      "step": 2290
    },
    {
      "epoch": 2.3,
      "grad_norm": 96.5,
      "learning_rate": 2.5570469798657717e-05,
      "loss": 1.9883,
      "step": 2300
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.0005340576171875,
      "learning_rate": 2.55503355704698e-05,
      "loss": 0.0,
      "step": 2310
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.00077056884765625,
      "learning_rate": 2.553020134228188e-05,
      "loss": 1.4578,
      "step": 2320
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.000392913818359375,
      "learning_rate": 2.551006711409396e-05,
      "loss": 0.4438,
      "step": 2330
    },
    {
      "epoch": 2.34,
      "grad_norm": 47.25,
      "learning_rate": 2.5489932885906043e-05,
      "loss": 1.8203,
      "step": 2340
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.00060272216796875,
      "learning_rate": 2.546979865771812e-05,
      "loss": 0.2469,
      "step": 2350
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.00081634521484375,
      "learning_rate": 2.54496644295302e-05,
      "loss": 0.4898,
      "step": 2360
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.00055694580078125,
      "learning_rate": 2.5429530201342283e-05,
      "loss": 1.5313,
      "step": 2370
    },
    {
      "epoch": 2.38,
      "grad_norm": 45.75,
      "learning_rate": 2.540939597315436e-05,
      "loss": 2.025,
      "step": 2380
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.000438690185546875,
      "learning_rate": 2.5389261744966444e-05,
      "loss": 1.3453,
      "step": 2390
    },
    {
      "epoch": 2.4,
      "grad_norm": 30.875,
      "learning_rate": 2.5369127516778523e-05,
      "loss": 0.4969,
      "step": 2400
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.000492095947265625,
      "learning_rate": 2.5348993288590605e-05,
      "loss": 0.6484,
      "step": 2410
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.000347137451171875,
      "learning_rate": 2.5328859060402687e-05,
      "loss": 0.5031,
      "step": 2420
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.000335693359375,
      "learning_rate": 2.5308724832214766e-05,
      "loss": 0.875,
      "step": 2430
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.00051116943359375,
      "learning_rate": 2.5288590604026848e-05,
      "loss": 2.7047,
      "step": 2440
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.001007080078125,
      "learning_rate": 2.5268456375838924e-05,
      "loss": 0.3703,
      "step": 2450
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.000743865966796875,
      "learning_rate": 2.5248322147651006e-05,
      "loss": 2.0688,
      "step": 2460
    },
    {
      "epoch": 2.4699999999999998,
      "grad_norm": 0.00037384033203125,
      "learning_rate": 2.5228187919463088e-05,
      "loss": 0.1613,
      "step": 2470
    },
    {
      "epoch": 2.48,
      "grad_norm": 36.25,
      "learning_rate": 2.5208053691275167e-05,
      "loss": 2.7281,
      "step": 2480
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.0004253387451171875,
      "learning_rate": 2.518791946308725e-05,
      "loss": 1.1969,
      "step": 2490
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.0003376007080078125,
      "learning_rate": 2.5167785234899328e-05,
      "loss": 1.1375,
      "step": 2500
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.0,
      "learning_rate": 2.514765100671141e-05,
      "loss": 0.7348,
      "step": 2510
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.0002899169921875,
      "learning_rate": 2.5127516778523493e-05,
      "loss": 2.1781,
      "step": 2520
    },
    {
      "epoch": 2.5300000000000002,
      "grad_norm": 0.0005950927734375,
      "learning_rate": 2.510738255033557e-05,
      "loss": 1.5313,
      "step": 2530
    },
    {
      "epoch": 2.54,
      "grad_norm": 40.25,
      "learning_rate": 2.508724832214765e-05,
      "loss": 0.8641,
      "step": 2540
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.0002613067626953125,
      "learning_rate": 2.506711409395973e-05,
      "loss": 0.6578,
      "step": 2550
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.000347137451171875,
      "learning_rate": 2.504697986577181e-05,
      "loss": 0.8234,
      "step": 2560
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.000339508056640625,
      "learning_rate": 2.5026845637583894e-05,
      "loss": 0.35,
      "step": 2570
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.0003814697265625,
      "learning_rate": 2.5006711409395973e-05,
      "loss": 0.7266,
      "step": 2580
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.00048828125,
      "learning_rate": 2.4986577181208055e-05,
      "loss": 0.1367,
      "step": 2590
    },
    {
      "epoch": 2.6,
      "grad_norm": 35.5,
      "learning_rate": 2.4966442953020137e-05,
      "loss": 1.1618,
      "step": 2600
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.000339508056640625,
      "learning_rate": 2.4946308724832216e-05,
      "loss": 2.8016,
      "step": 2610
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.0003185272216796875,
      "learning_rate": 2.4926174496644298e-05,
      "loss": 1.0336,
      "step": 2620
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.0004291534423828125,
      "learning_rate": 2.4906040268456374e-05,
      "loss": 1.0406,
      "step": 2630
    },
    {
      "epoch": 2.64,
      "grad_norm": 76.5,
      "learning_rate": 2.4885906040268456e-05,
      "loss": 1.7359,
      "step": 2640
    },
    {
      "epoch": 2.65,
      "grad_norm": 91.5,
      "learning_rate": 2.4865771812080538e-05,
      "loss": 1.1297,
      "step": 2650
    },
    {
      "epoch": 2.66,
      "grad_norm": 41.0,
      "learning_rate": 2.4845637583892617e-05,
      "loss": 1.6094,
      "step": 2660
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.0005035400390625,
      "learning_rate": 2.48255033557047e-05,
      "loss": 1.6586,
      "step": 2670
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.0003204345703125,
      "learning_rate": 2.4805369127516778e-05,
      "loss": 0.6813,
      "step": 2680
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.0004520416259765625,
      "learning_rate": 2.478523489932886e-05,
      "loss": 1.8234,
      "step": 2690
    },
    {
      "epoch": 2.7,
      "grad_norm": 40.75,
      "learning_rate": 2.4765100671140943e-05,
      "loss": 1.275,
      "step": 2700
    },
    {
      "epoch": 2.71,
      "grad_norm": 53.0,
      "learning_rate": 2.474496644295302e-05,
      "loss": 1.3908,
      "step": 2710
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.0004444122314453125,
      "learning_rate": 2.4724832214765104e-05,
      "loss": 0.7656,
      "step": 2720
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.000659942626953125,
      "learning_rate": 2.470469798657718e-05,
      "loss": 1.6438,
      "step": 2730
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.0003986358642578125,
      "learning_rate": 2.468456375838926e-05,
      "loss": 1.225,
      "step": 2740
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.0004863739013671875,
      "learning_rate": 2.4664429530201344e-05,
      "loss": 1.3688,
      "step": 2750
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.00057220458984375,
      "learning_rate": 2.4644295302013423e-05,
      "loss": 1.2617,
      "step": 2760
    },
    {
      "epoch": 2.77,
      "grad_norm": 81.0,
      "learning_rate": 2.4624161073825505e-05,
      "loss": 2.2656,
      "step": 2770
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 0.000492095947265625,
      "learning_rate": 2.4604026845637584e-05,
      "loss": 0.4344,
      "step": 2780
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.00083160400390625,
      "learning_rate": 2.4583892617449666e-05,
      "loss": 0.0,
      "step": 2790
    },
    {
      "epoch": 2.8,
      "grad_norm": 40.0,
      "learning_rate": 2.456375838926175e-05,
      "loss": 0.5196,
      "step": 2800
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.0003452301025390625,
      "learning_rate": 2.4543624161073827e-05,
      "loss": 1.4588,
      "step": 2810
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.000499725341796875,
      "learning_rate": 2.4523489932885906e-05,
      "loss": 0.5781,
      "step": 2820
    },
    {
      "epoch": 2.83,
      "grad_norm": 41.75,
      "learning_rate": 2.4503355704697985e-05,
      "loss": 2.0992,
      "step": 2830
    },
    {
      "epoch": 2.84,
      "grad_norm": 42.0,
      "learning_rate": 2.4483221476510067e-05,
      "loss": 0.5797,
      "step": 2840
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.0004596710205078125,
      "learning_rate": 2.446308724832215e-05,
      "loss": 0.29,
      "step": 2850
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.0004558563232421875,
      "learning_rate": 2.444295302013423e-05,
      "loss": 0.0,
      "step": 2860
    },
    {
      "epoch": 2.87,
      "grad_norm": 31.625,
      "learning_rate": 2.442281879194631e-05,
      "loss": 1.018,
      "step": 2870
    },
    {
      "epoch": 2.88,
      "grad_norm": 28.625,
      "learning_rate": 2.440268456375839e-05,
      "loss": 0.1641,
      "step": 2880
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.0003490447998046875,
      "learning_rate": 2.438255033557047e-05,
      "loss": 0.1195,
      "step": 2890
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.000324249267578125,
      "learning_rate": 2.4362416107382554e-05,
      "loss": 2.1625,
      "step": 2900
    },
    {
      "epoch": 2.91,
      "grad_norm": 68.5,
      "learning_rate": 2.434228187919463e-05,
      "loss": 1.4688,
      "step": 2910
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.000408172607421875,
      "learning_rate": 2.432214765100671e-05,
      "loss": 1.6609,
      "step": 2920
    },
    {
      "epoch": 2.93,
      "grad_norm": 34.25,
      "learning_rate": 2.430201342281879e-05,
      "loss": 0.3938,
      "step": 2930
    },
    {
      "epoch": 2.94,
      "grad_norm": 43.75,
      "learning_rate": 2.4281879194630873e-05,
      "loss": 1.3344,
      "step": 2940
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.000370025634765625,
      "learning_rate": 2.4261744966442955e-05,
      "loss": 1.7734,
      "step": 2950
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.000396728515625,
      "learning_rate": 2.4241610738255034e-05,
      "loss": 1.1703,
      "step": 2960
    },
    {
      "epoch": 2.9699999999999998,
      "grad_norm": 86.0,
      "learning_rate": 2.4221476510067116e-05,
      "loss": 1.807,
      "step": 2970
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.0002918243408203125,
      "learning_rate": 2.4201342281879195e-05,
      "loss": 0.3375,
      "step": 2980
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.0,
      "learning_rate": 2.4181208053691277e-05,
      "loss": 0.9041,
      "step": 2990
    },
    {
      "epoch": 3.0,
      "grad_norm": 37.5,
      "learning_rate": 2.4161073825503356e-05,
      "loss": 3.0688,
      "step": 3000
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.4237518310546875,
      "eval_runtime": 31.6733,
      "eval_samples_per_second": 3.157,
      "eval_steps_per_second": 3.157,
      "step": 3000
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.0002002716064453125,
      "learning_rate": 2.4140939597315435e-05,
      "loss": 1.9156,
      "step": 3010
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.00029754638671875,
      "learning_rate": 2.4120805369127517e-05,
      "loss": 0.6298,
      "step": 3020
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.0002498626708984375,
      "learning_rate": 2.4100671140939596e-05,
      "loss": 0.2484,
      "step": 3030
    },
    {
      "epoch": 3.04,
      "grad_norm": 37.25,
      "learning_rate": 2.408053691275168e-05,
      "loss": 1.5603,
      "step": 3040
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.000507354736328125,
      "learning_rate": 2.406040268456376e-05,
      "loss": 0.4188,
      "step": 3050
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.00020313262939453125,
      "learning_rate": 2.404026845637584e-05,
      "loss": 1.2055,
      "step": 3060
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.000263214111328125,
      "learning_rate": 2.4020134228187922e-05,
      "loss": 0.9656,
      "step": 3070
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.00023555755615234375,
      "learning_rate": 2.4e-05,
      "loss": 1.4422,
      "step": 3080
    },
    {
      "epoch": 3.09,
      "grad_norm": 0.00019550323486328125,
      "learning_rate": 2.397986577181208e-05,
      "loss": 0.8625,
      "step": 3090
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.000263214111328125,
      "learning_rate": 2.3959731543624162e-05,
      "loss": 0.5398,
      "step": 3100
    },
    {
      "epoch": 3.11,
      "grad_norm": 0.00043487548828125,
      "learning_rate": 2.393959731543624e-05,
      "loss": 0.7734,
      "step": 3110
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.0009613037109375,
      "learning_rate": 2.3919463087248323e-05,
      "loss": 1.0,
      "step": 3120
    },
    {
      "epoch": 3.13,
      "grad_norm": 39.0,
      "learning_rate": 2.3899328859060402e-05,
      "loss": 2.9141,
      "step": 3130
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.0003108978271484375,
      "learning_rate": 2.3879194630872484e-05,
      "loss": 1.6719,
      "step": 3140
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.0003032684326171875,
      "learning_rate": 2.3859060402684566e-05,
      "loss": 1.6281,
      "step": 3150
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.0002155303955078125,
      "learning_rate": 2.3838926174496645e-05,
      "loss": 0.3203,
      "step": 3160
    },
    {
      "epoch": 3.17,
      "grad_norm": 0.00030517578125,
      "learning_rate": 2.3818791946308727e-05,
      "loss": 0.4523,
      "step": 3170
    },
    {
      "epoch": 3.18,
      "grad_norm": 36.25,
      "learning_rate": 2.3798657718120806e-05,
      "loss": 0.8031,
      "step": 3180
    },
    {
      "epoch": 3.19,
      "grad_norm": 40.0,
      "learning_rate": 2.3778523489932885e-05,
      "loss": 1.0203,
      "step": 3190
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.0,
      "learning_rate": 2.3758389261744967e-05,
      "loss": 1.2908,
      "step": 3200
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.0002689361572265625,
      "learning_rate": 2.3738255033557046e-05,
      "loss": 1.2781,
      "step": 3210
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.0,
      "learning_rate": 2.371812080536913e-05,
      "loss": 1.2461,
      "step": 3220
    },
    {
      "epoch": 3.23,
      "grad_norm": 0.0004405975341796875,
      "learning_rate": 2.3697986577181207e-05,
      "loss": 1.5203,
      "step": 3230
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.0003528594970703125,
      "learning_rate": 2.367785234899329e-05,
      "loss": 1.2297,
      "step": 3240
    },
    {
      "epoch": 3.25,
      "grad_norm": 52.75,
      "learning_rate": 2.3657718120805372e-05,
      "loss": 3.3781,
      "step": 3250
    },
    {
      "epoch": 3.26,
      "grad_norm": 34.75,
      "learning_rate": 2.363758389261745e-05,
      "loss": 0.7047,
      "step": 3260
    },
    {
      "epoch": 3.27,
      "grad_norm": 40.0,
      "learning_rate": 2.3617449664429533e-05,
      "loss": 1.4344,
      "step": 3270
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 0.000255584716796875,
      "learning_rate": 2.359731543624161e-05,
      "loss": 1.0109,
      "step": 3280
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.00021076202392578125,
      "learning_rate": 2.357718120805369e-05,
      "loss": 0.2984,
      "step": 3290
    },
    {
      "epoch": 3.3,
      "grad_norm": 31.5,
      "learning_rate": 2.3557046979865773e-05,
      "loss": 1.5527,
      "step": 3300
    },
    {
      "epoch": 3.31,
      "grad_norm": 0.000202178955078125,
      "learning_rate": 2.3536912751677852e-05,
      "loss": 1.4109,
      "step": 3310
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.0005035400390625,
      "learning_rate": 2.3516778523489934e-05,
      "loss": 1.0992,
      "step": 3320
    },
    {
      "epoch": 3.33,
      "grad_norm": 0.00020599365234375,
      "learning_rate": 2.3496644295302013e-05,
      "loss": 1.4563,
      "step": 3330
    },
    {
      "epoch": 3.34,
      "grad_norm": 50.0,
      "learning_rate": 2.3476510067114095e-05,
      "loss": 1.007,
      "step": 3340
    },
    {
      "epoch": 3.35,
      "grad_norm": 77.5,
      "learning_rate": 2.3456375838926177e-05,
      "loss": 0.9477,
      "step": 3350
    },
    {
      "epoch": 3.36,
      "grad_norm": 76.5,
      "learning_rate": 2.3436241610738256e-05,
      "loss": 2.3445,
      "step": 3360
    },
    {
      "epoch": 3.37,
      "grad_norm": 0.000652313232421875,
      "learning_rate": 2.3416107382550335e-05,
      "loss": 0.0,
      "step": 3370
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.0025634765625,
      "learning_rate": 2.3395973154362414e-05,
      "loss": 0.4656,
      "step": 3380
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.00023746490478515625,
      "learning_rate": 2.3375838926174496e-05,
      "loss": 0.6852,
      "step": 3390
    },
    {
      "epoch": 3.4,
      "grad_norm": 79.5,
      "learning_rate": 2.335570469798658e-05,
      "loss": 2.2242,
      "step": 3400
    },
    {
      "epoch": 3.41,
      "grad_norm": 57.75,
      "learning_rate": 2.3335570469798657e-05,
      "loss": 1.299,
      "step": 3410
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.00029754638671875,
      "learning_rate": 2.331543624161074e-05,
      "loss": 1.757,
      "step": 3420
    },
    {
      "epoch": 3.43,
      "grad_norm": 0.0003414154052734375,
      "learning_rate": 2.329530201342282e-05,
      "loss": 0.5375,
      "step": 3430
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.0004596710205078125,
      "learning_rate": 2.32751677852349e-05,
      "loss": 0.35,
      "step": 3440
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.00045013427734375,
      "learning_rate": 2.3255033557046983e-05,
      "loss": 1.5719,
      "step": 3450
    },
    {
      "epoch": 3.46,
      "grad_norm": 77.5,
      "learning_rate": 2.323489932885906e-05,
      "loss": 0.8105,
      "step": 3460
    },
    {
      "epoch": 3.4699999999999998,
      "grad_norm": 0.00037384033203125,
      "learning_rate": 2.321476510067114e-05,
      "loss": 1.4281,
      "step": 3470
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.000400543212890625,
      "learning_rate": 2.319463087248322e-05,
      "loss": 1.0121,
      "step": 3480
    },
    {
      "epoch": 3.49,
      "grad_norm": 58.75,
      "learning_rate": 2.3174496644295302e-05,
      "loss": 0.3984,
      "step": 3490
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.0003108978271484375,
      "learning_rate": 2.3154362416107384e-05,
      "loss": 0.85,
      "step": 3500
    },
    {
      "epoch": 3.51,
      "grad_norm": 0.0003185272216796875,
      "learning_rate": 2.3134228187919463e-05,
      "loss": 1.3844,
      "step": 3510
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.000598907470703125,
      "learning_rate": 2.3114093959731545e-05,
      "loss": 0.7531,
      "step": 3520
    },
    {
      "epoch": 3.5300000000000002,
      "grad_norm": 0.000202178955078125,
      "learning_rate": 2.3093959731543624e-05,
      "loss": 0.0,
      "step": 3530
    },
    {
      "epoch": 3.54,
      "grad_norm": 0.0003337860107421875,
      "learning_rate": 2.3073825503355706e-05,
      "loss": 0.6125,
      "step": 3540
    },
    {
      "epoch": 3.55,
      "grad_norm": 92.0,
      "learning_rate": 2.3053691275167785e-05,
      "loss": 1.0104,
      "step": 3550
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.00034332275390625,
      "learning_rate": 2.3033557046979864e-05,
      "loss": 0.9094,
      "step": 3560
    },
    {
      "epoch": 3.57,
      "grad_norm": 0.00018405914306640625,
      "learning_rate": 2.3013422818791946e-05,
      "loss": 1.9188,
      "step": 3570
    },
    {
      "epoch": 3.58,
      "grad_norm": 0.00035858154296875,
      "learning_rate": 2.299328859060403e-05,
      "loss": 0.9,
      "step": 3580
    },
    {
      "epoch": 3.59,
      "grad_norm": 109.0,
      "learning_rate": 2.2973154362416107e-05,
      "loss": 1.6672,
      "step": 3590
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.000362396240234375,
      "learning_rate": 2.295302013422819e-05,
      "loss": 0.8828,
      "step": 3600
    },
    {
      "epoch": 3.61,
      "grad_norm": 0.00016689300537109375,
      "learning_rate": 2.293288590604027e-05,
      "loss": 0.6664,
      "step": 3610
    },
    {
      "epoch": 3.62,
      "grad_norm": 0.000247955322265625,
      "learning_rate": 2.291275167785235e-05,
      "loss": 0.0,
      "step": 3620
    },
    {
      "epoch": 3.63,
      "grad_norm": 36.75,
      "learning_rate": 2.2892617449664433e-05,
      "loss": 0.2266,
      "step": 3630
    },
    {
      "epoch": 3.64,
      "grad_norm": 46.25,
      "learning_rate": 2.2872483221476512e-05,
      "loss": 1.1156,
      "step": 3640
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.00020599365234375,
      "learning_rate": 2.285234899328859e-05,
      "loss": 0.0,
      "step": 3650
    },
    {
      "epoch": 3.66,
      "grad_norm": 0.0,
      "learning_rate": 2.283221476510067e-05,
      "loss": 1.2779,
      "step": 3660
    },
    {
      "epoch": 3.67,
      "grad_norm": 0.000370025634765625,
      "learning_rate": 2.2812080536912752e-05,
      "loss": 0.8969,
      "step": 3670
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.00023365020751953125,
      "learning_rate": 2.2791946308724834e-05,
      "loss": 1.2828,
      "step": 3680
    },
    {
      "epoch": 3.69,
      "grad_norm": 0.00020599365234375,
      "learning_rate": 2.2771812080536913e-05,
      "loss": 0.8889,
      "step": 3690
    },
    {
      "epoch": 3.7,
      "grad_norm": 79.5,
      "learning_rate": 2.2751677852348995e-05,
      "loss": 0.6469,
      "step": 3700
    },
    {
      "epoch": 3.71,
      "grad_norm": 0.00034332275390625,
      "learning_rate": 2.2731543624161074e-05,
      "loss": 1.1563,
      "step": 3710
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 0.0003414154052734375,
      "learning_rate": 2.2711409395973156e-05,
      "loss": 0.1789,
      "step": 3720
    },
    {
      "epoch": 3.73,
      "grad_norm": 0.000255584716796875,
      "learning_rate": 2.269127516778524e-05,
      "loss": 1.8375,
      "step": 3730
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.0003414154052734375,
      "learning_rate": 2.2671140939597314e-05,
      "loss": 0.5719,
      "step": 3740
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.000316619873046875,
      "learning_rate": 2.2651006711409396e-05,
      "loss": 1.2906,
      "step": 3750
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.00034332275390625,
      "learning_rate": 2.2630872483221475e-05,
      "loss": 0.6016,
      "step": 3760
    },
    {
      "epoch": 3.77,
      "grad_norm": 0.0003490447998046875,
      "learning_rate": 2.2610738255033557e-05,
      "loss": 1.6083,
      "step": 3770
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 0.0002460479736328125,
      "learning_rate": 2.259060402684564e-05,
      "loss": 0.0,
      "step": 3780
    },
    {
      "epoch": 3.79,
      "grad_norm": 0.0003662109375,
      "learning_rate": 2.257046979865772e-05,
      "loss": 2.7297,
      "step": 3790
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.000286102294921875,
      "learning_rate": 2.25503355704698e-05,
      "loss": 1.6406,
      "step": 3800
    },
    {
      "epoch": 3.81,
      "grad_norm": 0.00026702880859375,
      "learning_rate": 2.253020134228188e-05,
      "loss": 0.2766,
      "step": 3810
    },
    {
      "epoch": 3.82,
      "grad_norm": 0.000331878662109375,
      "learning_rate": 2.2510067114093962e-05,
      "loss": 0.3082,
      "step": 3820
    },
    {
      "epoch": 3.83,
      "grad_norm": 0.00031280517578125,
      "learning_rate": 2.248993288590604e-05,
      "loss": 0.0,
      "step": 3830
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.0002918243408203125,
      "learning_rate": 2.246979865771812e-05,
      "loss": 0.5719,
      "step": 3840
    },
    {
      "epoch": 3.85,
      "grad_norm": 62.5,
      "learning_rate": 2.2449664429530202e-05,
      "loss": 0.8617,
      "step": 3850
    },
    {
      "epoch": 3.86,
      "grad_norm": 43.0,
      "learning_rate": 2.242953020134228e-05,
      "loss": 0.7938,
      "step": 3860
    },
    {
      "epoch": 3.87,
      "grad_norm": 106.0,
      "learning_rate": 2.2409395973154363e-05,
      "loss": 2.35,
      "step": 3870
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.0002593994140625,
      "learning_rate": 2.2389261744966445e-05,
      "loss": 0.2188,
      "step": 3880
    },
    {
      "epoch": 3.89,
      "grad_norm": 0.000537872314453125,
      "learning_rate": 2.2369127516778524e-05,
      "loss": 0.9563,
      "step": 3890
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.00020122528076171875,
      "learning_rate": 2.2348993288590606e-05,
      "loss": 0.9703,
      "step": 3900
    },
    {
      "epoch": 3.91,
      "grad_norm": 0.000247955322265625,
      "learning_rate": 2.2328859060402685e-05,
      "loss": 2.775,
      "step": 3910
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.00021648406982421875,
      "learning_rate": 2.2308724832214764e-05,
      "loss": 0.1766,
      "step": 3920
    },
    {
      "epoch": 3.93,
      "grad_norm": 0.00016307830810546875,
      "learning_rate": 2.2288590604026846e-05,
      "loss": 0.8266,
      "step": 3930
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.00015163421630859375,
      "learning_rate": 2.2268456375838925e-05,
      "loss": 0.9695,
      "step": 3940
    },
    {
      "epoch": 3.95,
      "grad_norm": 0.00014781951904296875,
      "learning_rate": 2.2248322147651008e-05,
      "loss": 1.4002,
      "step": 3950
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.0,
      "learning_rate": 2.2228187919463086e-05,
      "loss": 0.3317,
      "step": 3960
    },
    {
      "epoch": 3.9699999999999998,
      "grad_norm": 0.000179290771484375,
      "learning_rate": 2.220805369127517e-05,
      "loss": 0.8375,
      "step": 3970
    },
    {
      "epoch": 3.98,
      "grad_norm": 0.000164031982421875,
      "learning_rate": 2.218791946308725e-05,
      "loss": 0.55,
      "step": 3980
    },
    {
      "epoch": 3.99,
      "grad_norm": 0.00015544891357421875,
      "learning_rate": 2.216778523489933e-05,
      "loss": 0.0,
      "step": 3990
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.000141143798828125,
      "learning_rate": 2.2147651006711412e-05,
      "loss": 0.5885,
      "step": 4000
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.4305479526519775,
      "eval_runtime": 31.671,
      "eval_samples_per_second": 3.157,
      "eval_steps_per_second": 3.157,
      "step": 4000
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.000156402587890625,
      "learning_rate": 2.2127516778523488e-05,
      "loss": 0.1297,
      "step": 4010
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.0001659393310546875,
      "learning_rate": 2.210738255033557e-05,
      "loss": 0.6313,
      "step": 4020
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.00016880035400390625,
      "learning_rate": 2.2087248322147652e-05,
      "loss": 0.65,
      "step": 4030
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.00014591217041015625,
      "learning_rate": 2.206711409395973e-05,
      "loss": 0.0,
      "step": 4040
    },
    {
      "epoch": 4.05,
      "grad_norm": 0.00024318695068359375,
      "learning_rate": 2.2046979865771813e-05,
      "loss": 0.0,
      "step": 4050
    },
    {
      "epoch": 4.06,
      "grad_norm": 0.00022983551025390625,
      "learning_rate": 2.2026845637583892e-05,
      "loss": 0.5719,
      "step": 4060
    },
    {
      "epoch": 4.07,
      "grad_norm": 0.00014400482177734375,
      "learning_rate": 2.2006711409395974e-05,
      "loss": 0.5125,
      "step": 4070
    },
    {
      "epoch": 4.08,
      "grad_norm": 39.5,
      "learning_rate": 2.1986577181208057e-05,
      "loss": 1.2734,
      "step": 4080
    },
    {
      "epoch": 4.09,
      "grad_norm": 0.0002574920654296875,
      "learning_rate": 2.1966442953020135e-05,
      "loss": 0.8438,
      "step": 4090
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.0002155303955078125,
      "learning_rate": 2.1946308724832218e-05,
      "loss": 0.0945,
      "step": 4100
    },
    {
      "epoch": 4.11,
      "grad_norm": 0.0002460479736328125,
      "learning_rate": 2.1926174496644293e-05,
      "loss": 0.0,
      "step": 4110
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.00021457672119140625,
      "learning_rate": 2.1906040268456375e-05,
      "loss": 1.0344,
      "step": 4120
    },
    {
      "epoch": 4.13,
      "grad_norm": 0.00015735626220703125,
      "learning_rate": 2.1885906040268458e-05,
      "loss": 1.5563,
      "step": 4130
    },
    {
      "epoch": 4.14,
      "grad_norm": 0.000164031982421875,
      "learning_rate": 2.1865771812080536e-05,
      "loss": 1.3023,
      "step": 4140
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.0002841949462890625,
      "learning_rate": 2.184563758389262e-05,
      "loss": 1.2484,
      "step": 4150
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.00025177001953125,
      "learning_rate": 2.1825503355704698e-05,
      "loss": 0.2422,
      "step": 4160
    },
    {
      "epoch": 4.17,
      "grad_norm": 56.5,
      "learning_rate": 2.180536912751678e-05,
      "loss": 0.3406,
      "step": 4170
    },
    {
      "epoch": 4.18,
      "grad_norm": 0.0002841949462890625,
      "learning_rate": 2.1785234899328862e-05,
      "loss": 0.0,
      "step": 4180
    },
    {
      "epoch": 4.19,
      "grad_norm": 0.0004253387451171875,
      "learning_rate": 2.176510067114094e-05,
      "loss": 1.4891,
      "step": 4190
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.0002574920654296875,
      "learning_rate": 2.174496644295302e-05,
      "loss": 0.4283,
      "step": 4200
    },
    {
      "epoch": 4.21,
      "grad_norm": 0.0,
      "learning_rate": 2.17248322147651e-05,
      "loss": 0.3962,
      "step": 4210
    },
    {
      "epoch": 4.22,
      "grad_norm": 0.00025177001953125,
      "learning_rate": 2.170469798657718e-05,
      "loss": 1.2422,
      "step": 4220
    },
    {
      "epoch": 4.23,
      "grad_norm": 56.75,
      "learning_rate": 2.1684563758389263e-05,
      "loss": 1.5563,
      "step": 4230
    },
    {
      "epoch": 4.24,
      "grad_norm": 120.5,
      "learning_rate": 2.1664429530201342e-05,
      "loss": 2.5469,
      "step": 4240
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.00023651123046875,
      "learning_rate": 2.1644295302013424e-05,
      "loss": 0.2891,
      "step": 4250
    },
    {
      "epoch": 4.26,
      "grad_norm": 0.00021648406982421875,
      "learning_rate": 2.1624161073825503e-05,
      "loss": 0.825,
      "step": 4260
    },
    {
      "epoch": 4.27,
      "grad_norm": 0.00023651123046875,
      "learning_rate": 2.1604026845637585e-05,
      "loss": 0.9098,
      "step": 4270
    },
    {
      "epoch": 4.28,
      "grad_norm": 42.5,
      "learning_rate": 2.1583892617449668e-05,
      "loss": 1.7172,
      "step": 4280
    },
    {
      "epoch": 4.29,
      "grad_norm": 82.5,
      "learning_rate": 2.1563758389261743e-05,
      "loss": 0.8539,
      "step": 4290
    },
    {
      "epoch": 4.3,
      "grad_norm": 43.5,
      "learning_rate": 2.1543624161073825e-05,
      "loss": 1.8406,
      "step": 4300
    },
    {
      "epoch": 4.31,
      "grad_norm": 35.25,
      "learning_rate": 2.1523489932885904e-05,
      "loss": 0.4422,
      "step": 4310
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.0002155303955078125,
      "learning_rate": 2.1503355704697987e-05,
      "loss": 0.1508,
      "step": 4320
    },
    {
      "epoch": 4.33,
      "grad_norm": 65.5,
      "learning_rate": 2.148322147651007e-05,
      "loss": 0.9602,
      "step": 4330
    },
    {
      "epoch": 4.34,
      "grad_norm": 0.00014781951904296875,
      "learning_rate": 2.1463087248322148e-05,
      "loss": 0.2839,
      "step": 4340
    },
    {
      "epoch": 4.35,
      "grad_norm": 0.0002231597900390625,
      "learning_rate": 2.144295302013423e-05,
      "loss": 0.3625,
      "step": 4350
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.00014591217041015625,
      "learning_rate": 2.142281879194631e-05,
      "loss": 1.0219,
      "step": 4360
    },
    {
      "epoch": 4.37,
      "grad_norm": 0.00013637542724609375,
      "learning_rate": 2.140268456375839e-05,
      "loss": 0.8203,
      "step": 4370
    },
    {
      "epoch": 4.38,
      "grad_norm": 0.0001583099365234375,
      "learning_rate": 2.138255033557047e-05,
      "loss": 1.0016,
      "step": 4380
    },
    {
      "epoch": 4.39,
      "grad_norm": 39.5,
      "learning_rate": 2.136241610738255e-05,
      "loss": 0.8971,
      "step": 4390
    },
    {
      "epoch": 4.4,
      "grad_norm": 101.5,
      "learning_rate": 2.134228187919463e-05,
      "loss": 1.6094,
      "step": 4400
    },
    {
      "epoch": 4.41,
      "grad_norm": 0.00014972686767578125,
      "learning_rate": 2.132214765100671e-05,
      "loss": 0.9641,
      "step": 4410
    },
    {
      "epoch": 4.42,
      "grad_norm": 0.00010347366333007812,
      "learning_rate": 2.1302013422818792e-05,
      "loss": 0.8957,
      "step": 4420
    },
    {
      "epoch": 4.43,
      "grad_norm": 0.00011348724365234375,
      "learning_rate": 2.1281879194630874e-05,
      "loss": 1.1219,
      "step": 4430
    },
    {
      "epoch": 4.44,
      "grad_norm": 61.0,
      "learning_rate": 2.1261744966442953e-05,
      "loss": 0.6469,
      "step": 4440
    },
    {
      "epoch": 4.45,
      "grad_norm": 0.0001316070556640625,
      "learning_rate": 2.1241610738255036e-05,
      "loss": 2.1574,
      "step": 4450
    },
    {
      "epoch": 4.46,
      "grad_norm": 0.00013065338134765625,
      "learning_rate": 2.1221476510067114e-05,
      "loss": 0.5453,
      "step": 4460
    },
    {
      "epoch": 4.47,
      "grad_norm": 56.0,
      "learning_rate": 2.1201342281879193e-05,
      "loss": 0.7871,
      "step": 4470
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.0002307891845703125,
      "learning_rate": 2.1181208053691275e-05,
      "loss": 0.0,
      "step": 4480
    },
    {
      "epoch": 4.49,
      "grad_norm": 66.0,
      "learning_rate": 2.1161073825503354e-05,
      "loss": 1.5766,
      "step": 4490
    },
    {
      "epoch": 4.5,
      "grad_norm": 36.5,
      "learning_rate": 2.1140939597315437e-05,
      "loss": 0.0965,
      "step": 4500
    },
    {
      "epoch": 4.51,
      "grad_norm": 0.000270843505859375,
      "learning_rate": 2.1120805369127515e-05,
      "loss": 1.675,
      "step": 4510
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.00030517578125,
      "learning_rate": 2.1100671140939598e-05,
      "loss": 1.5885,
      "step": 4520
    },
    {
      "epoch": 4.53,
      "grad_norm": 0.00023651123046875,
      "learning_rate": 2.108053691275168e-05,
      "loss": 1.3344,
      "step": 4530
    },
    {
      "epoch": 4.54,
      "grad_norm": 0.0003662109375,
      "learning_rate": 2.106040268456376e-05,
      "loss": 0.9531,
      "step": 4540
    },
    {
      "epoch": 4.55,
      "grad_norm": 0.000202178955078125,
      "learning_rate": 2.104026845637584e-05,
      "loss": 0.0,
      "step": 4550
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 0.00016307830810546875,
      "learning_rate": 2.102013422818792e-05,
      "loss": 1.1578,
      "step": 4560
    },
    {
      "epoch": 4.57,
      "grad_norm": 0.0004291534423828125,
      "learning_rate": 2.1e-05,
      "loss": 0.9688,
      "step": 4570
    },
    {
      "epoch": 4.58,
      "grad_norm": 0.0003299713134765625,
      "learning_rate": 2.097986577181208e-05,
      "loss": 0.5547,
      "step": 4580
    },
    {
      "epoch": 4.59,
      "grad_norm": 0.0002307891845703125,
      "learning_rate": 2.095973154362416e-05,
      "loss": 0.35,
      "step": 4590
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.0002536773681640625,
      "learning_rate": 2.0939597315436242e-05,
      "loss": 0.8563,
      "step": 4600
    },
    {
      "epoch": 4.61,
      "grad_norm": 0.00013446807861328125,
      "learning_rate": 2.0919463087248324e-05,
      "loss": 0.5844,
      "step": 4610
    },
    {
      "epoch": 4.62,
      "grad_norm": 0.0001983642578125,
      "learning_rate": 2.0899328859060403e-05,
      "loss": 0.5766,
      "step": 4620
    },
    {
      "epoch": 4.63,
      "grad_norm": 38.5,
      "learning_rate": 2.0879194630872486e-05,
      "loss": 1.3102,
      "step": 4630
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.00020122528076171875,
      "learning_rate": 2.0859060402684564e-05,
      "loss": 0.8625,
      "step": 4640
    },
    {
      "epoch": 4.65,
      "grad_norm": 59.5,
      "learning_rate": 2.0838926174496647e-05,
      "loss": 1.1844,
      "step": 4650
    },
    {
      "epoch": 4.66,
      "grad_norm": 0.00026702880859375,
      "learning_rate": 2.0818791946308726e-05,
      "loss": 0.6328,
      "step": 4660
    },
    {
      "epoch": 4.67,
      "grad_norm": 0.00020122528076171875,
      "learning_rate": 2.0798657718120804e-05,
      "loss": 0.7447,
      "step": 4670
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.000247955322265625,
      "learning_rate": 2.0778523489932887e-05,
      "loss": 0.9438,
      "step": 4680
    },
    {
      "epoch": 4.6899999999999995,
      "grad_norm": 0.0,
      "learning_rate": 2.0758389261744966e-05,
      "loss": 1.2195,
      "step": 4690
    },
    {
      "epoch": 4.7,
      "grad_norm": 70.0,
      "learning_rate": 2.0738255033557048e-05,
      "loss": 1.925,
      "step": 4700
    },
    {
      "epoch": 4.71,
      "grad_norm": 43.75,
      "learning_rate": 2.071812080536913e-05,
      "loss": 0.33,
      "step": 4710
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.000217437744140625,
      "learning_rate": 2.069798657718121e-05,
      "loss": 0.8556,
      "step": 4720
    },
    {
      "epoch": 4.73,
      "grad_norm": 0.000209808349609375,
      "learning_rate": 2.067785234899329e-05,
      "loss": 1.075,
      "step": 4730
    },
    {
      "epoch": 4.74,
      "grad_norm": 43.25,
      "learning_rate": 2.065771812080537e-05,
      "loss": 0.45,
      "step": 4740
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.00023555755615234375,
      "learning_rate": 2.063758389261745e-05,
      "loss": 0.6805,
      "step": 4750
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.000194549560546875,
      "learning_rate": 2.061744966442953e-05,
      "loss": 0.1389,
      "step": 4760
    },
    {
      "epoch": 4.77,
      "grad_norm": 61.75,
      "learning_rate": 2.059731543624161e-05,
      "loss": 1.2711,
      "step": 4770
    },
    {
      "epoch": 4.78,
      "grad_norm": 0.0002803802490234375,
      "learning_rate": 2.0577181208053692e-05,
      "loss": 0.3109,
      "step": 4780
    },
    {
      "epoch": 4.79,
      "grad_norm": 0.0004024505615234375,
      "learning_rate": 2.055704697986577e-05,
      "loss": 1.5172,
      "step": 4790
    },
    {
      "epoch": 4.8,
      "grad_norm": 118.0,
      "learning_rate": 2.0536912751677853e-05,
      "loss": 0.8758,
      "step": 4800
    },
    {
      "epoch": 4.8100000000000005,
      "grad_norm": 74.5,
      "learning_rate": 2.0516778523489936e-05,
      "loss": 1.2377,
      "step": 4810
    },
    {
      "epoch": 4.82,
      "grad_norm": 0.00022602081298828125,
      "learning_rate": 2.0496644295302015e-05,
      "loss": 1.0055,
      "step": 4820
    },
    {
      "epoch": 4.83,
      "grad_norm": 0.00015544891357421875,
      "learning_rate": 2.0476510067114097e-05,
      "loss": 0.8672,
      "step": 4830
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.00037384033203125,
      "learning_rate": 2.0456375838926172e-05,
      "loss": 0.8195,
      "step": 4840
    },
    {
      "epoch": 4.85,
      "grad_norm": 0.0002994537353515625,
      "learning_rate": 2.0436241610738254e-05,
      "loss": 0.9078,
      "step": 4850
    },
    {
      "epoch": 4.86,
      "grad_norm": 45.5,
      "learning_rate": 2.0416107382550337e-05,
      "loss": 0.6586,
      "step": 4860
    },
    {
      "epoch": 4.87,
      "grad_norm": 0.000186920166015625,
      "learning_rate": 2.0395973154362416e-05,
      "loss": 0.5656,
      "step": 4870
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.000244140625,
      "learning_rate": 2.0375838926174498e-05,
      "loss": 0.2979,
      "step": 4880
    },
    {
      "epoch": 4.89,
      "grad_norm": 0.0003261566162109375,
      "learning_rate": 2.0355704697986577e-05,
      "loss": 0.7445,
      "step": 4890
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.000194549560546875,
      "learning_rate": 2.033557046979866e-05,
      "loss": 2.7906,
      "step": 4900
    },
    {
      "epoch": 4.91,
      "grad_norm": 0.000347137451171875,
      "learning_rate": 2.031543624161074e-05,
      "loss": 1.1703,
      "step": 4910
    },
    {
      "epoch": 4.92,
      "grad_norm": 76.0,
      "learning_rate": 2.029530201342282e-05,
      "loss": 1.5375,
      "step": 4920
    },
    {
      "epoch": 4.93,
      "grad_norm": 0.0001735687255859375,
      "learning_rate": 2.02751677852349e-05,
      "loss": 0.4523,
      "step": 4930
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 87.5,
      "learning_rate": 2.0255033557046978e-05,
      "loss": 0.8133,
      "step": 4940
    },
    {
      "epoch": 4.95,
      "grad_norm": 0.000255584716796875,
      "learning_rate": 2.023489932885906e-05,
      "loss": 0.7365,
      "step": 4950
    },
    {
      "epoch": 4.96,
      "grad_norm": 30.625,
      "learning_rate": 2.0214765100671142e-05,
      "loss": 1.7204,
      "step": 4960
    },
    {
      "epoch": 4.97,
      "grad_norm": 0.0001544952392578125,
      "learning_rate": 2.019463087248322e-05,
      "loss": 1.1188,
      "step": 4970
    },
    {
      "epoch": 4.98,
      "grad_norm": 128.0,
      "learning_rate": 2.0174496644295303e-05,
      "loss": 1.4531,
      "step": 4980
    },
    {
      "epoch": 4.99,
      "grad_norm": 39.75,
      "learning_rate": 2.0154362416107382e-05,
      "loss": 1.3586,
      "step": 4990
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.0002689361572265625,
      "learning_rate": 2.0134228187919465e-05,
      "loss": 1.25,
      "step": 5000
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.4232043027877808,
      "eval_runtime": 31.6713,
      "eval_samples_per_second": 3.157,
      "eval_steps_per_second": 3.157,
      "step": 5000
    }
  ],
  "logging_steps": 10,
  "max_steps": 15000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.804827694980608e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
