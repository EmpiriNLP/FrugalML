{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6788811e8e49d19a10559ab51046e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi-3 (3.8B) model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"  # 3.8B model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")  # Auto maps to GPU if available\n",
    "\n",
    "print(\"Phi-3 (3.8B) model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            pre_text  \\\n",
      "0  [entergy corporation and subsidiaries manageme...   \n",
      "1  [item 1b ., unresolved staff comments not appl...   \n",
      "2  [undesignated hedges was $ 41.2 million and $ ...   \n",
      "3  [chairman and a director of the board of fis a...   \n",
      "4  [performance graph the table below compares th...   \n",
      "\n",
      "                                           post_text               filename  \\\n",
      "0  [the retail electric price variance is primari...   ETR/2016/page_23.pdf   \n",
      "1  [1 leases on portions of the land used for the...  INTC/2015/page_41.pdf   \n",
      "2  [the amounts earned and owed under the swap ag...   ADI/2011/page_61.pdf   \n",
      "3  [we recorded a preliminary allocation of the p...   FIS/2010/page_70.pdf   \n",
      "4  [$ 50.00 $ 100.00 $ 150.00 $ 200.00 $ 250.00 $...   MAS/2017/page_27.pdf   \n",
      "\n",
      "                                           table_ori  \\\n",
      "0  [[, Amount (In Millions)], [2014 net revenue, ...   \n",
      "1  [[(Square Feet in Millions), UnitedStates, Oth...   \n",
      "2  [[Statement of Income, October 29, 2011, Octob...   \n",
      "3  [[Value of Metavante common stock, $4,066.4], ...   \n",
      "4  [[, 2013, 2014, 2015, 2016, 2017], [Masco, $13...   \n",
      "\n",
      "                                               table  \\\n",
      "0  [[, amount ( in millions )], [2014 net revenue...   \n",
      "1  [[( square feet in millions ), unitedstates, o...   \n",
      "2  [[statement of income classification, statemen...   \n",
      "3  [[value of metavante common stock, $ 4066.4], ...   \n",
      "4  [[, 2013, 2014, 2015, 2016, 2017], [masco, $ 1...   \n",
      "\n",
      "                                                  qa                       id  \\\n",
      "0  {'question': 'what is the net change in net re...   ETR/2016/page_23.pdf-2   \n",
      "1  {'question': 'what percentage of total facilit...  INTC/2015/page_41.pdf-4   \n",
      "2  {'question': 'what is the percentage change in...   ADI/2011/page_61.pdf-2   \n",
      "3  {'question': 'what portion of total purchase p...   FIS/2010/page_70.pdf-2   \n",
      "4  {'question': 'what was the difference in perce...   MAS/2017/page_27.pdf-2   \n",
      "\n",
      "                                     table_retrieved  \\\n",
      "0  [{'score': 3.0425944328308105, 'ind': 'table_8...   \n",
      "1  [{'score': 2.7798845767974854, 'ind': 'table_3...   \n",
      "2                                                 []   \n",
      "3  [{'score': 2.4790191650390625, 'ind': 'table_2...   \n",
      "4  [{'score': 2.594181537628174, 'ind': 'table_2'...   \n",
      "\n",
      "                                      text_retrieved  \\\n",
      "0  [{'score': 0.3962186276912689, 'ind': 'text_10'}]   \n",
      "1  [{'score': -0.8847692608833313, 'ind': 'text_3...   \n",
      "2  [{'score': -0.08387626707553864, 'ind': 'text_...   \n",
      "3  [{'score': -1.7995294332504272, 'ind': 'text_2...   \n",
      "4  [{'score': 1.0542901754379272, 'ind': 'text_1'...   \n",
      "\n",
      "                                 table_retrieved_all  \\\n",
      "0  [{'score': 3.0425944328308105, 'ind': 'table_8...   \n",
      "1  [{'score': 2.7798845767974854, 'ind': 'table_3...   \n",
      "2  [{'score': -2.742973804473877, 'ind': 'table_1...   \n",
      "3  [{'score': 2.4790191650390625, 'ind': 'table_2...   \n",
      "4  [{'score': 2.594181537628174, 'ind': 'table_2'...   \n",
      "\n",
      "                                  text_retrieved_all  \n",
      "0  [{'score': 0.3962186276912689, 'ind': 'text_10...  \n",
      "1  [{'score': -0.8847692608833313, 'ind': 'text_3...  \n",
      "2  [{'score': -0.08387626707553864, 'ind': 'text_...  \n",
      "3  [{'score': -1.7995294332504272, 'ind': 'text_2...  \n",
      "4  [{'score': 1.0542901754379272, 'ind': 'text_1'...  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "def load_finqa_dataset(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Load training, validation, and test sets\n",
    "train_data = load_finqa_dataset(\"/cs/student/projects2/aisd/2024/giliev/FinQA/dataset/train.json\")\n",
    "dev_data = load_finqa_dataset(\"/cs/student/projects2/aisd/2024/giliev/FinQA/dataset/dev.json\")\n",
    "test_data = load_finqa_dataset(\"/cs/student/projects2/aisd/2024/giliev/FinQA/dataset/test.json\")\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "df_test = pd.DataFrame(test_data)\n",
    "print(df_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"pre_text\": [\n",
      "        \"entergy corporation and subsidiaries management 2019s financial discussion and analysis a result of the entergy louisiana and entergy gulf states louisiana business combination , results of operations for 2015 also include two items that occurred in october 2015 : 1 ) a deferred tax asset and resulting net increase in tax basis of approximately $ 334 million and 2 ) a regulatory liability of $ 107 million ( $ 66 million net-of-tax ) as a result of customer credits to be realized by electric customers of entergy louisiana , consistent with the terms of the stipulated settlement in the business combination proceeding .\",\n",
      "        \"see note 2 to the financial statements for further discussion of the business combination and customer credits .\",\n",
      "        \"results of operations for 2015 also include the sale in december 2015 of the 583 mw rhode island state energy center for a realized gain of $ 154 million ( $ 100 million net-of-tax ) on the sale and the $ 77 million ( $ 47 million net-of-tax ) write-off and regulatory charges to recognize that a portion of the assets associated with the waterford 3 replacement steam generator project is no longer probable of recovery .\",\n",
      "        \"see note 14 to the financial statements for further discussion of the rhode island state energy center sale .\",\n",
      "        \"see note 2 to the financial statements for further discussion of the waterford 3 write-off .\",\n",
      "        \"results of operations for 2014 include $ 154 million ( $ 100 million net-of-tax ) of charges related to vermont yankee primarily resulting from the effects of an updated decommissioning cost study completed in the third quarter 2014 along with reassessment of the assumptions regarding the timing of decommissioning cash flows and severance and employee retention costs .\",\n",
      "        \"see note 14 to the financial statements for further discussion of the charges .\",\n",
      "        \"results of operations for 2014 also include the $ 56.2 million ( $ 36.7 million net-of-tax ) write-off in 2014 of entergy mississippi 2019s regulatory asset associated with new nuclear generation development costs as a result of a joint stipulation entered into with the mississippi public utilities staff , subsequently approved by the mpsc , in which entergy mississippi agreed not to pursue recovery of the costs deferred by an mpsc order in the new nuclear generation docket .\",\n",
      "        \"see note 2 to the financial statements for further discussion of the new nuclear generation development costs and the joint stipulation .\",\n",
      "        \"net revenue utility following is an analysis of the change in net revenue comparing 2015 to 2014 .\",\n",
      "        \"amount ( in millions ) .\"\n",
      "    ],\n",
      "    \"post_text\": [\n",
      "        \"the retail electric price variance is primarily due to : 2022 formula rate plan increases at entergy louisiana , as approved by the lpsc , effective december 2014 and january 2015 ; 2022 an increase in energy efficiency rider revenue primarily due to increases in the energy efficiency rider at entergy arkansas , as approved by the apsc , effective july 2015 and july 2014 , and new energy efficiency riders at entergy louisiana and entergy mississippi that began in the fourth quarter 2014 ; and 2022 an annual net rate increase at entergy mississippi of $ 16 million , effective february 2015 , as a result of the mpsc order in the june 2014 rate case .\",\n",
      "        \"see note 2 to the financial statements for a discussion of rate and regulatory proceedings. .\"\n",
      "    ],\n",
      "    \"filename\": \"ETR/2016/page_23.pdf\",\n",
      "    \"table_ori\": [\n",
      "        [\n",
      "            \"\",\n",
      "            \"Amount (In Millions)\"\n",
      "        ],\n",
      "        [\n",
      "            \"2014 net revenue\",\n",
      "            \"$5,735\"\n",
      "        ],\n",
      "        [\n",
      "            \"Retail electric price\",\n",
      "            \"187\"\n",
      "        ],\n",
      "        [\n",
      "            \"Volume/weather\",\n",
      "            \"95\"\n",
      "        ],\n",
      "        [\n",
      "            \"Waterford 3 replacement steam generator provision\",\n",
      "            \"(32)\"\n",
      "        ],\n",
      "        [\n",
      "            \"MISO deferral\",\n",
      "            \"(35)\"\n",
      "        ],\n",
      "        [\n",
      "            \"Louisiana business combination customer credits\",\n",
      "            \"(107)\"\n",
      "        ],\n",
      "        [\n",
      "            \"Other\",\n",
      "            \"(14)\"\n",
      "        ],\n",
      "        [\n",
      "            \"2015 net revenue\",\n",
      "            \"$5,829\"\n",
      "        ]\n",
      "    ],\n",
      "    \"table\": [\n",
      "        [\n",
      "            \"\",\n",
      "            \"amount ( in millions )\"\n",
      "        ],\n",
      "        [\n",
      "            \"2014 net revenue\",\n",
      "            \"$ 5735\"\n",
      "        ],\n",
      "        [\n",
      "            \"retail electric price\",\n",
      "            \"187\"\n",
      "        ],\n",
      "        [\n",
      "            \"volume/weather\",\n",
      "            \"95\"\n",
      "        ],\n",
      "        [\n",
      "            \"waterford 3 replacement steam generator provision\",\n",
      "            \"-32 ( 32 )\"\n",
      "        ],\n",
      "        [\n",
      "            \"miso deferral\",\n",
      "            \"-35 ( 35 )\"\n",
      "        ],\n",
      "        [\n",
      "            \"louisiana business combination customer credits\",\n",
      "            \"-107 ( 107 )\"\n",
      "        ],\n",
      "        [\n",
      "            \"other\",\n",
      "            \"-14 ( 14 )\"\n",
      "        ],\n",
      "        [\n",
      "            \"2015 net revenue\",\n",
      "            \"$ 5829\"\n",
      "        ]\n",
      "    ],\n",
      "    \"qa\": {\n",
      "        \"question\": \"what is the net change in net revenue during 2015 for entergy corporation?\",\n",
      "        \"answer\": \"94\",\n",
      "        \"explanation\": \"\",\n",
      "        \"ann_table_rows\": [\n",
      "            1,\n",
      "            8\n",
      "        ],\n",
      "        \"ann_text_rows\": [],\n",
      "        \"steps\": [\n",
      "            {\n",
      "                \"op\": \"minus2-1\",\n",
      "                \"arg1\": \"5829\",\n",
      "                \"arg2\": \"5735\",\n",
      "                \"res\": \"94\"\n",
      "            }\n",
      "        ],\n",
      "        \"program\": \"subtract(5829, 5735)\",\n",
      "        \"gold_inds\": {\n",
      "            \"table_1\": \"the 2014 net revenue of amount ( in millions ) is $ 5735 ;\",\n",
      "            \"table_8\": \"the 2015 net revenue of amount ( in millions ) is $ 5829 ;\"\n",
      "        },\n",
      "        \"exe_ans\": 94.0,\n",
      "        \"tfidftopn\": {\n",
      "            \"text_9\": \"net revenue utility following is an analysis of the change in net revenue comparing 2015 to 2014 .\"\n",
      "        },\n",
      "        \"program_re\": \"subtract(5829, 5735)\",\n",
      "        \"model_input\": [\n",
      "            [\n",
      "                \"table_1\",\n",
      "                \"the 2014 net revenue of amount ( in millions ) is $ 5735 ;\"\n",
      "            ],\n",
      "            [\n",
      "                \"table_3\",\n",
      "                \"the volume/weather of amount ( in millions ) is 95 ;\"\n",
      "            ],\n",
      "            [\n",
      "                \"table_8\",\n",
      "                \"the 2015 net revenue of amount ( in millions ) is $ 5829 ;\"\n",
      "            ]\n",
      "        ]\n",
      "    },\n",
      "    \"id\": \"ETR/2016/page_23.pdf-2\",\n",
      "    \"table_retrieved\": [\n",
      "        {\n",
      "            \"score\": 3.0425944328308105,\n",
      "            \"ind\": \"table_8\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": 2.630547046661377,\n",
      "            \"ind\": \"table_1\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": 0.7781655788421631,\n",
      "            \"ind\": \"table_3\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": 0.606473982334137,\n",
      "            \"ind\": \"table_7\"\n",
      "        }\n",
      "    ],\n",
      "    \"text_retrieved\": [\n",
      "        {\n",
      "            \"score\": 0.3962186276912689,\n",
      "            \"ind\": \"text_10\"\n",
      "        }\n",
      "    ],\n",
      "    \"table_retrieved_all\": [\n",
      "        {\n",
      "            \"score\": 3.0425944328308105,\n",
      "            \"ind\": \"table_8\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": 2.630547046661377,\n",
      "            \"ind\": \"table_1\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": 0.7781655788421631,\n",
      "            \"ind\": \"table_3\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": 0.606473982334137,\n",
      "            \"ind\": \"table_7\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": 0.3680412769317627,\n",
      "            \"ind\": \"table_2\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": -0.06215459108352661,\n",
      "            \"ind\": \"table_5\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": -0.23549103736877441,\n",
      "            \"ind\": \"table_4\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": -1.1832187175750732,\n",
      "            \"ind\": \"table_6\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": -3.0562329292297363,\n",
      "            \"ind\": \"table_0\"\n",
      "        }\n",
      "    ],\n",
      "    \"text_retrieved_all\": [\n",
      "        {\n",
      "            \"score\": 0.3962186276912689,\n",
      "            \"ind\": \"text_10\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": -0.6703973412513733,\n",
      "            \"ind\": \"text_0\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": -0.8628821969032288,\n",
      "            \"ind\": \"text_11\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": -0.9996260404586792,\n",
      "            \"ind\": \"text_9\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": -1.4163694381713867,\n",
      "            \"ind\": \"text_2\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": -1.4738928079605103,\n",
      "            \"ind\": \"text_7\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": -1.6805188655853271,\n",
      "            \"ind\": \"text_5\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": -1.8574978113174438,\n",
      "            \"ind\": \"text_12\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": -2.2638840675354004,\n",
      "            \"ind\": \"text_6\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": -2.363234519958496,\n",
      "            \"ind\": \"text_8\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": -2.428662061691284,\n",
      "            \"ind\": \"text_4\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": -2.465285062789917,\n",
      "            \"ind\": \"text_1\"\n",
      "        },\n",
      "        {\n",
      "            \"score\": -2.482703924179077,\n",
      "            \"ind\": \"text_3\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Print an example entry from test_data\n",
    "print(json.dumps(test_data[0], indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_example(example):\n",
    "    \"\"\"Prepare structured input for Phi-3\"\"\"\n",
    "    # Extract question and relevant information from table\n",
    "    question = example[\"qa\"].get(\"question\", \"No question available.\")\n",
    "    table = example.get(\"table\", [])\n",
    "    table_str = \"\\n\".join([\" | \".join(row) for row in table])\n",
    "    \n",
    "    # Extract text context\n",
    "    pre_text = \" \".join(example.get(\"pre_text\", []))\n",
    "    post_text = \" \".join(example.get(\"post_text\", []))\n",
    "    \n",
    "    # Get the gold indices for relevant information\n",
    "    gold_inds = example[\"qa\"].get(\"gold_inds\", {})\n",
    "    relevant_info = \"\\n\".join(gold_inds.values())\n",
    "    \n",
    "    # Get the mathematical program if available\n",
    "    program = example[\"qa\"].get(\"program\", \"\")\n",
    "    \n",
    "    # Structured format with explicit instruction\n",
    "    input_text = (\n",
    "        \"You are a financial AI assistant. Answer the following question using only numbers or percentages.\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"1. Extract numerical values from the context and table\\n\"\n",
    "        \"2. Perform any necessary calculations\\n\"\n",
    "        \"3. Return ONLY the final number or percentage\\n\"\n",
    "        \"4. Do not include any explanatory text\\n\\n\"\n",
    "        f\"Relevant Information:\\n{relevant_info}\\n\\n\"\n",
    "        f\"Table Data:\\n{table_str}\\n\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        f\"Mathematical Operation: {program}\\n\"\n",
    "        \"Answer (number/percentage only): \"\n",
    "    )\n",
    "\n",
    "    return tokenizer(\n",
    "        input_text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=2048,  # Increased context length\n",
    "        return_tensors=\"pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_answer(response_text):\n",
    "    \"\"\"Extract the most relevant numerical value.\"\"\"\n",
    "    matches = re.findall(r\"[-+]?\\d*\\.?\\d+%?\", response_text.strip())\n",
    "    \n",
    "    if matches:\n",
    "        return matches[0]  # Return the first match (most likely correct)\n",
    "    return \"Not Found\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(example):\n",
    "    \"\"\"Generate an answer using the Phi-3 model\"\"\"\n",
    "    inputs = preprocess_example(example)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,  # Slightly increased to allow for decimal numbers\n",
    "            do_sample=False,    # Deterministic output\n",
    "            temperature=0.1,    # Very slight randomness to avoid repetition\n",
    "            top_p=0.95,        # Nuclear sampling\n",
    "            num_beams=3,       # Beam search for better answer selection\n",
    "            early_stopping=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return clean_answer(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c12e3e4e1084c24a2180837039dc7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# Load the model with 4-bit quantization\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_answer(text):\n",
    "    \"\"\"Clean and extract numerical answer\"\"\"\n",
    "    # Remove everything before the last colon if present\n",
    "    if ':' in text:\n",
    "        text = text.split(':')[-1]\n",
    "    \n",
    "    # First try to find percentage values\n",
    "    percent_match = re.search(r'[-+]?\\d*\\.?\\d+\\s*%', text)\n",
    "    if percent_match:\n",
    "        return percent_match.group(0)\n",
    "    \n",
    "    # Then try to find decimal numbers\n",
    "    decimal_match = re.search(r'[-+]?\\d*\\.?\\d+', text)\n",
    "    if decimal_match:\n",
    "        return decimal_match.group(0)\n",
    "    \n",
    "    # If no numerical value found, return original cleaned text\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fdd6d8623b43b7bb0c133bb62fe247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully!\n",
      "Dataset loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_145777/2634805306.py:120: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"squad\")\n",
      "/cs/student/projects2/aisd/2024/giliev/miniconda3/envs/finqaEnv/lib/python3.9/site-packages/datasets/load.py:759: FutureWarning: The repository for squad contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/squad/squad.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/cs/student/projects2/aisd/2024/giliev/miniconda3/envs/finqaEnv/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/cs/student/projects2/aisd/2024/giliev/miniconda3/envs/finqaEnv/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/cs/student/projects2/aisd/2024/giliev/miniconda3/envs/finqaEnv/lib/python3.9/site-packages/bitsandbytes/nn/modules.py:451: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Example 1\n",
      "â“ Question: what is the net change in net revenue during 2015 for entergy corporation?\n",
      "âœ… Ground Truth: 94\n",
      "ðŸ¤– Prediction: 94.0%\n",
      "ðŸ“Š Metrics - Exact Match: 0, F1: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/student/projects2/aisd/2024/giliev/miniconda3/envs/finqaEnv/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/cs/student/projects2/aisd/2024/giliev/miniconda3/envs/finqaEnv/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Example 2\n",
      "â“ Question: what percentage of total facilities as measured in square feet are leased?\n",
      "âœ… Ground Truth: 14%\n",
      "ðŸ¤– Prediction: 14.2%\n",
      "ðŸ“Š Metrics - Exact Match: 0, F1: 0.00\n",
      "\n",
      "ðŸ”¹ Example 3\n",
      "â“ Question: what is the percentage change in cash flow hedges in 2011 compare to the 2010?\n",
      "âœ… Ground Truth: 9.9%\n",
      "ðŸ¤– Prediction: 9.1%\n",
      "ðŸ“Š Metrics - Exact Match: 0, F1: 0.00\n",
      "\n",
      "ðŸ”¹ Example 4\n",
      "â“ Question: what portion of total purchase price is related to stock awards?\n",
      "âœ… Ground Truth: 2.9%\n",
      "ðŸ¤– Prediction: 2.9%\n",
      "ðŸ“Š Metrics - Exact Match: 1, F1: 100.00\n",
      "\n",
      "ðŸ”¹ Example 5\n",
      "â“ Question: what was the difference in percentage cumulative total shareholder return on masco common stock versus the s&p 500 index for the five year period ended 2017?\n",
      "âœ… Ground Truth: \n",
      "ðŸ¤– Prediction: 0.0%\n",
      "ðŸ“Š Metrics - Exact Match: 0, F1: 0.00\n",
      "\n",
      "ðŸ”¹ Example 6\n",
      "â“ Question: what was the percentage change in total rental expense under operating leases from july 2 , 2005 to july 1 , 2006?\n",
      "âœ… Ground Truth: 7%\n",
      "ðŸ¤– Prediction: 6.7%\n",
      "ðŸ“Š Metrics - Exact Match: 0, F1: 0.00\n",
      "\n",
      "ðŸ”¹ Example 7\n",
      "â“ Question: what percent of total recourse debt is current?\n",
      "âœ… Ground Truth: 10%\n",
      "ðŸ¤– Prediction: 10.0%\n",
      "ðŸ“Š Metrics - Exact Match: 0, F1: 0.00\n",
      "\n",
      "ðŸ”¹ Example 8\n",
      "â“ Question: what percentage of future minimum rental payments are due in 2018?\n",
      "âœ… Ground Truth: 12%\n",
      "ðŸ¤– Prediction: 11.7%\n",
      "ðŸ“Š Metrics - Exact Match: 0, F1: 0.00\n",
      "\n",
      "ðŸ”¹ Example 9\n",
      "â“ Question: did altria outperform the s&p 500?\n",
      "âœ… Ground Truth: yes\n",
      "ðŸ¤– Prediction: to determine\n",
      "ðŸ“Š Metrics - Exact Match: 0, F1: 0.00\n",
      "\n",
      "ðŸ”¹ Example 10\n",
      "â“ Question: what was the change in unrecognized tax benefits from the end of 2014 to the end of 2015?\n",
      "âœ… Ground Truth: -35\n",
      "ðŸ¤– Prediction: 35.0%\n",
      "ðŸ“Š Metrics - Exact Match: 0, F1: 0.00\n",
      "\n",
      "ðŸ“Š Overall Results: {'exact_match': 10.0, 'f1': 10.0}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# Model initialization\n",
    "def initialize_model():\n",
    "    model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Initialize with 4-bit quantization for better memory efficiency\n",
    "    quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=quantization_config\n",
    "    )\n",
    "    return model, tokenizer\n",
    "\n",
    "# Data loading\n",
    "def load_finqa_dataset(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def preprocess_example(example, tokenizer):\n",
    "    \"\"\"Prepare structured input for Phi-3\"\"\"\n",
    "    question = example[\"qa\"].get(\"question\", \"No question available.\")\n",
    "    table = example.get(\"table\", [])\n",
    "    table_str = \"\\n\".join([\" | \".join(row) for row in table])\n",
    "    \n",
    "    pre_text = \" \".join(example.get(\"pre_text\", []))\n",
    "    post_text = \" \".join(example.get(\"post_text\", []))\n",
    "    \n",
    "    gold_inds = example[\"qa\"].get(\"gold_inds\", {})\n",
    "    relevant_info = \"\\n\".join(gold_inds.values())\n",
    "    program = example[\"qa\"].get(\"program\", \"\")\n",
    "    \n",
    "    input_text = (\n",
    "        \"You are a financial calculator. Follow these steps:\\n\"\n",
    "        \"1. Read the question carefully\\n\"\n",
    "        \"2. Look at the relevant information and table data\\n\"\n",
    "        \"3. Follow the mathematical operation exactly\\n\"\n",
    "        \"4. Return ONLY the final numerical answer with no text\\n\\n\"\n",
    "        f\"Relevant Information:\\n{relevant_info}\\n\\n\"\n",
    "        f\"Table Data:\\n{table_str}\\n\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        f\"Mathematical Operation: {program}\\n\"\n",
    "        \"Final Answer (number only): \"\n",
    "    )\n",
    "\n",
    "    return tokenizer(\n",
    "        input_text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=2048,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "def clean_answer(text):\n",
    "    \"\"\"Extract and format numerical answer\"\"\"\n",
    "    if ':' in text:\n",
    "        text = text.split(':')[-1]\n",
    "    \n",
    "    # Handle percentages first\n",
    "    percent_match = re.search(r'[-+]?\\d*\\.?\\d+\\s*%?', text)\n",
    "    if percent_match:\n",
    "        number = float(percent_match.group(0).replace('%', '').strip())\n",
    "        # If the number is small (likely decimal), convert to percentage\n",
    "        if number < 1:\n",
    "            number *= 100\n",
    "        # Round to one decimal place and add % symbol\n",
    "        return f\"{round(number, 1)}%\"\n",
    "    \n",
    "    # Handle regular numbers\n",
    "    decimal_match = re.search(r'[-+]?\\d*\\.?\\d+', text)\n",
    "    if decimal_match:\n",
    "        number = float(decimal_match.group(0))\n",
    "        # If it's close to an integer, round it\n",
    "        if abs(round(number) - number) < 0.01:\n",
    "            return str(round(number))\n",
    "        # Otherwise, round to one decimal place\n",
    "        return str(round(number, 1))\n",
    "    \n",
    "    # Handle yes/no answers\n",
    "    text = text.lower().strip()\n",
    "    if 'yes' in text or 'true' in text:\n",
    "        return 'yes'\n",
    "    if 'no' in text or 'false' in text:\n",
    "        return 'no'\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def generate_answer(example, model, tokenizer):\n",
    "    \"\"\"Generate answer using Phi-3\"\"\"\n",
    "    inputs = preprocess_example(example, tokenizer)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,\n",
    "            num_beams=5,\n",
    "            temperature=0.1,\n",
    "            top_p=0.95,\n",
    "            early_stopping=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return clean_answer(generated_text)\n",
    "\n",
    "def evaluate_model(test_data, model, tokenizer, num_samples=10):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    metric = load_metric(\"squad\")\n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    for i, example in enumerate(test_data[:num_samples]):\n",
    "        try:\n",
    "            pred_text = generate_answer(example, model, tokenizer)\n",
    "            true_text = example[\"qa\"][\"answer\"]\n",
    "            \n",
    "            predictions.append({\"id\": str(i), \"prediction_text\": pred_text})\n",
    "            references.append({\"id\": str(i), \"answers\": {\"text\": [true_text], \"answer_start\": [0]}})\n",
    "            \n",
    "            em = 1 if pred_text.strip() == true_text.strip() else 0\n",
    "            f1 = metric.compute(\n",
    "                predictions=[{\"id\": str(i), \"prediction_text\": pred_text}],\n",
    "                references=[{\"id\": str(i), \"answers\": {\"text\": [true_text], \"answer_start\": [0]}}]\n",
    "            )[\"f1\"]\n",
    "            \n",
    "            print(f\"\\nðŸ”¹ Example {i+1}\")\n",
    "            print(f\"â“ Question: {example['qa']['question']}\")\n",
    "            print(f\"âœ… Ground Truth: {true_text}\")\n",
    "            print(f\"ðŸ¤– Prediction: {pred_text}\")\n",
    "            print(f\"ðŸ“Š Metrics - Exact Match: {em}, F1: {f1:.2f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing example {i}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    results = metric.compute(predictions=predictions, references=references)\n",
    "    print(\"\\nðŸ“Š Overall Results:\", results)\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Initialize model and tokenizer\n",
    "    model, tokenizer = initialize_model()\n",
    "    print(\"Model initialized successfully!\")\n",
    "    \n",
    "    # Load datasets\n",
    "    test_data = load_finqa_dataset(\"/cs/student/projects2/aisd/2024/giliev/FinQA/dataset/test.json\")\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "    \n",
    "    # Evaluate model\n",
    "    results = evaluate_model(test_data, model, tokenizer, num_samples=10)\n",
    "    \n",
    "    # Save results\n",
    "    with open(\"evaluation_results.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finqaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
